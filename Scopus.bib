
@ARTICLE{Wang2019,
author={Wang, X. and Nie, T. and Zhu, D.},
title={Indoor robot path planning assisted by wireless network},
journal={Eurasip Journal on Wireless Communications and Networking},
year={2019},
volume={2019},
number={1},
doi={10.1186/s13638-019-1437-x},
art_number={123},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066142680&doi=10.1186%2fs13638-019-1437-x&partnerID=40&md5=9ced8981dd42373c88dd55bff39d57eb},
affiliation={College of Electrics and Information, Xi’an Polytechnic University, Xi’an, China; College of Communication and Information Engineer, Xi’an University of Science and Technology, Xi’an, China},
abstract={Indoor robot global path planning needs to complete the motion between the starting point and the target point according to robot position command transmitted by the wireless network. Behavior dynamics and rolling windows in global path planning methods have limitations in their applications because the path may not be optimal, there could be a pseudo attractor or blind search in an environment with a large state space, there could be an environment where offline learning is not applicable to real-time changes, or there could be a need to set the probability of selecting the robot action. To solve these problems, we propose a behavior dynamics and rolling windows approach to a path planning which is based on online reinforcement learning. It applies Q learning to optimize the behavior dynamics model parameters to improve the performance, behavior dynamics guides the learning process of Q learning and improves learning efficiency, and each round of intensive learning action selection knowledge is gradually corrected as the Q table is updated. The learning process is optimized. The simulation results show that this method has achieved remarkable improvement in path planning. And, in the actual experiment, the robot obtains the target location information by wireless network, and plans an optimized and smooth global path online. © 2019, The Author(s).},
author_keywords={Behavior dynamics;  Path planning;  Q learning;  Rolling windows},
document_type={Article},
source={Scopus},
}

@ARTICLE{Kuhner201998,
author={Kuhner, D. and Fiederer, L.D.J. and Aldinger, J. and Burget, F. and Völker, M. and Schirrmeister, R.T. and Do, C. and Boedecker, J. and Nebel, B. and Ball, T. and Burgard, W.},
title={A service assistant combining autonomous robotics, flexible goal formulation, and deep-learning-based brain–computer interfacing},
journal={Robotics and Autonomous Systems},
year={2019},
volume={116},
pages={98-113},
doi={10.1016/j.robot.2019.02.015},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063740287&doi=10.1016%2fj.robot.2019.02.015&partnerID=40&md5=447d0427bcbd0fe352e2275e1e81181b},
affiliation={Department of Computer Science, University of Freiburg, Germany; Faculty of Medicine, University of Freiburg, Germany; Faculty of Biology, University of Freiburg, Germany; BrainLinks-BrainTools Cluster of Excellence, University of Freiburg, Germany},
abstract={As autonomous service robots become more affordable and thus available for the general public, there is a growing need for user-friendly interfaces to control these systems. Control interfaces typically get more complicated with increasing complexity of robotic tasks and environments. Traditional control modalities such as touch, speech or gesture are not necessarily suited for all users. While some users can make the effort to familiarize themselves with a robotic system, users with motor disabilities may not be capable of controlling such systems even though they need robotic assistance most. In this paper, we present a novel framework that allows these users to interact with a robotic service assistant in a closed-loop fashion, using only thoughts. The system is composed of several interacting components: a brain–computer interface (BCI) that uses non-invasive neuronal signal recording and co-adaptive deep learning, high-level task planning based on referring expressions, navigation and manipulation planning as well as environmental perception. We extensively evaluate the BCI in various tasks, determine the performance of the goal formulation user interface and investigate its intuitiveness in a user study. Furthermore, we demonstrate the applicability and robustness of the system in real-world scenarios, considering fetch-and-carry tasks, close human–robot interactions and in presence of unexpected changes. As our results show, the system is capable of adapting to frequent changes in the environment and reliably accomplishes given tasks within a reasonable amount of time. Combined with high-level task planning based on referring expressions and an autonomous robotic system, interesting new perspectives open up for non-invasive BCI-based human–robot interactions. © 2019 The Authors},
author_keywords={Autonomous robotics;  Co-adaptive brain–computer-interface;  Computer vision;  EEG;  High-level task planning;  Realtime deep learning;  Referring expression generation},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rice2019814,
author={Rice, M.K. and Zenati, M.S. and Novak, S.M. and Al Abbas, A.I. and Zureikat, A.H. and Zeh, H.J., III and Hogg, M.E.},
title={Crowdsourced Assessment of Inanimate Biotissue Drills: A Valid and Cost-Effective Way to Evaluate Surgical Trainees},
journal={Journal of Surgical Education},
year={2019},
volume={76},
number={3},
pages={814-823},
doi={10.1016/j.jsurg.2018.10.007},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056852127&doi=10.1016%2fj.jsurg.2018.10.007&partnerID=40&md5=2df084f310c2494eeb63d399054627d2},
affiliation={University of Maryland School of Medicine, Baltimore, MD, United States; Department of Surgery, University of Pittsburgh Medical Center, Pittsburgh, PA, United States; Department of Surgery, Northshore University HealthSystem, Chicago, IL, United States; Division of Surgical Oncology, University of Pittsburgh Medical Center, Pittsburgh, PA, United States; Department of Surgery, University of Texas Southwestern Medical Center, Dallas, TX, United States},
abstract={OBJECTIVE: Providing feedback to surgical trainees is a critical component for assessment of technical skills, yet remains costly and time consuming. We hypothesize that statistical selection can identify a homogenous group of nonexpert crowdworkers capable of accurately grading inanimate surgical video. DESIGN: Applicants auditioned by grading 9 training videos using the Objective Structured Assessment of Technical Skills (OSATS) tool and an error-based checklist. The summed OSATS, summed errors, and OSATS summary score were tested for outliers using Cronbach's Alpha and single measure intraclass correlation. Accepted crowdworkers then submitted grades for videos in 3 different compositions: full video 1× speed, full video 2× speed, and critical section segmented video. Graders were blinded to this study and a similar statistical analysis was performed. SETTING: The study was conducted at the University of Pittsburgh Medical Center (Pittsburgh, PA), a tertiary care academic teaching hospital. PARTICIPANTS: Thirty-six premedical students participated as crowdworker applicants and 2 surgery experts were compared as the gold-standard. RESULTS: The selected hire intraclass correlation was 0.717 for Total Errors and 0.794 for Total OSATS for the first hire group and 0.800 for Total OSATS and 0.654 for Total Errors for the second hire group. There was very good correlation between full videos at 1× and 2× speed with an interitem statistic of 0.817 for errors and 0.86 for OSATS. Only moderate correlation was found with critical section segments. In 1 year 275hours of inanimate video was graded costing $22.27/video or $1.03/minute. CONCLUSIONS: Statistical selection can be used to identify a homogenous cohort of crowdworkers used for grading trainees’ inanimate drills. Crowdworkers can distinguish OSATS metrics and errors in full videos at 2× speed but were less consistent with segmented videos. The program is a comparatively cost-effective way to provide feedback to surgical trainees. © 2018 Association of Program Directors in Surgery},
author_keywords={Biotissue;  critical section;  Crowdsource;  CS;  gastrojejunostomy;  GJ;  hepaticojejunostomy;  hepatobiliary;  HJ;  HPB;  IHJ;  interrupted hepaticojejunostomy;  Objective Structured Assessment of Technical Skills;  OSATS;  pancreaticojejunostomy;  PJ;  Practice-Based Learning and Improvement;  Robotic surgery;  Surgical education},
document_type={Article},
source={Scopus},
}

@ARTICLE{Magaña20192140,
author={Magaña, O.A.V. and Barasuol, V. and Camurri, M. and Franceschi, L. and Focchi, M. and Pontil, M. and Caldwell, D.G. and Semini, C.},
title={Fast and Continuous Foothold Adaptation for Dynamic Locomotion Through CNNs},
journal={IEEE Robotics and Automation Letters},
year={2019},
volume={4},
number={2},
pages={2140-2147},
doi={10.1109/LRA.2019.2899434},
art_number={8642374},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062921473&doi=10.1109%2fLRA.2019.2899434&partnerID=40&md5=6c4f39017ab57b5fb9ef1016a8cdb725},
affiliation={Dynamic Legged Systems Lab, Istituto Italiano di Tecnologia, Genoa, 16163, Italy; Oxford Robotics Institute, University of Oxford, Oxford, OX2 6NN, United Kingdom; Computational Statistics and Machine Learning, Istituto Italiano di Tecnologia, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, 16163, Italy},
abstract={Legged robots can outperform wheeled machines for most navigation tasks across unknown and rough terrains. For such tasks, visual feedback is a fundamental asset to provide robots with terrain awareness. However, robust dynamic locomotion on difficult terrains with real-time performance guarantees remains a challenge. We present here a real-time, dynamic foothold adaptation strategy based on visual feedback. Our method adjusts the landing position of the feet in a fully reactive manner, using only on-board computers and sensors. The correction is computed and executed continuously along the swing phase trajectory of each leg. To efficiently adapt the landing position, we implement a self-supervised foothold classifier based on a convolutional neural network. Our method results in an up to 200 times faster computation with respect to the full-blown heuristics. Our goal is to react to visual stimuli from the environment, bridging the gap between blind reactive locomotion and purely vision-based planning strategies. We assess the performance of our method on the dynamic quadruped robot HyQ, executing static and dynamic gaits (at speeds up to 0.5 m/s) in both simulated and real scenarios; the benefit of safe foothold adaptation is clearly demonstrated by the overall robot behavior. © 2019 IEEE.},
author_keywords={Deep Learning in Robotics and Automation;  Legged Robots;  Reactive and Sensor-Based Planning},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Hung2019162,
author={Hung, C.-M. and Lin, A.T. and Peng, B. and Wang, H. and Hsu, J.-L. and Lu, Y.-J. and Hsu, W. and Zhan, J.-H.C. and Juan, B. and Lok, C.-H. and Lee, S. and Hsiao, P. and Zhou, Q. and Wei, M. and Chu, H.-Y. and Chen, Y.-L. and Hung, C.-C. and Fong, K. and Huang, P.-C. and Chen, P. and Su, S.-Y. and Chen, Y.-J. and Chen, K. and Tung, C.-C. and Hsieh, Y.-J. and Tsai, T.-C. and Chen, Y.-F. and Hsin, W.-K. and Guo, L. and Liu, H. and Jin, D.},
title={9.1 Toward Automotive Surround-View Radars},
journal={Digest of Technical Papers - IEEE International Solid-State Circuits Conference},
year={2019},
volume={2019-February},
pages={162-164},
doi={10.1109/ISSCC.2019.8662489},
art_number={8662489},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063537172&doi=10.1109%2fISSCC.2019.8662489&partnerID=40&md5=cbffc6b9828a436b43c3c8873792db7c},
affiliation={MediaTek, Hsinchu, Taiwan; MediaTek, San Jose, CA, United States; MediaTek, Hefei, China},
abstract={The future of driving extends from physical mobility and enjoyment today to having more services enabled by wireless connectivity, clean and green technologies, secure transactions, and so forth. Whether the ownership is based on physical vehicles or services, or whether the drivers are human or robots, one demand that will never change is to have better safety at affordable cost. Among available sensor technologies for the advanced-driver-assistance-system (ADAS), radar is indispensable due to its unique capability in robustness against environmental impacts, long-range detection, sufficient range resolution, and simultaneous multi-depth detection. Those are very crucial since camera, Lidar and ultrasonic sensors perform poorly under severe weather conditions, and an autonomous vehicle would become partially blinded without radars. There are several automotive radar applications such as front radars responsible for autonomous cruise control and automatic emergency braking, as well as corner radars responsible for blind-spot detection (BSD), cross-traffic alert (CTA), and the like. A new class of applications comprehending ultra-short range sensing and 360° surround view for parking assistance, door-opening alert, etc. is emerging. In this paper, requirements of the new applications will be examined, which will be further broken into system and circuit specification. A new system including application-driven algorithm, hardware and software designs will be presented to fulfill the new demands. © 2019 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jayaraman2019E263,
author={Jayaraman, A. and O'brien, M.K. and Madhavan, S. and Mummidisetty, C.K. and Roth, H.R. and Hohl, K. and Tapp, A. and Brennan, K. and Kocherginsky, M. and Williams, K.J. and Takahashi, H. and Rymer, W.Z.},
title={Stride management assist exoskeleton vs functional gait training in stroke: A randomized trial},
journal={Neurology},
year={2019},
volume={92},
number={3},
pages={E263-E273},
doi={10.1212/WNL.0000000000006782},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060053557&doi=10.1212%2fWNL.0000000000006782&partnerID=40&md5=e2cd5047941047557e600d91c3c5f48b},
affiliation={Max Nader Lab for Rehabilitation Technologies and Outcomes Research, Northwestern University, Raymond, OH, United States; Shirley Ryan AbilityLab, Northwestern University, Raymond, OH, United States; Department of Physical Medicine and Rehabilitation, Northwestern University, Raymond, OH, United States; Preventative Medicine, Northwestern University, Raymond, OH, United States; Department of Physical Therapy, University of Illinois at Chicago, Raymond, OH, United States; Honda RandD Americas, Inc., Raymond, OH, United States},
abstract={ObjectiveTo test the hypothesis that gait training with a hip-assistive robotic exoskeleton improves clinical outcomes and strengthens the descending corticospinal drive to the lower limb muscles in persons with chronic stroke.MethodsFifty participants completed the randomized, single-blind, parallel study. Participants received over-ground gait training with the Honda Stride Management Assist (SMA) exoskeleton or intensity-matched functional gait training, delivered in 18 sessions over 6-8 weeks. Performance-based and self-reported clinical outcomes were measured at baseline, midpoint, and completion, and at a 3-month follow-up. Corticomotor excitability (CME) of 3 bilateral leg muscles was measured using transcranial magnetic stimulation.ResultsThe primary outcome, walking speed, improved for the SMA group by completion of the program (0.24 ± 0.14 m/s difference, p < 0.001). Compared to the functional group, SMA users had greater improvement in walking endurance (46.0% ± 27.4% vs 35.7% ± 20.8%, p = 0.033), took more steps during therapy days (4,366 ± 2,426 vs 3,028 ± 1,510; p = 0.013), and demonstrated larger changes in CME of the paretic rectus femoris (178% ± 75% vs 33% ± 32%, p = 0.010). Participants with hemorrhagic stroke demonstrated greater improvement in balance when using the SMA (24.7% ± 20% vs 6.8% ± 6.7%, p = 0.029).ConclusionsGait training with the SMA improved walking speed in persons with chronic stroke, and may promote greater walking endurance, balance, and CME than functional gait training.Clinicaltrials.gov identifierNCT01994395.Classification of evidenceThis study provides Class I evidence that gait training with a hip-assistive exoskeleton increases clinical outcomes and CME in persons with chronic stroke, but does not significantly improve walking speeds compared to intensity-matched functional gait training. © American Academy of Neurology 2018.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Torres2019623,
author={Torres, C. and Franklin, W. and Martins, L.},
title={Accessibility in chatbots: The state of the art in favor of users with visual impairment},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={794},
pages={623-635},
doi={10.1007/978-3-319-94947-5_63},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049510734&doi=10.1007%2f978-3-319-94947-5_63&partnerID=40&md5=bc3ec195da217d658ef0bec939a33846},
affiliation={Universidade Federal de Pernambuco, Recife, PE, Brazil},
abstract={Society has been experiencing a great technological advance in the most diverse areas and, clearly, the development of accessibility for software and applications does not seem to follow this speed. In fact, systems sometimes do not embrace people with some kind of disability, and this is a problem that should be on the agenda of every designer and system designer when thinking about user experience. Chatbots are conversational interfaces on which users communicate with a robotic entity through text, either designed with artificial intelligence or not. However, how does a blind user interact with Chatbots? How should this interaction be carried on? What to expect when users’ needs are challenged by physical barriers worse than what affects the common user? This article aims to present a systematic review of the existing literature on Chatbots, conversational interfaces and the inclusion of accessibility in these interfaces. © 2019, Springer International Publishing AG, part of Springer Nature.},
author_keywords={Accessibility;  Chatbots;  Conversational interface;  Rapid systematic review;  Smartphones;  User centered design;  Visual impairment},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Suresh201999,
author={Suresh, A. and Arora, C. and Laha, D. and Gaba, D. and Bhambri, S.},
title={Intelligent smart glass for visually impaired using deep learning machine vision techniques and robot operating system (ROS)},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={751},
pages={99-112},
doi={10.1007/978-3-319-78452-6_10},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048225919&doi=10.1007%2f978-3-319-78452-6_10&partnerID=40&md5=d1498c12bd9fce39a95432512cc8b1d2},
affiliation={Department of Mechanical and Aerospace Engineering, New York University, New York, United States; Department of Electronics and Communication Engineering, Bharati Vidyapeeth’s College of Engineering, Pune, India},
abstract={The Smart Glass represents potential aid for people who are visually impaired that might lead to improvements in the quality of life. The smart glass is for the people who need to navigate independently and feel socially convenient and secure while they do so. It is based on the simple idea that blind people do not want to stand out while using tools for help. This paper focuses on the significant work done in the field of wearable electronics and the features which comes as add-ons. The Smart glass consists of ultrasonic sensors to detect the object ahead in real-time and feeds the Raspberry for analysis of the object whether it is an obstacle or a person. It can also assist the person on whether the object is closing in very fast and if so, provides a warning through vibrations in the recognized direction. It has an added feature of GSM, which can assist the person to make a call during an emergency situation. The software framework management of the whole system is controlled using Robot Operating System (ROS). It is developed using ROS catkin workspace with necessary packages and nodes. The ROS was loaded on to Raspberry Pi with Ubuntu Mate. © Springer International Publishing AG, part of Springer Nature 2019.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{doCarmo2019,
author={do Carmo, A.P. and Vassallo, R.F. and de Queiroz, F.M. and Picoreti, R. and Fernandes, M.R. and Gomes, R.L. and Martinello, M. and Dominicini, C.K. and Guimarães, R. and Garcia, A.S. and Ribeiro, M.R.N. and Simeonidou, D.},
title={Programmable intelligent spaces for Industry 4.0: Indoor visual localization driving attocell networks},
journal={Transactions on Emerging Telecommunications Technologies},
year={2019},
doi={10.1002/ett.3610},
art_number={e3610},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063888979&doi=10.1002%2fett.3610&partnerID=40&md5=3e6c7669a9828aeeabb5015c49fbe2ce},
affiliation={Electrical Engineering Department, Federal Institute of Espírito Santo, Guarapari, Brazil; Electric Engineering Department, Federal University of Espírito Santo, Vitória, Brazil; Electrical Engineering Department, Federal Institute of Espírito Santo, Vitória, Brazil; Informatics Department, Federal University of Espírito Santo, Vitória, Brazil; High Performance Networks Group, University of Bristol, Bristol, United Kingdom},
abstract={Real-time and mission-critical applications for Industry 4.0 demand fast and reliable communication. Therefore, knowing devices' location is essential, but GPS is of little use indoors, whereas electromagnetic impairments and interferences demand new approaches to ensure reliability. The challenges include real-time feedback with end-to-end (E2E) low latency; high data density due to large number of IoT devices per area; and smaller communication cells, which increases the handover frequency and complexity. To tackle these issues, we introduce a programmable intelligent space (PIS) to deploy attocells, enable E2E programmability, and provide a precise computer vision localization system and networking programmability based on software-defined networking. To validate our approach, experiments were conducted, controlling a mobile robot through a trajectory. We demonstrate the need for higher camera frame rate to achieve tighter precision, evaluating different trade-offs on localization, bandwidth, and latency. Results have shown that PIS wireless attocell handover achieves seamlessly mobile communication, delivering packets within the deadline window, with similar performance to a no handover baseline. © 2019 John Wiley & Sons, Ltd.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Fachantidis2019,
author={Fachantidis, N. and Syriopoulou-Delli, C.K. and Vezyrtzis, I. and Zygopoulou, M.},
title={Beneficial effects of a robot-mediated class activities on a child with ASD and his typical classmates},
journal={International Journal of Developmental Disabilities},
year={2019},
doi={10.1080/20473869.2019.1565725},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061246448&doi=10.1080%2f20473869.2019.1565725&partnerID=40&md5=d329469e28148360b1a5353f12e5b4e0},
affiliation={Department of Educational and Social Policy, University of Macedonia, Thessaloniki, Greece},
abstract={Objective: The current educational intervention investigates how the use of the educational robot as an assistive tool can aid young children with Autism Spectrum Disorder helping them strengthen relationships and improving their interaction with typically developing children. Method: For this purpose an interdisciplinary road safety program was implemented involving the construction, programming and operation of a 3D LEGO robot bicycle model. Results: The results showed that the use of educational robotics appeared to bring about a change in the indifferent attitude of the typically developing students towards the students with ASD. In addition in contributed to the development of the social, communicational and emotionsl skills of the child with ASD and lead to a reduction in his challenging behaviors. © 2019, © 2019 The British Society of Developmental Disabilities.},
author_keywords={autism spectrum disorder;  Educational robotics;  skills development},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor2019,
title={Joint proceedings of the AHFE International Conference on Advanced Production Management and Process Control, AHFE International Conference on Human Aspects of Advanced Manufacturing, and AHFE International Conference on Additive Manufacturing, Modeling Systems and 3D Prototyping, 2018},
journal={Advances in Intelligent Systems and Computing},
year={2019},
volume={793},
page_count={479},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049666324&partnerID=40&md5=bfec8f151502c57362902fe5500a9afb},
abstract={The proceedings contain 51 papers. The special focus in this conference is on Advanced Production Management and Process Control. The topics include: Evaluating Strategies to Restore Trust in Decision Support Systems in Cross-Company Cooperation; designing for the Future Factory: Exploring the Co-evolution of Manufacturing Digital Intensity and Personas; ways to Encourage Re-manufacturing as Nigeria Seeks to Transition into a Green Economy; Exoskeleton Assistance Assessment (EAA)-Tool; regional Development in Modern Robotic Education on Industrial and Society Context; the Effect of Speed Variation on Initial and Sustained Forces During Pushing and Pulling Activities: A Preliminary Study; Human Factor and Working Out of NBIC Technologies; prior Knowledge and Opportunity Recognition; modelling 3D Objects Using 2D Sketches Through Radial Renderings of Curvature Maps; evaluation of Order Picking Processes Regarding the Suitability of Smart Glasses-Based Assistance Using Rasmussen’s Skills-Rules-Knowledge Framework; towards a Digital Healthcare Revolution Views and Researches of the Milanese FabLab Community; direct Control of 3D Models Through User Input to Simulate the Behavior of Mechatronic Systems; 3D Design Process: Case Study of Metaproject Analysis and 3D Printing Concept Proposal in the Field of Fashion; image Processing of Artworks for Construction of 3D Models Accessible to the Visually Impaired; use of Digital Modeling and 3D Printing for the Inclusive Valorization of Cultural Heritage; applying the Programmable Modeling Tool to Support the Hospital Infection Control Staff in Customizing the Filtering Face-Piece Respirators for Health Care Worker; reverse Engineering and Digital Archives as a Resource for Practical Craft-Based Manufacturing Process; c4t: Safe Behavior Performance Tool.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Wu2019,
author={Wu, Q. and Lin, H. and Jin, Y. and Chen, Z. and Li, S. and Chen, D.},
title={A new fallback beetle antennae search algorithm for path planning of mobile robots with collision-free capability},
journal={Soft Computing},
year={2019},
doi={10.1007/s00500-019-04067-3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066622576&doi=10.1007%2fs00500-019-04067-3&partnerID=40&md5=8cdf6b19a092afe925032c0d188c0932},
affiliation={Department of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Department of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong, China},
abstract={With the development of technology, mobile robots are becoming more and more common in industrial production and daily life. Various rules are set to ensure that mobile robots can move without collision. This paper proposes a novel intelligent optimization algorithm, named fallback beetle antennae search algorithm. Based on the analysis of biological habits, when the creature enters blind alley during the foraging process, it will retreat a distance and then restart the search process. We introduce a fallback mechanism in the traditional beetle antenna search algorithm. In addition, the proposed algorithm possesses the characteristic of low time complexity. It can plan a collision-free path in a short period of time. Moreover, the effectiveness and superiority of the algorithm are verified by simulations in different types of environments and comparisons with existing path planning algorithms. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.},
author_keywords={Fallback beetle antennae search (FBAS);  Mobile robots;  Obstacle avoidance;  Optimization;  Path planning},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Lewis20187383,
author={Lewis, J.S. and Feshbach, D.A. and O'Kane, J.M.},
title={Guaranteed Coverage with a Blind Unreliable Robot},
journal={IEEE International Conference on Intelligent Robots and Systems},
year={2018},
pages={7383-7390},
doi={10.1109/IROS.2018.8594048},
art_number={8594048},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062946574&doi=10.1109%2fIROS.2018.8594048&partnerID=40&md5=1d827cfb0338f8df9488b162056fb0b5},
affiliation={University of South Carolina, Department of Computer Science and Engineering, Columbia, SC, United States; Department of Computer Science at Haverford College, Haverford, PA, United States},
abstract={We consider the problem of coverage planning for a particular type of very simple mobile robot. The robot must be able to translate in a commanded direction (specified in a global reference frame), with bounded error on the motion direction, until reaching the environment boundary. The objective, for a given environment map, is to generate a sequence of motions that is guaranteed to cover as large a portion of that environment as possible, in spite of the severe limits on the robot's sensing and actuation abilities. We show how to model the knowledge available to this kind of robot about its own position within the environment, show how to compute the region whose coverage can be guaranteed for a given plan, and characterize regions whose coverage cannot be guaranteed by any plan. We also describe a heuristic algorithm that generates coverage plans for this robot, based on a search across a specially-constructed graph. Simulation results demonstrate the effectiveness of the approach. © 2018 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Mayr2018819,
author={Mayr, A. and Quirbach, E. and Picelli, A. and Kofler, M. and Smania, N. and Saltuari, L.},
title={Early robot-assisted gait retraining in non-ambulatory patients with stroke: A single blind randomized controlled trial},
journal={European Journal of Physical and Rehabilitation Medicine},
year={2018},
volume={54},
number={6},
pages={819-826},
doi={10.23736/S1973-9087.18.04832-3},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059794804&doi=10.23736%2fS1973-9087.18.04832-3&partnerID=40&md5=b3e1b04d6641cec4b4c04cd933b30518},
affiliation={Department of Neurology, Hochzirl Hospital, Zirl, Austria; Neuromotor and Cognitive Rehabilitation Research Center, Department of Neurosciences, Biomedicine and Movement Sciences, University of Verona, Verona, Italy; Unit of Neurorehabilitation, Department of Neurosciences, Hospital Trust of Verona, Verona, Italy; Research Department for Neurorehabilitation South Tyrol, Bolzano, Italy; Department of Neurology, Hospital Hochzirl-Natters, Hochzirl, A-6170, Austria},
abstract={BACKGROUND: Restoration of walking function is a primary concern of neurorehabilitation with respect to the aspired social and vocational reintegration. To date, the best practice for improving gait early after stroke is still object of debate. On one hand, repetitive task-specific approaches with higher intensities of walking have been observed to result in greater improvements of gait after stroke. Conversely there is some evidence that conventional gait training would be more effective for facilitating walking ability after stroke. AIM: To compare the effects of an early treatment protocol of add-on robot-assisted gait training with add-on conventional overground physiotherapy for improving locomotion in non-ambulatory adult stroke patients. DESIGN: Single-blind randomized controlled trial. SETTING: Neurorehabilitation hospital. POPULATION: Seventy-four subacute patients with first-ever ischemic stroke. METHODS: The patients were randomized into two groups. The training program consisted of forty, 2-hour sessions (including 45 minutes basic training, 45 minutes add-on training plus rest periods), 5 days a week, for 8 consecutive weeks. Patients allocated to the add-on robot-assisted gait training were treated by means of the Lokomat. Patients allocated to the add-on conventional overground gait training aimed at improving postural control during gait, body weight transfer, stability during the stance phase, free swing phase, adequate heel contact and gait pattern. Primary outcome was the modified Emory Functional Ambulation Profile. Secondary outcomes were the Rivermead Motor Index, the Mobility Milestones and the Hochzirl Walking Aids Profile. RESULTS: No significant difference was observed between groups with regards to age (P=0.661), time from stroke onset (P=0.413) and the primary outcome (P=0.854) at baseline evaluation. As to the primary outcome, no significant differences were found between groups at the end of the study. As During the 8-week training, within-group comparisons showed significant improvements of mean modified Emory Functional Ambulation Profile in both groups (P<0.001). CONCLUSIONS: Our results support the hypothesis that an early treatment protocol of robot-assisted gait retraining is not superior to add-on conventional gait training intervention for improving locomotion in non-ambulatory stroke patients. CLINICAL REHABILITATION IMPACT: This study might help to better understand the role of robot-assisted gait training in early phase stroke rehabilitation © 2018 EDIZIONI MINERVA MEDICA},
author_keywords={Locomotion;  Rehabilitation;  Robotics},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wang2018,
author={Wang, M. and Li, Z. and Zhao, Q. and Si, F. and Huang, D.},
title={Path planning based on an improved ant colony algorithm},
journal={MATEC Web of Conferences},
year={2018},
volume={228},
doi={10.1051/matecconf/201822801010},
art_number={01010},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057384999&doi=10.1051%2fmatecconf%2f201822801010&partnerID=40&md5=3301a10b9b3fa127bfebcb248c31eae7},
affiliation={College of Electrical and Information Engineering, Guangxi University of Science and Technology, Liuzhou, 545006, China},
abstract={The classical ant colony algorithm has the disadvantages of initial search blindness, slow convergence speed and easy to fall into local optimum when applied to mobile robot path planning. This paper presents an improved ant colony algorithm in order to solve these disadvantages. First, the algorithm use A∗ search algorithm for initial search to generate uneven initial pheromone distribution to solve the initial search blindness problem. At the same time, the algorithm also limits the pheromone concentration to avoid local optimum. Then, the algorithm optimizes the transfer probability and adopts the pheromone update rule of »incentive and suppression strategy» to accelerate the convergence speed. Finally, the algorithm builds an adaptive model of pheromone coefficient to make the pheromone coefficient adjustment self-adaptive to avoid falling into a local minimum. The results proved that the proposed algorithm is practical and effective. © 2018 The Authors, published by EDP Sciences.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Castellanos-Cruz20181280,
author={Castellanos-Cruz, J.L. and Gómez-Medina, M.F. and Tavakoli, M. and Pilarski, P.M. and Adams, K.},
title={Preliminary Testing of a Telerobotic Haptic System and Analysis of Visual Attention during a Playful Activity},
journal={Proceedings of the IEEE RAS and EMBS International Conference on Biomedical Robotics and Biomechatronics},
year={2018},
volume={2018-August},
pages={1280-1285},
doi={10.1109/BIOROB.2018.8487612},
art_number={8487612},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056584825&doi=10.1109%2fBIOROB.2018.8487612&partnerID=40&md5=6ff99140468b7c7946e25976515e277f},
affiliation={Faculty of Rehabilitation Medicine, University of Alberta, Canada; Electrical Computer Engineering Department, University of Alberta, Canada; Department of Medicine, University of Alberta, Canada},
abstract={Children with physical impairments face great challenges to play because of their limitations, for example, in reaching and grasping obj ects. Children with physical impairments can improve their independence, cognitive, and social skills by playing using robots. In this study, we developed a telerobotic haptic system with two haptic robots, one that is for a child and the other to interact with the environment. The goal of this study was to do preliminary tests of the haptic guidance method and the prediction of targets. Another goal was to explore and analyze the visual attention of the participants during the activity when eye-hand discoordination was induced. Five adults without disabilities played a whack-a-mole game using the robotic system, to assure that the robot works adequately before children with disabilities use it. The robots were programmed to induce eye-hand discoordination, so that haptic guidance would be required. A multi-layer perceptron neural network was implemented to predict the target moles that the participants had to reach, which in future versions, will control the activation of forbidden region virtual fixtures (FRVF) to guide the user towards the target moles. Analysis of participant's eye gaze led to the hypothesis that the less control a person has over the teleoperation system, the less they will look at the target. On average, the accuracy of the target prediction by the neural network was 70.7%. The predicting of targets will allow the robot to assist children during movement of the robot towards the target toy, without needing the children to explicitly point out with their gaze which toy they want to reach. This will potentially lead to a more intuitive and faster human-robot interaction. © 2018 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Wang20181775,
author={Wang, X.-Y. and Yang, L. and Zhang, Y. and Meng, S.},
title={Robot path planning based on improved ant colony algorithm with potential field heuristic [基于改进势场蚁群算法的机器人路径规划]},
journal={Kongzhi yu Juece/Control and Decision},
year={2018},
volume={33},
number={10},
pages={1775-1781},
doi={10.13195/j.kzyjc.2017.0639},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059453488&doi=10.13195%2fj.kzyjc.2017.0639&partnerID=40&md5=73ac687ca423557c6d65b6f23e8ea65b},
affiliation={School of Mechatronic Engineering, Xi'an University of Architecture and Technology, Xi'an, 710055, China},
abstract={The paper proposes an improved ant colony algorithm with potential field heuristic for the path planning of mobile robots in the global static environment. The algorithm constructs the comprehensive heuristic information based on the initial path obatined by using the artificial potential field method and the distance between the robot and the next node. Then, the heuristic information decline coefficient is introduced to avoid the local optimization problem caused by misleading information of the traditional ant colony algorithm. Based on the zero point theorem, this paper proposes an initial pheromone unequal allocation principle. Various grid positions are endowed with different initial pheromones, which decreases the blindness of ant colony search and improves the searching efficiency of the algorithm. An iterative threshold is set to adaptively adjust pheromone volatilization coefficients. In this way, the algorithm has excellent global searching ability, and the stagnation phenomenon can be avoided. The simulation results show the feasibility and effectiveness of the proposed method. © 2018, Editorial Office of Control and Decision. All right reserved.},
author_keywords={Ant colony algorithm;  Artificial potential field;  Heuristic information;  Path planning},
document_type={Article},
source={Scopus},
}

@ARTICLE{DeLuca2018791,
author={De Luca, R. and Russo, M. and Naro, A. and Tomasello, P. and Leonardi, S. and Santamaria, F. and Desireè, L. and Bramanti, A. and Silvestri, G. and Bramanti, P. and Calabrò, R.S.},
title={Effects of virtual reality-based training with BTs-Nirvana on functional recovery in stroke patients: preliminary considerations},
journal={International Journal of Neuroscience},
year={2018},
volume={128},
number={9},
pages={791-796},
doi={10.1080/00207454.2017.1403915},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041567314&doi=10.1080%2f00207454.2017.1403915&partnerID=40&md5=afdc8739edbfd3081412a35c061f8a71},
affiliation={IRCCS Centro Neurolesi ‘Bonino Pulejo’, Messina, Italy},
abstract={Aim of the study: Cognitive impairment occurs frequently in post-stroke patients. This study aimed to determine the effects of a virtual reality training (VRT) with BTs-Nirvana (BTsN) on the recovery of cognitive functions in stroke patients, using the Interactive-Semi-Immersive Program (I-SIP). Materials and methods: We enrolled 12 subjects (randomly divided into two groups: experimental group (EG); and control group (CG)), who attended the Laboratory of Robotic and Cognitive Rehabilitation of IRCCS Neurolesi of Messina from January to June 2016. The EG underwent a VRT with BTsN, whereas CG received a standard cognitive treatment. Both the groups underwent the same conventional physiotherapy program. Each treatment session lasted 45 minutes and was repeated three times a week for 8 weeks. All the patients were evaluated by a specific clinical-psychometric battery before (T0), immediately (T1), and one month (T2) after the end of the training. Results: At T1, the EG presented a greater improvement in the trunk control test (p = 0.03), the Montreal Cognitive Assessment (p = 0.01), the selective attention assessment scores (p = 0.01), the verbal memory (p = 0.03), and the visuospatial and constructive abilities (p = 0.01), as compared to CG. Moreover, such amelioration persisted at T2 only in the EG. Conclusions: According to these preliminary data, VRT with I-SIP can be considered a useful complementary treatment to potentiate functional recovery, with regard to attention, visual-spatial deficits, and motor function in patients affected by stroke. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.},
author_keywords={neuropsychological improvement;  Nirvana;  trunk control;  Virtual reality},
document_type={Article},
source={Scopus},
}

@ARTICLE{Taylor201878,
author={Taylor, M.S.},
title={Computer Programming With Pre-K Through First-Grade Students With Intellectual Disabilities},
journal={Journal of Special Education},
year={2018},
volume={52},
number={2},
pages={78-88},
doi={10.1177/0022466918761120},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044019445&doi=10.1177%2f0022466918761120&partnerID=40&md5=3ed66fdbbeef0351d56aa434390f95c7},
affiliation={University of Central Florida, Orlando, United States},
abstract={Researchers suggest students in early elementary grade levels are active learners and creators and need to be exposed to science, technology, engineering, and mathematics (STEM) curriculum. The need for student understanding in STEM curriculum is well-documented, and positive results in robotics and computer programming are leading researchers and policy makers to introduce new standards in education. The purpose of this single-case design study is to research the potential for PreK-1st grade students with intellectual disabilities (ID) to learn skills in computer programming through explicit instruction, concrete manipulatives, and tangible interfaces. Students were assessed through baseline, treatment, and generalization phases. The students with ID were found to successfully program the robot, following explicit instruction, although they had difficulty generalizing skills to tablet application. Discussion of results, future research, and limitations is provided. © Hammill Institute on Disabilities 2018.},
author_keywords={computer programming;  elementary;  intellectual disabilities;  robotics;  technology},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={ACM International Conference Proceeding Series},
journal={ACM International Conference Proceeding Series},
year={2018},
page_count={586},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049912703&partnerID=40&md5=b8e963120093d8b10a5ba7d89c3b11e5},
abstract={The proceedings contain 96 papers. The topics discussed include: user-centered design of instructive assistance systems for manual assembly tasks; application areas for mixed and virtual reality-supported assistive systems; requirements for tracking technologies in industrial MR applications; framework for educating users for industrial human-robot collaboration (HRC); modeling workflows considering human-robot-collaboration; a framework for programming a swarm of UAVs; analysis of concise 'average load' definitions in uniformly random deployed wireless sensor networks; towards deep learning based hand keypoints detection for rapid sequential movements from RGB images; health recommender system design in the context of caregivers PRO-MMD project; designing a gamified social platform for people living with dementia and their live-in family caregivers; activity segmentation and identification based on eye gaze features; multidimensional trajectory similarity estimation via spatial-temporal key frame selection and signal correlation analysis; design thinking: using photo prototyping for a user-centred interface design for pick-by-vision systems; smart tourism in cities: exploring urban destinations with audio augmented reality; unsupervised learning fuzzy finite state machine for human activities recognition; automata classification with convolutional neural networks for use in assistive technologies for the visually impaired; and skim-reading strategies in sighted and visually-impaired individuals: a comparative study.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Wu20181005,
author={Wu, Q. and Wang, X. and Chen, B. and Wu, H.},
title={Development of a Minimal-Intervention-Based Admittance Control Strategy for Upper Extremity Rehabilitation Exoskeleton},
journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems},
year={2018},
volume={48},
number={6},
pages={1005-1016},
doi={10.1109/TSMC.2017.2771227},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035793178&doi=10.1109%2fTSMC.2017.2771227&partnerID=40&md5=a4f1942f92d75e2aa0e4779f8445613d},
affiliation={College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210016, China; College of Mechanical Engineering, Southeast University, Nanjing, 211189, China},
abstract={The applications of robotics to the rehabilitation training of neuromuscular impairments have received increasing attention due to their promising prospects. The effectiveness of robot-assisted training directly depends on the control strategy applied in the therapy program. This paper presents an upper extremity exoskeleton for the functional recovery training of disabled patients. A minimal-intervention-based admittance control strategy is developed to induce the active participation of patients and maximize the use of recovered motor functions during training. The proposed control strategy can transit among three control modes, including human-conduct mode, robot-assist mode, and motion-restricted mode, based on the real-time position tracking errors of the end-effector. The human-robot interaction in different working areas can be modulated according to the motion intention of patient. Graphical guidance developed in Unity-3-D environment is introduced to provide visual training instructions. Furthermore, to improve training performance, the controller parameters should be adjusted in accordance with the hemiplegia degree of patients. For the patients with severe paralysis, robotic assistance should be increased to guarantee the accomplishment of training. For the patients recovering parts of motor functions, robotic assistance should be reduced to enhance the training intensity of effected limb and improve therapeutic effectiveness. The feasibility and effectiveness of the proposed control scheme are validated via training experiments with two healthy subjects and six stroke patients with different degrees of hemiplegia. © 2013 IEEE.},
author_keywords={Admittance control strategy;  human-robot interaction;  minimal-intervention-based;  rehabilitation;  upper extremity exoskeleton},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2018,
title={2017 6th International Conference on Information and Communication Technology and Accessbility, ICTA 2017},
journal={2017 6th International Conference on Information and Communication Technology and Accessbility, ICTA 2017},
year={2018},
volume={2017-December},
page_count={263},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051171449&partnerID=40&md5=4c915754e216ce4f5ab74a0bdb197b08},
abstract={The proceedings contain 43 papers. The topics discussed include: moving towards digital manufacturing in the Arab region: a 3D printing workshop experience; the experience of developing Mr. Saud educational system using NAO humanoid robot; challenges with creating accessible and usable learning environments for visually impaired students' language education; collaborative learning: a new horizon for e-learning in Sultan Qaboos university using concepts of MOOC and cloud computing; hybrid module for low-cost surveillance system; requirement elicitation for a toilet training wearable watch to serve autistic children; assistive technology competencies in learning disability program candidates at Sultan Qaboos university: a proposed model; a review on soccer player tracking techniques based on extracted features; an assistive mobile application i-AIM app with accessible UI implementation for visually-impaired and aging users; effectiveness of electronic interactive whiteboard use in developing the creative problem solving and learning motivation; and towards realistic simulation of facial deformation in sign language.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Fan2018344,
author={Fan, K. and Lyu, C. and Liu, Y. and Zhou, W. and Jiang, X. and Li, P. and Chen, H.},
title={Hardware implementation of a virtual blind cane on FPGA},
journal={2017 IEEE International Conference on Real-Time Computing and Robotics, RCAR 2017},
year={2018},
volume={2017-July},
pages={344-348},
doi={10.1109/RCAR.2017.8311885},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050588115&doi=10.1109%2fRCAR.2017.8311885&partnerID=40&md5=a01299cda35941b58d3e93dbfe46563c},
affiliation={School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen Graduate School, Shenzhen, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, Hong Kong},
abstract={This paper presented an FPGA based real-time virtual blind cane system for the visually impaired. This system consists of a Xilinx ZYNQ-7000 device, a CMOS camera, an inertial measurement unit (IMU) and a line laser. With this system, the visually impaired can recognize the distance and shape of the barrier ahead in real time to avoid it. The computational complexity of processing images in real time can be very high. In addition, for most embedded systems, there is a payload limitation, high performance computer and GPU is not suitable for embedded system. In this research, FPGA was chosen as its computing platform. Contrastive experimental results are presented to show the speed and robustness. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Molins-Ruano2018428,
author={Molins-Ruano, P. and Gonzalez-Sacristan, C. and Garcia-Saura, C.},
title={Phogo: A low cost, free and “maker” revisit to Logo},
journal={Computers in Human Behavior},
year={2018},
volume={80},
pages={428-440},
doi={10.1016/j.chb.2017.09.029},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031321658&doi=10.1016%2fj.chb.2017.09.029&partnerID=40&md5=2594e8e4f8974cc4bcaaba36a324c72c},
affiliation={Dpto. Ingeniería Informática, Escuela Politécnica Superior, Universidad Autónoma de Madrid, 28049 Campus de Cantoblanco, Madrid, Spain},
abstract={Today it is almost impossible to spend a single day without depending on an information system, a computer or any other form of computation. Though the starting barrier is low, fundamental concepts are still required in order to manage the technicalities of the engineering environment and everyday computational systems. In 1967, Logo proposed to teach abstract programming concepts by providing a set of functions that had intuitive, visible effects over a robotic Turtle. LOGO was a success, but the robots quickly migrated into computer simulations. From LOGO, many followed. Scratch and Lego Mindstorm are some of the most notorious examples. Both introduced graphical block-based programming interfaces. We propose to bring back the powerful ideas behind LOGO by updating it with state of the art technologies. Phogo combines Python, Arduino and 3D printing into a low cost robot that is easy to build and control. The robot has a pen to draw shapes and can be commanded from a computer via a wireless link that is transparent to the students. The use of a physical robot can make programming more accessible for students with disabilities. The open and maker philosophies behind Phogo makes it more interesting as students will be able to access and study the electronic components. The textual programing language can be a long life companion for the students. In this work we discuss LOGO and other projects inspired by it, and we also share the methodology and design decisions behind Phogo, the results of its application in a workshop and the improvements we are currently developing. © 2017 Elsevier Ltd},
author_keywords={Computational thinking;  Educational robots;  LOGO;  Pre-university education;  Technology education},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Ludi2018372,
author={Ludi, S. and Bernstein, D. and Mutch-Jones, K.},
title={Enhanced robotics! Improving building and programming learning experiences for students with visual impairments},
journal={SIGCSE 2018 - Proceedings of the 49th ACM Technical Symposium on Computer Science Education},
year={2018},
volume={2018-January},
pages={372-377},
doi={10.1145/3159450.3159501},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046076169&doi=10.1145%2f3159450.3159501&partnerID=40&md5=1fef207ffefba8b0d849f65d517c8b8c},
affiliation={Computer Science and Engineering Dept., University of North Texas, United States; TERC, United States},
abstract={Making technology and computer science learning experiences accessible to students with disabilities is an important step in preparing them to enter the workforce of the future-one in which many jobs will require skills to solve problems with technology. This paper presents the tool and curricular enhancements developed to make the Exploring Computer Science Robotics unit accessible to students with visual impairments (VI). It describes the evolution of enhancements, based on formative evaluation studies, to increase support as VI students engaged in building and programming LEGO Mindstorms robots. Results describe the ways in which enhancements were iteratively designed in response to student engagement and confidence, as well as their emerging understanding of top-down and bottom-up processes in robotics design and programming. © 2018 Association for Computing Machinery.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Tsuda2018611,
author={Tsuda, M. and Motoyoshi, T. and Sawai, K. and Tamamoto, T. and Masuta, H. and Koyanagi, K. and Oshima, T.},
title={Improvement of a tangible programming tool for the study of the subroutine concept},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={10896 LNCS},
pages={611-618},
doi={10.1007/978-3-319-94277-3_95},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049811193&doi=10.1007%2f978-3-319-94277-3_95&partnerID=40&md5=1e074626334987602d8c781240818712},
affiliation={Department of Intelligent Systems Design Engineering, Toyama Prefectural University, Toyama, 939-0398, Japan},
abstract={We developed a tangible programming education tool “P-CUBE2” to aim at learning benefits of subroutine such as to create a function once and then reuse it. The target user of this tool are visual impairments and inexperienced persons who are not familiar with PC operation. We introduced the function mat, utterance function blocks and HIRAGANA (Japanese character) blocks so that user can learn subroutine concept. Users can create the function of utterance by combining and placing these blocks which on the function mat. The created function of utterance can be called on the main mat. By these operation, the user can control a robot which outputs sound as a controlled object. In this research, we introduce the system configuration of the P-CUBE2 and report the result of experiment for evaluation of the tool operability. © Springer International Publishing AG, part of Springer Nature 2018.},
author_keywords={Subroutine concept;  Tangible programming tool;  Visual impairments},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Clary2018446,
author={Clary, P. and Morais, P. and Fern, A. and Hurst, J.},
title={Monte-Carlo planning for agile legged locomotion},
journal={Proceedings International Conference on Automated Planning and Scheduling, ICAPS},
year={2018},
volume={2018-June},
pages={446-450},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054977317&partnerID=40&md5=8bcca6052a876fb479841675e2dec783},
affiliation={Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, United States},
abstract={Recent progress in legged locomotion research has produced robots that can perform agile blind-walking with robustness comparable to a blindfolded human. However, this walking approach has not yet been integrated with planners for high-level activities. In this paper, we take a step towards high-level task planning for these robots by studying a planar simulated biped that captures their essential dynamics. We investigate variants of Monte-Carlo Tree Search (MCTS) for selecting an appropriate blind-walking controller at each decision cycle. In particular, we consider UCT with an intelligently selected rollout policy, which is shown to be capable of guiding the biped through treacherous terrain. In addition, we develop a new MCTS variant, called Monte-Carlo Discrepancy Search (MCDS), which is shown to make more effective use of limited planning time than UCT for this domain. We demonstrate the effectiveness of these planners in both deterministic and stochastic environments across a range of algorithm parameters. In addition, we present results for using these planners to control a full-order 3D simulation of Cassie, an agile bipedal robot, through complex terrain. Copyright © 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Chang201866,
author={Chang, N. and Pan, S. and Srinivasan, K. and Feng, Z. and Xia, W. and Pawlak, T. and Geb, D.},
title={Emerging ADAS Thermal Reliability Needs and Solutions},
journal={IEEE Micro},
year={2018},
volume={38},
number={1},
pages={66-81},
doi={10.1109/MM.2018.112130058},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041692395&doi=10.1109%2fMM.2018.112130058&partnerID=40&md5=a0f11904df96aa948ebec1938ece3cf2},
affiliation={University of California, Berkeley, CA, United States},
abstract={Advanced driver assistance systems (ADASs) used for pedestrian detection, parking assist, night vision, blind-spot monitoring, collision avoidance, and other such capabilities have significantly enhanced car safety and reduced the risk of dangerous accidents. Their further evolution into a network of intelligent systems using vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communications is paving the way for autonomous driving. To support these advanced technologies, automotive electronics must be overhauled to enable machine learning capabilities, particularly deep learning, to transform the typical car into a smart system on wheels. Thermal reliability is critical because these high-power, intelligent electronics systems must last more than 10 years under often hostile thermal environments. This article presents an innovative multiphysics solution for thermal, thermal-aware electromigration, and thermal-induced stress analysis of a chip-package-system realized in 3DIC, an example of which is an AI system used in ADAS. © 2017 IEEE.},
author_keywords={automotive computing;  hardware;  robotics},
document_type={Article},
source={Scopus},
}

@ARTICLE{Wang201820,
author={Wang, J. and Bartels, J. and Whittaker, W. and Sankaranarayanan, A.C. and Narasimhan, S.G.},
title={Programmable Triangulation Light Curtains},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11207 LNCS},
pages={20-35},
doi={10.1007/978-3-030-01219-9_2},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055086020&doi=10.1007%2f978-3-030-01219-9_2&partnerID=40&md5=a3649865db700704fc3b88e652a072a1},
affiliation={Carnegie Mellon University, Pittsburgh, PA  15213, United States},
abstract={A vehicle on a road or a robot in the field does not need a full-featured 3D depth sensor to detect potential collisions or monitor its blind spot. Instead, it needs to only monitor if any object comes within its near proximity which is an easier task than full depth scanning. We introduce a novel device that monitors the presence of objects on a virtual shell near the device, which we refer to as a light curtain. Light curtains offer a light-weight, resource-efficient and programmable approach to proximity awareness for obstacle avoidance and navigation. They also have additional benefits in terms of improving visibility in fog as well as flexibility in handling light fall-off. Our prototype for generating light curtains works by rapidly rotating a line sensor and a line laser, in synchrony. The device is capable of generating light curtains of various shapes with a range of 20–30 m in sunlight (40 m under cloudy skies and 50 m indoors) and adapts dynamically to the demands of the task. We analyze properties of light curtains and various approaches to optimize their thickness as well as power requirements. We showcase the potential of light curtains using a range of real-world scenarios. © 2018, Springer Nature Switzerland AG.},
author_keywords={Computational imaging;  Proximity sensors},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20181,
title={5th International Conference on Man-Machine Interactions, ICMMI 2017},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={659},
pages={1-592},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030781966&partnerID=40&md5=4df79cf9a65856cd567664b343f5dc2e},
abstract={The proceedings contain 56 papers. The special focus in this conference is on Man-Machine Interactions. The topics include: Deep learning with dense random neural networks; a perceptually inspired method for enhancing contrast in uneven lighting images.; advances in hand-eye robot interactions; human perception of the pattern strength measure; typing braille code in the air with the leap motion controller; touchless virtual keyboard controlled by eye blinking and EEG signals; an alternative virtual keyboard for blind people; how increasing machine agency affects human agency; eye movement traits in differentiating experts and laymen; mobile application using embedded sensors as a three dimensional motion registration method; virtual reality application to study the visual influences on human balance; improvements in DNA reads correction; semantic-based clustering of gene ontology terms on the biotest platform; comparative analysis of MicroRNA-target gene interaction prediction algorithms based on integrated P-value calculation; searching through scientific PDF files supported by bi-clustering of key terms matrices.; searching for cancer signatures using data mining techniques; consensus approach for detection of cancer somatic mutations; cancer clonal evolution simulation program; image denoising using backward stochastic differential equations; gabor filters generalization based on ateb-functions for information security; hierarchical agglomerative clustering of time-warped series; averaging of nonlinearly aligned evoked potentials in impulsive noise environment; linguistically described covariance matrix estimation; DBpedia and YAGO as knowledge base for natural language based question answering - the evaluation and expressing the notion of a mathematical structure in the formal language of mizar.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={18th International Conference on Algorithms and Architectures for Parallel Processing, ICA3PP 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11335 LNCS},
page_count={2619},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058654442&partnerID=40&md5=2859ea76aadef57f17c3d1fdf976eb06},
abstract={The proceedings contain 191 papers. The special focus in this conference is on Algorithms and Architectures for Parallel Processing. The topics include: Incentivizing multimedia data acquisition for machine learning system; Toward performance prediction for multi-BSP programs in ML; exploiting the table of energy and power leverages; a semantic web based intelligent IoT model; Accelerating CNNs using optimized scheduling strategy; data analysis of blended learning in python programming; APs deployment optimization for indoor fingerprint positioning with adaptive particle swarm algorithm; deployment optimization of indoor positioning signal sources with fireworks algorithm; a study of sleep stages threshold based on multiscale fuzzy entropy; qoS-driven service matching algorithm based on user requirements; Blind estimation algorithm over fast-fading multipath OFDM channels; facial shape and expression transfer via non-rigid image deformation; p-schedule: Erasure coding schedule strategy in big data storage system; Answer aggregation of crowdsourcing employing an improved EM-based approach; a parallel fast fourier transform algorithm for large-scale signal data using apache spark in cloud; task offloading in edge-clouds with budget constraint; motion trajectory sequence-based map matching assisted indoor autonomous mobile robot positioning; towards the independent spanning trees in the line graphs of interconnection networks; POEM: Pricing longer for edge computing in the device cloud; mobility analysis and response for software-defined internet of things; Research on overload classification method for bus images based on image processing and SVM; DStore: A distributed cloud storage system based on smart contracts and blockchain; towards an efficient and real-time scheduling platform for mobile charging vehicles; Streaming ETL in polystore era.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={18th International Conference on Algorithms and Architectures for Parallel Processing, ICA3PP 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11334 LNCS},
page_count={2619},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058646688&partnerID=40&md5=c58db9c354474fa3a6c914cb44ddd077},
abstract={The proceedings contain 191 papers. The special focus in this conference is on Algorithms and Architectures for Parallel Processing. The topics include: Incentivizing multimedia data acquisition for machine learning system; Toward performance prediction for multi-BSP programs in ML; exploiting the table of energy and power leverages; a semantic web based intelligent IoT model; Accelerating CNNs using optimized scheduling strategy; data analysis of blended learning in python programming; APs deployment optimization for indoor fingerprint positioning with adaptive particle swarm algorithm; deployment optimization of indoor positioning signal sources with fireworks algorithm; a study of sleep stages threshold based on multiscale fuzzy entropy; qoS-driven service matching algorithm based on user requirements; Blind estimation algorithm over fast-fading multipath OFDM channels; facial shape and expression transfer via non-rigid image deformation; p-schedule: Erasure coding schedule strategy in big data storage system; Answer aggregation of crowdsourcing employing an improved EM-based approach; a parallel fast fourier transform algorithm for large-scale signal data using apache spark in cloud; task offloading in edge-clouds with budget constraint; motion trajectory sequence-based map matching assisted indoor autonomous mobile robot positioning; towards the independent spanning trees in the line graphs of interconnection networks; POEM: Pricing longer for edge computing in the device cloud; mobility analysis and response for software-defined internet of things; Research on overload classification method for bus images based on image processing and SVM; DStore: A distributed cloud storage system based on smart contracts and blockchain; towards an efficient and real-time scheduling platform for mobile charging vehicles; Streaming ETL in polystore era.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={18th International Conference on Algorithms and Architectures for Parallel Processing, ICA3PP 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11337 LNCS},
page_count={2619},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058644211&partnerID=40&md5=0af58d75e405127632b2278527599dbc},
abstract={The proceedings contain 191 papers. The special focus in this conference is on Algorithms and Architectures for Parallel Processing. The topics include: Incentivizing multimedia data acquisition for machine learning system; Toward performance prediction for multi-BSP programs in ML; exploiting the table of energy and power leverages; a semantic web based intelligent IoT model; Accelerating CNNs using optimized scheduling strategy; data analysis of blended learning in python programming; APs deployment optimization for indoor fingerprint positioning with adaptive particle swarm algorithm; deployment optimization of indoor positioning signal sources with fireworks algorithm; a study of sleep stages threshold based on multiscale fuzzy entropy; qoS-driven service matching algorithm based on user requirements; Blind estimation algorithm over fast-fading multipath OFDM channels; facial shape and expression transfer via non-rigid image deformation; p-schedule: Erasure coding schedule strategy in big data storage system; Answer aggregation of crowdsourcing employing an improved EM-based approach; a parallel fast fourier transform algorithm for large-scale signal data using apache spark in cloud; task offloading in edge-clouds with budget constraint; motion trajectory sequence-based map matching assisted indoor autonomous mobile robot positioning; towards the independent spanning trees in the line graphs of interconnection networks; POEM: Pricing longer for edge computing in the device cloud; mobility analysis and response for software-defined internet of things; Research on overload classification method for bus images based on image processing and SVM; DStore: A distributed cloud storage system based on smart contracts and blockchain; towards an efficient and real-time scheduling platform for mobile charging vehicles; Streaming ETL in polystore era.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={18th International Conference on Algorithms and Architectures for Parallel Processing, ICA3PP 2018},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2018},
volume={11336 LNCS},
page_count={2619},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058631696&partnerID=40&md5=d57ed181a8d3b6f8d8ab2a83d82d1819},
abstract={The proceedings contain 191 papers. The special focus in this conference is on Algorithms and Architectures for Parallel Processing. The topics include: Incentivizing multimedia data acquisition for machine learning system; Toward performance prediction for multi-BSP programs in ML; exploiting the table of energy and power leverages; a semantic web based intelligent IoT model; Accelerating CNNs using optimized scheduling strategy; data analysis of blended learning in python programming; APs deployment optimization for indoor fingerprint positioning with adaptive particle swarm algorithm; deployment optimization of indoor positioning signal sources with fireworks algorithm; a study of sleep stages threshold based on multiscale fuzzy entropy; qoS-driven service matching algorithm based on user requirements; Blind estimation algorithm over fast-fading multipath OFDM channels; facial shape and expression transfer via non-rigid image deformation; p-schedule: Erasure coding schedule strategy in big data storage system; Answer aggregation of crowdsourcing employing an improved EM-based approach; a parallel fast fourier transform algorithm for large-scale signal data using apache spark in cloud; task offloading in edge-clouds with budget constraint; motion trajectory sequence-based map matching assisted indoor autonomous mobile robot positioning; towards the independent spanning trees in the line graphs of interconnection networks; POEM: Pricing longer for edge computing in the device cloud; mobility analysis and response for software-defined internet of things; Research on overload classification method for bus images based on image processing and SVM; DStore: A distributed cloud storage system based on smart contracts and blockchain; towards an efficient and real-time scheduling platform for mobile charging vehicles; Streaming ETL in polystore era.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor2018,
title={17th International Conference on Intelligent Systems Design and Applications, ISDA 2017},
journal={Advances in Intelligent Systems and Computing},
year={2018},
volume={736},
page_count={1051},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044445860&partnerID=40&md5=f5d6ada2c4f6d1530d7d39bac5fa3204},
abstract={The proceedings contain 100 papers. The special focus in this conference is on . The topics include: A Study of the Privacy Attitudes of the Users of the Social Network(ing) Sites and Their Expectations from the Law in India; CRF+LG: A Hybrid Approach for the Portuguese Named Entity Recognition; a Secure and Efficient Temporal Features Based Framework for Cloud Using MapReduce; a Comparison of Machine Learning Methods to Identify Broken Bar Failures in Induction Motors Using Statistical Moments; canonical Correlation-Based Feature Fusion Approach for Scene Classification; a Mixed-Integer Linear Programming Model and a Simulated Annealing Algorithm for the Long-Term Preventive Maintenance Scheduling Problem; interval Valued Feature Selection for Classification of Logo Images; an Hierarchical Framework for Classroom Events Classification; hand Gesture Recognition System Based on Local Binary Pattern Approach for Mobile Devices; an Efficient Real-Time Approach for Detection of Parkinson’s Disease; UML2ADA for Early Verification of Concurrency Inside the UML2.0 Atomic Components; dual Image Encryption Technique: Using Logistic Map and Noise; a Memetic Algorithm for the Network Construction Problem with Due Dates; incremental Real Time Support Vector Machines; content-Based Classification Approach for Video-Spam Identification; Kinematic Analysis and Simulation of a 6 DOF Robot in a Web-Based Platform Using CAD File Import; Large Scale Deep Network Architecture of CNN for Unconstraint Visual Activity Analytics; an Automated Support Tool to Compute State Redundancy Semantic Metric; computing Theory Prime Implicates in Modal Logic; fault Tolerance in Real-Time Systems: A Review; gauss-Newton Representation Based Algorithm for Magnetic Resonance Brain Image Classification; blind Write Protocol.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Marques20171,
author={Marques, G.H.M. and Einloft, D.C. and Bergamin, A.C.P. and Marek, J.A. and Maidana, R.G. and Campos, M.B. and Manssour, I.H. and Amory, A.M.},
title={Donnie robot: Towards an accessible and educational robot for visually impaired people},
journal={Proceedings - 2017 LARS 14th Latin American Robotics Symposium and 2017 5th SBR Brazilian Symposium on Robotics, LARS-SBR 2017 - Part of the Robotics Conference 2017},
year={2017},
volume={2017-December},
pages={1-6},
doi={10.1109/SBR-LARS-R.2017.8215273},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048501154&doi=10.1109%2fSBR-LARS-R.2017.8215273&partnerID=40&md5=c608ecdd3ce6e45fa86b457c03cba8a8},
affiliation={PUCRS University, Faculdade de Informatica, Porto Alegre, RS, Brazil},
abstract={Robotics has been used to draw the attention of young students to computing and engineering. Unfortunately, most hardware and software resources used to teach programming and robotics are not adequate for students with visual impairment (VI). For instance, most programming environments for young students are highly visual and the commercial robotics kits were not built for people with VI. This paper describes the main design requirements so that both the proposed robot hardware and the software can also be used by people with VI. The hardware part is the focus of this paper, a robot called Donnie. It consists of open hardware, a design with low-cost and easy to find parts, and a 3D printed structure. Our main contribution is the presentation of a low-cost Arduino-based robot, compatible with Player robotic framework and integrated with sound feedback and text-to-speech. © 2017 IEEE.},
author_keywords={Assistive Robotics;  Audio-based navigation;  Blind Programmers;  Educational Robotics},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Zhang20173603,
author={Zhang, F. and Cully, A. and Demiris, Y.},
title={Personalized robot-assisted dressing using user modeling in latent spaces},
journal={IEEE International Conference on Intelligent Robots and Systems},
year={2017},
volume={2017-September},
pages={3603-3610},
doi={10.1109/IROS.2017.8206206},
art_number={8206206},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041947852&doi=10.1109%2fIROS.2017.8206206&partnerID=40&md5=f77ee2d10770ca7dcf9eb9c92726b355},
affiliation={Personal Robotics Lab, Department of Electrical and Electronic Engineering, Imperial College London, United Kingdom},
abstract={Robots have the potential to provide tremendous support to disabled and elderly people in their everyday tasks, such as dressing. Many recent studies on robotic dressing assistance usually view dressing as a trajectory planning problem. However, the user movements during the dressing process are rarely taken into account, which often leads to the failures of the planned trajectory and may put the user at risk. The main difficulty of taking user movements into account is caused by severe occlusions created by the robot, the user, and the clothes during the dressing process, which prevent vision sensors from accurately detecting the postures of the user in real time. In this paper, we address this problem by introducing an approach that allows the robot to automatically adapt its motion according to the force applied on the robot's gripper caused by user movements. There are two main contributions introduced in this paper: 1) the use of a hierarchical multi-task control strategy to automatically adapt the robot motion and minimize the force applied between the user and the robot caused by user movements; 2) the online update of the dressing trajectory based on the user movement limitations modeled with the Gaussian Process Latent Variable Model in a latent space, and the density information extracted from such latent space. The combination of these two contributions leads to a personalized dressing assistance that can cope with unpredicted user movements during the dressing while constantly minimizing the force that the robot may apply on the user. The experimental results demonstrate that the proposed method allows the Baxter humanoid robot to provide personalized dressing assistance for human users with simulated upper-body impairments. © 2017 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={2017 IEEE Long Island Systems, Applications and Technology Conference, LISAT 2017},
journal={2017 IEEE Long Island Systems, Applications and Technology Conference, LISAT 2017},
year={2017},
page_count={223},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028583598&partnerID=40&md5=8505336d1801fc6f917feab5ecc4d053},
abstract={The proceedings contain 39 papers. The topics discussed include: BIONIC EGG: sealed mobile sensor packaging design with adaptive power consumption; comparison of autoencoder and principal component analysis followed by neural network for e-learning using handwritten recognition; lateropulsion rehabilitation using virtual reality for stroke patients; immersive virtual reality for individuals with spinal cord injuries; finding partial hash collisions by brute force parallel programming; finding hash collisions using MPI on HPC clusters; Linux kernel OS local root exploit; biometrics: password replacement for elderly?; ZigBee network using low power techniques and modified leach protocol; rolled versus plain fingerprints: matching with cryptographic one-way hashes; secure transmission with matrix encryption and data compression mechanism; lidar for Scribbler 2 enhancing sensing capabilities in an educational robot; design of a broadband finline filter; QKD protocol based on entangled states by trusted third party; cybersecurity in the age of autonomous vehicles, intelligent traffic controls and pervasive transportation networks; blind digital signature schemes with four particle entanglement states; reader leveled RFID localization approaches and their simulation; and video steganography techniques: taxonomy, challenges, and future directions.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Thomaier20173279,
author={Thomaier, L. and Orlando, M. and Abernethy, M. and Paka, C. and Chen, C.C.G.},
title={Laparoscopic and robotic skills are transferable in a simulation setting: a randomized controlled trial},
journal={Surgical Endoscopy},
year={2017},
volume={31},
number={8},
pages={3279-3285},
doi={10.1007/s00464-016-5359-y},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001799470&doi=10.1007%2fs00464-016-5359-y&partnerID=40&md5=2f8a20bedc766ed84834c96853d2034d},
affiliation={Department of Gynecology and Obstetrics, Johns Hopkins Hospital, Baltimore, MD, United States; Division of Female Pelvic Medicine and Reconstructive Surgery, Department of Gynecology and Obstetrics, Johns Hopkins University School of Medicine, 301 Mason Lord Drive, Suite 3200, Baltimore, MD  21224, United States},
abstract={Background: Although surgical simulation provides an effective supplement to traditional training, it is not known whether skills are transferable between minimally invasive surgical modalities. The purpose of this study was to assess the transferability of skills between minimally invasive surgical simulation platforms among simulation-naïve participants. Methods: Forty simulation-naïve medical students were enrolled in this randomized single-blinded controlled trial. Participants completed a baseline evaluation on laparoscopic (Fundamentals of Laparoscopic Surgery Program, Los Angeles, CA) and robotic (dV-Trainer, Mimic, Seattle, WA) simulation peg transfer tasks. Participants were then randomized to perform a practice session on either the robotic (N = 20) or laparoscopic (N = 20) simulator. Two blinded, expert minimally invasive surgeons evaluated participants before and after training using a modified previously validated subjective global rating scale. Objective measures including time to task completion and Mimic dV-Trainer motion metrics were also recorded. Results: At baseline, there were no significant differences between the training groups as measured by objective and subjective measures for either simulation task. After training, participants randomized to the laparoscopic practice group completed the laparoscopic task faster (p < 0.003) and with higher global rating scale scores (p < 0.001) than the robotic group. Robotic-trained participants performed the robotic task faster (p < 0.001), with improved economy of motion (p < 0.001), and with higher global rating scale scores (p = 0.006) than the laparoscopic group. The robotic practice group also demonstrated significantly improved performance on the laparoscopic task (p = 0.02). Laparoscopic-trained participants also improved their robotic performance (p = 0.02), though the robotic group had a higher percent improvement on the robotic task (p = 0.037). Conclusions: Skills acquired through practice on either laparoscopic or robotic simulation platforms appear to be transferable between modalities. However, participants demonstrate superior skill in the modality in which they specifically train. © 2016, Springer Science+Business Media New York.},
author_keywords={Laparoscopy;  Robotic skills;  Simulation;  Surgical simulation;  Surgical training},
document_type={Article},
source={Scopus},
}

@ARTICLE{Mengoni2017,
author={Mengoni, S.E. and Irvine, K. and Thakur, D. and Barton, G. and Dautenhahn, K. and Guldberg, K. and Robins, B. and Wellsted, D. and Sharma, S.},
title={Feasibility study of a randomised controlled trial to investigate the effectiveness of using a humanoid robot to improve the social skills of children with autism spectrum disorder (Kaspar RCT): A study protocol},
journal={BMJ Open},
year={2017},
volume={7},
number={6},
doi={10.1136/bmjopen-2017-017376},
art_number={e017376},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021220443&doi=10.1136%2fbmjopen-2017-017376&partnerID=40&md5=a80ed0f26956241d177c96bafbf06eda},
affiliation={Centre for Health Services and Clinical Research, Department of Psychology and Sport Sciences, School of Life and Medical Sciences, University of Hertfordshire, Hatfield, United Kingdom; Hertfordshire Community NHS Trust, Welwyn Garden, Hertfordshire, United Kingdom; Health Economics Group, Norwich Medical School, University of East Anglia, Norwich, United Kingdom; School of Computer Science, University of Hertfordshire, Hatfield, United Kingdom; Autism Centre for Education and Research, School of Education, University of Birmingham, Birmingham, United Kingdom},
abstract={Introduction: Interventions using robot-assisted therapy may be beneficial for the social skills development of children with autism spectrum disorder (ASD); however, randomised controlled trials (RCTs) are lacking. The present research aims to assess the feasibility of conducting an RCT evaluating the effectiveness of a social skills intervention using Kinesics and Synchronisation in Personal Assistant Robotics (Kaspar) with children with ASD. Methods and analysis: Forty children will be recruited. Inclusion criteria are the following: aged 5-10 years, confirmed ASD diagnosis, IQ over 70, English-language comprehension, a carer who can complete questionnaires in English and no current participation in a private social communication intervention. Children will be randomised to receive an intervention with a therapist and Kaspar, or with the therapist only. They will receive two familiarisation sessions and six treatment sessions for 8 weeks. They will be assessed at baseline, and at 10 and 22 weeks after baseline. The primary outcome of this study is to evaluate whether the predetermined feasibility criteria for a full-scale trial are met. The potential primary outcome measures for a full-scale trial are the Social Communication Questionnaire and the Social Skills Improvement System. We will conduct a preliminary economic analysis. After the study has ended, a sample of 20 participants and their families will be invited to participate in semistructured interviews to explore the feasibility and acceptability of the study's methods and intervention. Ethics and dissemination: Parents/carers will provide informed consent, and children will give assent, where appropriate. Care will be taken to avoid pressure or coercion to participate. Aftercare is available from the recruiting NHS Trust, and a phased withdrawal protocol will be followed if children become excessively attached to the robot. The results of the study will be disseminated to academic audiences and non-academic stakeholders, for example, families of children with ASD, support groups, clinicians and charities. © 2017 Article author(s). All rights reserved.},
author_keywords={child & adolescent psychiatry;  community child health;  developmental neurology & neurodisability},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={2017 Conference on Information Communication Technology and Society, ICTAS 2017 - Proceedings},
journal={2017 Conference on Information Communication Technology and Society, ICTAS 2017 - Proceedings},
year={2017},
page_count={161},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019986610&partnerID=40&md5=a33c4aeaddb71f22000af4790a543933},
abstract={The proceedings contain 25 papers. The topics discussed include: developing e-examination voice interface for visually impaired students in open and distance learning context; using a user experience evaluation framework for e-moderation; student perception of the contribution of hackathon and collaborative learning approach on computer programming pass rate; acceptance and usage of learning management systems amongst academics; initiating a pipeline for the computer industry using scratch and Lego robotics; a framework for assessing the socio-economic impact of e-governance projects in developing countries; mobile search interfaces for isiXhosa speakers: a comparison between voice and text; and examining the evolution of mobile bully-victims across different schools located in low to high safety risk areas in Cape Town, South Africa.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Broad2017,
author={Broad, A. and Arkin, J. and Ratliff, N. and Howard, T. and Argall, B.},
title={Real-time natural language corrections for assistive robotic manipulators},
journal={International Journal of Robotics Research},
year={2017},
doi={10.1177/0278364917706418},
note={cited By 2; Article in Press},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044069877&doi=10.1177%2f0278364917706418&partnerID=40&md5=19666a507ab3fddd96da5537ce00eae4},
affiliation={Department of Electrical Engineering and Computer Science, Northwestern University, USA, United States; Rehabilitation Institute of Chicago, USA, United States; Department of Computer Science, University of Rochester, USA, United States; Lula Robotics Inc., USA, United States},
abstract={We propose a generalizable natural language interface that allows users to provide corrective instructions to an assistive robotic manipulator in real-time. This work is motivated by the desire to improve collaboration between humans and robots in a home environment. Allowing human operators to modify properties of how their robotic counterpart achieves a goal on-the-fly increases the utility of the system by incorporating the strengths of the human partner (e.g. visual acuity and environmental knowledge). This work is applicable to users with and without disability. Our natural language interface is based on the distributed correspondence graph, a probabilistic graphical model that assigns semantic meaning to user utterances in the context of the robot’s environment and current behavior. We then use the desired corrections to alter the behavior of the robotic manipulator by treating the modifications as constraints on the motion generation (planning) paradigm. In this paper, we highlight four dimensions along which a user may wish to correct the behavior of his or her assistive manipulator. We develop our language model using data collected from Amazon Mechanical Turk to capture a comprehensive sample of terminology that people use to describe desired corrections. We then develop an end-to-end system using open-source speech-to-text software and a Kinova Robotics MICO robotic arm. To demonstrate the efficacy of our approach, we run a pilot study with users unfamiliar with robotic systems and analyze points of failure and future directions. © 2017, The Author(s) 2017.},
author_keywords={assistive robotics;  constrained motion planning;  Human–robot interaction;  natural language processing},
document_type={Article in Press},
source={Scopus},
}

@ARTICLE{Huang2017,
author={Huang, C. and Fei, J. and Liu, Y. and Li, H. and Liu, X.},
title={Smooth Path Planning Method Based on Dynamic Feedback A* Ant Colony Algorithm},
journal={Nongye Jixie Xuebao/Transactions of the Chinese Society for Agricultural Machinery},
year={2017},
volume={48},
number={4},
pages={34-40 and 102},
doi={10.6041/j.issn.1000-1298.2017.04.004},
note={cited By 6},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025065482&doi=10.6041%2fj.issn.1000-1298.2017.04.004&partnerID=40&md5=2be187fde3e69390a53cbbb291269306},
affiliation={College of Mechanical Engineering, Dalian Jiaotong University, Dalian, 116028, China; College of Bullet Train Application and Maintenance Engineering, Dalian Jiaotong University, Dalian, 116028, China; College of Engineering, Pukyong National University, Busan, 608737, South Korea},
abstract={A smooth path planning method for mobile robot with A* ant colony optimization was proposed based on dynamic feedback for mobile robot. First of all, in order to overcome the disadvantage about slow convergence speed of ant colony algorithm, simplified A* algorithm was presented to optimize the initial pheromone settings, which was able to solve the blindness of the first search. In this step, the planning path with the minimum value of the valuation function was obtained by the evaluation function of A* algorithm. And the presented multi-evolutionary strategy mechanism which could increase search space was used to strengthen the global search ability of the algorithm. Secondly, in order to further improve the adaptability of algorithm about the problem of local minimum and stagnation in the path planning, the key parameters of the algorithm were systematically analyzed and the closed-loop feedback idea was adopted to adjust the parameters of ant colony optimization algorithm dynamically. Finally, combining with the cubic B spline curve method, the planning path was smoothed to meet the practical movement route of mobile robot. The simulation experiment results showed that compared with traditional ant colony (AC), A* ant colony optimization based on dynamic feedback could reduce 10.4% of the average path cost and shorten 65.8% of the computing time in average. In addition, compared with ant colony system (ACS), the average path cost could be reduced by 5.9%, the calculation time could be shortened by 52.6%. The improved ant colony optimization algorithm could plan a smooth and high quality path in both the dynamic and static environments. © 2017, Chinese Society of Agricultural Machinery. All right reserved.},
author_keywords={A* algorithm;  Ant colony algorithm;  B spline curve;  Dynamic feedback;  Path planning},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Paramasivam2017447,
author={Paramasivam, V. and Huang, J. and Elliott, S. and Cakmak, M.},
title={Computer science outreach with end-user robot-programming tools},
journal={Proceedings of the Conference on Integrating Technology into Computer Science Education, ITiCSE},
year={2017},
pages={447-452},
doi={10.1145/3017680.3017796},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018248929&doi=10.1145%2f3017680.3017796&partnerID=40&md5=90b51d9e246a7a56f7b3c3aaba48e51b},
affiliation={Computer Science and Engineering, University of Washington, 185 Stevens Way, Seattle, WA  98195, United States},
abstract={Robots are becoming popular in Computer Science outreach to K-12 students. Easy-To-program toy robots already exist as commercial educational products. These toys take advantage of the increased interest and engagement resulting from the ability to write code that makes a robot physically move. However, toy robots do not demonstrate the potential of robots to carry out useful everyday tasks. On the other hand, functional robots are often dificult to program even for professional software developers or roboticists. In this work, we apply end-user programming tools for functional robots to the Computer Science outreach context. This experience report describes two offerings of a week-long introductory workshop in which students with various disabilities learned to program a Clearpath Turtlebot, capable of delivering items, interacting with people via touchscreen, and autonomously navigating its environment. We found that the robot and the end-user programming tool that we developed in previous work were successful in provoking interest in Computer Science among both groups of students and in establishing confidence among students that programming is both accessible and interesting. We present key observa-Tions from the workshops, lessons learned, and suggestions for readers interested in employing a similar approach. © 2017 ACM.},
author_keywords={Accessibility;  End-User programming;  Outreach;  Robotics},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Barros2017517,
author={Barros, R.P. and Burlamaqui, A.M.F. and Azevedo, S.O. and Sá, S.T. and Gonçalves, L.M.G. and Burlamaqui, A.A.R.S.},
title={CardBot-Assistive Technology for Visually Impaired in Educational Robotics: Experiments and Results},
journal={IEEE Latin America Transactions},
year={2017},
volume={15},
number={3},
pages={517-527},
doi={10.1109/TLA.2017.7867603},
art_number={7867603},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015231495&doi=10.1109%2fTLA.2017.7867603&partnerID=40&md5=886b64b2c5c923a7561c383957722c4d},
affiliation={Universidade Federal Do Rio Grande Do Norte), Natal, RN, Brazil; Universidade Federal Rural Do Semi-Árido (UFERSA), Angicos, RN, Brazil; Instituto Federal de Educação Ciência e Tecnologia Do Rio Grande Do Norte, Parelhas, RN, Brazil; Universidade Federal Rural Do Semi-Árido, Angicos, RN, Brazil},
abstract={We proposes an educational assistive methodology aiming to provide the access to educational robotics activities to students with visual impairments or low vision. As an approach to soften the main issues related to this challenging problem, we introduce a low cost, assistive technology, called CardBot 2.0. Basically, this model for teaching-learning is composed by a programming environment, a mobile application, and several geometric cards, each of them representing a specific action that is recognized by the application with a tag. So, the student can program the robot by selecting and organizing geometric cards on the surface of a board or on a table. Also a contribution of this work being part of the solution, the professor can create new cards and register the respective actions and tags. This allows the professor to add new actions for the robot or even to create a new language. We validated our approach by performing experimental classes for students with different visual impairments and ages, and for students without impairment, with an analysis of the results, qualitative. © 2003-2012 IEEE.},
author_keywords={Assistive Technologies;  Educational Robotics;  Visual Impairments},
document_type={Article},
source={Scopus},
}

@ARTICLE{Straudi2017,
author={Straudi, S. and Manfredini, F. and Lamberti, N. and Zamboni, P. and Bernardi, F. and Marchetti, G. and Pinton, P. and Bonora, M. and Secchiero, P. and Tisato, V. and Volpato, S. and Basaglia, N.},
title={The effectiveness of Robot-Assisted Gait Training versus conventional therapy on mobility in severely disabled progressIve MultiplE sclerosis patients (RAGTIME): Study protocol for a randomized controlled trial},
journal={Trials},
year={2017},
volume={18},
number={1},
doi={10.1186/s13063-017-1838-2},
art_number={88},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014078788&doi=10.1186%2fs13063-017-1838-2&partnerID=40&md5=5d3b5b805c84ab7f7dc79b082ff2c1ee},
affiliation={Ferrara University Hospital, Neuroscience and Rehabilitation Department, Via Aldo Moro 8, Ferrara, 44124, Italy; University of Ferrara, Department of Biomedical and Specialty Surgical Sciences, Ferrara, Italy; Ferrara University Hospital, Unit of Translational Surgery and Vascular Diseases Center, Ferrara, Italy; University of Ferrara, Department of Life Sciences and Biotechnology, Ferrara, Italy; University of Ferrara, Department of Morphology, Surgery and Experimental Medicine, Section of Pathology, Oncology and Experimental Biology, Laboratory for Technologies of Advanced Therapies (LTTA), Ferrara, Italy; University of Ferrara, Department of Morphology, Surgery and Experimental Medicine, Section of Anatomy and Histology, Laboratory for Technologies of Advanced Therapies (LTTA), Ferrara, Italy; University of Ferrara, Center for Clinical Epidemiology, School of Medicine, Ferrara, Italy},
abstract={Background: Gait and mobility impairments affect the quality of life (QoL) of patients with progressive multiple sclerosis (MS). Robot-assisted gait training (RAGT) is an effective rehabilitative treatment but evidence of its superiority compared to other options is lacking. Furthermore, the response to rehabilitation is multidimensional, person-specific and possibly involves functional reorganization processes. The aims of this study are: (1) to test the effectiveness on gait speed, mobility, balance, fatigue and QoL of RAGT compared to conventional therapy (CT) in progressive MS and (2) to explore changes of clinical and circulating biomarkers of neural plasticity. Methods: This will be a parallel-group, randomized controlled trial design with the assessor blinded to the group allocation of participants. Ninety-eight (49 per arm) progressive MS patients (EDSS scale 6-7) will be randomly assigned to receive twelve 2-h training sessions over a 4-week period (three sessions/week) of either: (1) RAGT intervention on a robotic-driven gait orthosis (Lokomat, Hocoma, Switzerland). The training parameters (torque of the knee and hip drives, treadmill speed, body weight support) are set during the first session and progressively adjusted during training progression or (2) individual conventional physiotherapy focusing on over-ground walking training performed with the habitual walking device. The same assessors will perform outcome measurements at four time points: baseline (before the first intervention session); intermediate (after six training sessions); end of treatment (after the completion of 12 sessions); and follow-up (after 3 months from the end of the training program). The primary outcome is gait speed, assessed by the Timed 25-Foot Walk Test. We will also assess walking endurance, balance, depression, fatigue and QoL as well as instrumental laboratory markers (muscle metabolism, cerebral venous hemodynamics, cortical activation) and circulating laboratory markers (rare circulating cell populations pro and anti-inflammatory cytokines/chemokines, growth factors, neurotrophic factors, coagulation factors, other plasma proteins suggested by transcriptomic analysis and metabolic parameters). Discussion: The RAGT training is expected to improve mobility compared to the active control intervention in progressive MS. Unique to this study is the analysis of various potential markers of plasticity in relation with clinical outcomes. Trial registration: ClinicalTrials.gov, identifier: NCT02421731. Registered on 19 January 2015 (retrospectively registered). © 2017 The Author(s).},
author_keywords={Biological markers;  Mobility;  Motor recovery;  Plasticity;  Progressive multiple sclerosis;  Rehabilitation;  Robot-assisted gait training},
document_type={Article},
source={Scopus},
}

@ARTICLE{Takakusaki20172,
author={Takakusaki, K. and Takahashi, M. and Obara, K. and Chiba, R.},
title={Neural substrates involved in the control of posture},
journal={Advanced Robotics},
year={2017},
volume={31},
number={1-2},
pages={2-23},
doi={10.1080/01691864.2016.1252690},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002339056&doi=10.1080%2f01691864.2016.1252690&partnerID=40&md5=b84c37bd3d47a6143b2b9015eb70b589},
affiliation={The Research Center for Brain Function and Medical Engineering, Asahikawa Medical University, Asahikawa, Japan},
abstract={This review argues neuronal mechanisms of postural control. Multi-sensory information such as somatosensory, visual, and vestibular sensation act on various areas of the brain so that adaptable postural control can be achieved. Automatic process of postural control, which is termed as postural reflexes including head–eye coordination accompanied by appropriate alignment of body segments, is mediated by the descending pathways from the brainstem. Cooperation of the vestibulospinal, reticulospinal, and tectospinal tracts contributes to this process. On the other hand, walking in unfamiliar circumstance requires cognitive process of postural control, which depends on knowledge of self-body, such as body schema, sense of postural verticality, and body motion in space. Such a bodily cognitive information is produced at the temporoparietal cortex. They are fundamental to sustention of vertical posture and construction of motor programs. The programs then run to execute anticipatory postural adjustment which is appropriate for achievement of goal-directed movements. The basal ganglia and cerebellum may affect both the automatic and cognitive processes of postural control through reciprocal connections with the brainstem and cerebral cortex, respectively. Consequently, impairments in cognitive function in addition to damages in the motor cortex, basal ganglia, and cerebellum may disturb appropriate postural control, resulting in falling. © 2016 Taylor & Francis and The Robotics Society of Japan.},
author_keywords={anticipatory postural adjustment;  Body schema;  motor programing;  postural reflex;  postural verticality},
document_type={Article},
source={Scopus},
}

@ARTICLE{DamasioOliveira2017155,
author={Damasio Oliveira, J. and de Borba Campos, M. and de Morais Amory, A. and Manssour, I.H.},
title={Teaching robot programming activities for visually impaired students: A systematic review},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10279 LNCS},
pages={155-167},
doi={10.1007/978-3-319-58700-4_14},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025151975&doi=10.1007%2f978-3-319-58700-4_14&partnerID=40&md5=85cb2fac0ec7b17313d8f3fc7b54390d},
affiliation={Faculty of Informatics (FACIN), Pontifical Catholic University of Rio Grande do Sul (PUCRS), Porto Alegre, Brazil},
abstract={This paper presents a systematic review of studies concerning the use of robotics for the programming education of individuals with visual impairment. This study presents a thorough discussion and classification of the surveyed papers, including: different programming teaching methodologies based on robotics for people who are blind; the use of several robotics kits and programming environments; the evaluation procedure for each environment; and the challenges found during the teaching process. Based on these papers we created a guideline to prepare, conduct and evaluate a robot programming workshop for people who are visually impaired. These instructions include, for example, how to train instructors to work in workshops for people with visual disabilities, how to prepare concrete and digital support materials, suggestions of work dynamics for programming teaching, how to conduct collaborative activities, forms of feedback for the student to better understand the syntax and semantics of the language, recommendations for the development of a robotic environment concerning the hardware (robot) and software (programming language to operate the robot). These recommendations were validated with two users with visual impairment. © Springer International Publishing AG 2017.},
author_keywords={Systematic review;  Teaching robot programming;  Visual impairment},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Hemalatha2017262,
author={Hemalatha, P. and Dhanalakshmi, K.},
title={Development of IOT enabled voice recognition robotic guide dog for visually impaired people to enhance the guiding and interacting experience},
journal={Journal of Advanced Research in Dynamical and Control Systems},
year={2017},
volume={9},
pages={262-272},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047443235&partnerID=40&md5=5a46eeffc331c41abbf7c686fdb0c56c},
affiliation={Department of Information Technology, IFET College of Engineering, Villupuram, Tamil nadu  605108, India; Department of Computer Science and Engineering, PSNA College of Engineering, Dindigul, Tamil nadu  624622, India},
abstract={In recent times, advancement in Robotic industry made huge impact on Visual path Guiding Industry, Several Blind Assistive system are suggested by many researchers. However Guiding through the unpredictable ambient environment is difficult task for the mobile Guiding Robots. Internet of Things (IOT) enabled Robot Control is seen as more flexible and effective communication medium in Robotic Industry. In this paper we are suggesting RTOS (Real TimeOperating System) enabled Smart and Multipurpose voice recognition Guiding Robot to guide visually impaired people to Locally Programmed Destination. This Robotic Dog Capable of Recognizing Word Spoken by the User by using Google Voice Recognition API and Operate depend upon the Voice Commands. This Robotic Dog uses the Ultrasonic Sound signals to detect the Obstacles placed in the travelling path. Also it uses Corner Crossing Algorithm to intelligently avoid the Corners in Operating Environment. This robot having ―Watchdog mode, with this mode it acts as a Watch Dog and will warn a user if there is any abnormal Movement in the surface and also it featured with Fire Sensor to warn about the temperature alerts. The robot was designed with self-charging feature, in normal daytime it can capable of finding the sun light by moving around the working location and charge by itself using photovoltaic cells. © 2017, Institute of Advanced Scientific Research, Inc. All rights reserved.},
author_keywords={Blind assistive system;  Comer crossing algorithm;  Fire sensor;  Internet of Things;  Multipurpose voice recognition guiding robot;  Photovoltaic cells;  Real time operating system;  Smart voice recognition guiding robot;  Ultrasonic sound signals;  Watchdog mode},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={4th International Conference on HCI in Business, Government and Organizations, HCIBGO 2017, held as part of the 19th International Conference on Human-Computer Interaction , HCI 2017},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2017},
volume={10296 LNCS},
pages={1-498},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025141015&partnerID=40&md5=161a08b4e91a46fc4f139083b1691772},
abstract={The proceedings contain 75 papers. The special focus in this conference is on HCI in Business, Government and Organizations. The topics include: Using augmented reality interactive system to support digital electronics learning; an AI system for coaching novice programmers; affective walkthroughs and heuristics; a creative engineering experience; manipulation of mathematical expressions in collaborative environments; designing tools that allows children in the early childhood to program robots; decision making for interactive systems; preschool learning with a fingertip; augmentative and alternative communication in the literacy teaching for deaf children; a model for collaboration in virtual worlds bringing together cultures in conflict; challenges of integrating non-traditional students in higher education and how electronic learning can support inclusion; training socially responsible engineers by developing accessible video games; the use of a new visual language as a supporting resource for people with intellectual disabilities; dashboard for actionable feedback on learning skills; learning analytics and spelling acquisition in German; data analysis of coaching and advising in undergraduate students; learning analytics and its paternalistic influences; development of a dashboard for learning analytics in higher education; mixing and matching learning design and learning analytics; a guidance and evaluation approach for mhealth education applications; collaborative hybrid agent provision of learner needs using ontology based semantic technology and designing a peer feedback mobile application as a professional development tool.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={4th International KES conference on Smart Education and Smart e-Learning, SEEL 2017},
journal={Smart Innovation, Systems and Technologies},
year={2017},
volume={75},
pages={1-496},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041778993&partnerID=40&md5=b7bf40adf3658f592cc6e8e8230db96a},
abstract={The proceedings contain 48 papers. The special focus in this conference is on Smart Education and Smart e-Learning. The topics include: Smart pedagogy for smart universities; information channel based measure of effectiveness of computer-assisted assessment in flipped classroom; efforts for upward spirals based on both teacher and student feedback on smart education; a serious game to promote environmental attitude; the development of the critical thinking as strategy for transforming a traditional university into a smart university; RLCP-compatible virtual laboratories with 3D-models and demonstration mode: development and application in e-learning; remote laboratory environments for smart e-learning; an automata model for an adaptive course development; algorithm of contextual information formation for smart learning object; information technologies in musical and art education of children; a SPOC produced by sophomores for their junior counterparts; an outcome-based framework for developing learning trajectories; a simple MVC-framework for local management of online course material; multi-agent smart-system of distance learning for people with vision disabilities; use of smart technologies in the e-learning course project management; approaches to the description of model massive open online course based on the cloud platform in the educational environment of the university; a half-duplex dual-lingual video chat to enhance simultaneous second language speaking skill; a recommender system for supporting students in programming online judges; eye tracking technology for assessment of electronic hybrid text perception by students and motivation of students and young scientists in robotics.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Broad2017684,
author={Broad, A. and Arkin, J. and Ratliff, N. and Howard, T. and Argall, B.},
title={Real-time natural language corrections for assistive robotic manipulators},
journal={International Journal of Robotics Research},
year={2017},
volume={36},
number={5-7},
pages={684-698},
doi={10.1177/0278364917706418},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044212812&doi=10.1177%2f0278364917706418&partnerID=40&md5=eeae8aa63278759d70f6c4dad90e42c9},
affiliation={Department of Electrical Engineering and Computer Science, Northwestern University, United States; Rehabilitation Institute of Chicago, United States; Department of Computer Science, University of Rochester, United States; Lula Robotics Inc., United States},
abstract={We propose a generalizable natural language interface that allows users to provide corrective instructions to an assistive robotic manipulator in real-time. This work is motivated by the desire to improve collaboration between humans and robots in a home environment. Allowing human operators to modify properties of how their robotic counterpart achieves a goal on-the-fly increases the utility of the system by incorporating the strengths of the human partner (e.g. visual acuity and environmental knowledge). This work is applicable to users with and without disability. Our natural language interface is based on the distributed correspondence graph, a probabilistic graphical model that assigns semantic meaning to user utterances in the context of the robot’s environment and current behavior. We then use the desired corrections to alter the behavior of the robotic manipulator by treating the modifications as constraints on the motion generation (planning) paradigm. In this paper, we highlight four dimensions along which a user may wish to correct the behavior of his or her assistive manipulator. We develop our language model using data collected from Amazon Mechanical Turk to capture a comprehensive sample of terminology that people use to describe desired corrections. We then develop an end-to-end system using open-source speech-to-text software and a Kinova Robotics MICO robotic arm. To demonstrate the efficacy of our approach, we run a pilot study with users unfamiliar with robotic systems and analyze points of failure and future directions. © The Author(s) 2017.},
author_keywords={Assistive robotics;  Constrained motion planning;  Human;  Natural language processing;  Robot interaction},
document_type={Article},
source={Scopus},
}

@CONFERENCE{NoAuthor2017,
title={Procedia Computer Science},
journal={Procedia Computer Science},
year={2017},
volume={116},
page_count={651},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039986470&partnerID=40&md5=26d388c1fd87f21bd855b3417c258fc1},
abstract={The proceedings contain 81 papers. The topics discussed include: automatic debate text summarization in online debate forum; text normalization algorithm on twitter in complaint category; mobile expert system using fuzzy Tsukamoto for diagnosing cattle disease; authoring tool for interactive video content for learning programming; WAN optimization to speed up data transfer; evaluating the implementation of public information disclosure on the official website of Indonesian ministries; current issue on knowledge management system for future research: a systematic literature review; mango fruit sortation system using neural network and computer vision; and implementation of blind speech separation for intelligent humanoid robot using DUET method.},
document_type={Conference Review},
source={Scopus},
}

@ARTICLE{Zhang2017,
author={Zhang, B. and Wang, S. and Liu, Y. and Yang, H.},
title={Research on Trajectory Planning and Autodig of Hydraulic Excavator},
journal={Mathematical Problems in Engineering},
year={2017},
volume={2017},
doi={10.1155/2017/7139858},
art_number={7139858},
note={cited By 4},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019542734&doi=10.1155%2f2017%2f7139858&partnerID=40&md5=2d3d29f2091f5b7cd6e346654eead3fe},
affiliation={State Key Laboratory of Fluid Power and Mechatronic Systems, Zhejiang University, Hangzhou, 310027, China},
abstract={As the advances in computer control technology keep emerging, robotic hydraulic excavator becomes imperative. It can improve excavation accuracy and greatly reduce the operator's labor intensity. The 12-ton backhoe bucket excavator has been utilized in this research work where this type of excavator is commonly used in engineering work. The kinematics model of operation device (boom, arm, bucket, and swing) in excavator is established in both Denavit-Hartenberg coordinates for easy programming and geometric space for avoiding blind spot. The control approach is based on trajectory tracing method with displacements and velocities feedbacks. The trajectory planning and autodig program is written by Visual C++. By setting the bucket teeth's trajectory, the program can automatically plan the velocity and acceleration of each hydraulic cylinder and motor. The results are displayed through a 3D entity simulation environment which can present real-time movements of excavator kinematics. Object-Oriented Graphics Rendering Engine and skeletal animation are used to give accurate parametric control and feedback. The simulation result shows that a stable linear autodig can be achieved. The errors between trajectory planning command and simulation model are analyzed. © 2017 Bin Zhang et al.},
document_type={Article},
source={Scopus},
}

@ARTICLE{NoAuthor20171,
title={2nd International Conference on Emerging trends in Electrical, Communication and Information Technologies, ICECIT 2015},
journal={Lecture Notes in Electrical Engineering},
year={2017},
volume={394},
pages={1-458},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998693378&partnerID=40&md5=1f46055e981a1ec48447653cbd7bc42a},
abstract={The proceedings contain 47 papers. The special focus in this conference is on Emerging trends in Electrical, Communication and Information Technologies. The topics include: An enhanced mechanism for balanced job scheduling based on deadline control in computational grid; a secure location-based coupon redeeming system; Sanskrit as inter-lingua language in machine translation; scalability in virtualization; blind spectrum sensing techniques in cognitive radio-survey; an empirical analysis of unsupervised learning approach on medical databases; applying agile programming and design patterns in IT domain; a novel approach to improve the system performance by proper scheduling in memory management; removal of high density salt and pepper noise from the image Using CMA; a new stratified immune based approach for clustering high dimensional categorical data; an intelligent frame work system for finger touch association on planar surfaces; robust invisible watermarking for image authentication; automatic digital modulation recognition system using feature extraction; design of common source amplifier using amorphous Silicon TFT; study on influence of hip trajectory on the balance of a biped robot; a comparative study of decoupler design techniques for TITO control processes; coordination of energy storage devices in hybrid power systems; application of bio-inspired MPPT techniques for photovoltaic system; four level boost converter for linear loads; field failure rate reduction through ESS with MATLAB Based GUI; mitigation of power quality problems in distribution system using D-STATCOM and Location of IPFC under contingency condition in power system.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{DarioBellicoso2016558,
author={Dario Bellicoso, C. and Gehring, C. and Hwangbo, J. and Fankhauser, P. and Hutter, M.},
title={Perception-less terrain adaptation through whole body control and hierarchical optimization},
journal={IEEE-RAS International Conference on Humanoid Robots},
year={2016},
pages={558-564},
doi={10.1109/HUMANOIDS.2016.7803330},
art_number={7803330},
note={cited By 11},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010207625&doi=10.1109%2fHUMANOIDS.2016.7803330&partnerID=40&md5=06a20a738f8e48092f499492a0aab5ef},
affiliation={Robotic Systems Lab, ETH Zurich, Switzerland},
abstract={This paper presents a control approach based on a whole body control framework combined with hierarchical optimization. Locomotion is formulated as multiple tasks (e.g. maintaining balance or tracking a desired motion of one of the limbs) which are solved in a prioritized way using QP solvers. It is shown how complex locomotion behaviors can purely emerge from robot-specific inequality tasks (i.e. torque or reaching limits) together with the optimization of balance and system manipulability. Without any specific motion planning, this prioritized task optimization leads to a natural adaption of the robot to the terrain while walking and hence enables blind locomotion over rough grounds. The presented framework is implemented and successfully tested on ANYmal, a torque controllable quadrupedal robot. It enables the machine to walk while accounting for slippage and torque limitation constraints, and even step down from an unperceived 14 cm obstacle. Thereby, ANYmal exploits the maximum reach of the limbs and automatically adapts the body posture and height. © 2016 IEEE.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Trent20161954,
author={Trent, M. and Laubhan, K. and Abdelgawad, A. and Yelamarthi, K.},
title={An FPGA-based portable real-time obstacle detection and notification system},
journal={International Conference on Electrical, Electronics, and Optimization Techniques, ICEEOT 2016},
year={2016},
pages={1954-1958},
doi={10.1109/ICEEOT.2016.7755030},
art_number={7755030},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006701090&doi=10.1109%2fICEEOT.2016.7755030&partnerID=40&md5=86a5ba1de8b1b2c43f14eb3744899a1b},
affiliation={School of Engineering and Technology, Central Michigan University, Mount Pleasant, MI, United States},
abstract={There are abundant accounts of research relating to obstacle detection using vision sensors. Finding a solution that is low-power, easily portable, low-cost, and still effective is a challenge. Overcoming this challenge will help millions whether it is through improving assistive technology for the visually impaired, autonomous robot navigation, or another application. This paper presents the design and implementation of such a system. The architecture consists of an array of ultrasonic sensors to survey the scene, FPGA chip for data processing, and, in this scenario, vibration motors to indicate the obstacle direction. The system will be attached to a belt that can be used by a user. The FPGA is used to process the data coming from the ultrasonic sensors to detect the surrounding obstacles' distances. Accordingly, the FPGA will send the signal to the corresponding vibration motors to indicate the direction of the nearby obstacles. The experimental results validate the proposed system. © 2016 IEEE.},
author_keywords={embedded system;  FPGA;  obstacle detection;  sensor fusion},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={2016 International Symposium on Computers in Education, SIIE 2016: Learning Analytics Technologies},
journal={2016 International Symposium on Computers in Education, SIIE 2016: Learning Analytics Technologies},
year={2016},
page_count={340},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006782961&partnerID=40&md5=e6ab24d043239ec9e0f7c03e5b63127b},
abstract={The proceedings contain 61 papers. The topics discussed include: introduction to computational thinking. educational technology in primary and secondary education; adapting the design and the use methodology of a pedagogical conversational agent of secondary education to childhood education; combining traditional methodologies and social networks to teach job related skills to students with special needs; audiovisual didactic storytelling through virtual reconstruction: the Iberian temple of La Alcudia in Elche; students' motivation and satisfaction in an online practice community; assessment, training and innovation in information literacy in secondary education; the submicroscopic level of chemistry: analyzing learning objects to help the teacher in the process of teaching and learning; the analysis of the use of mobile technology in 6-8 years old children's literacy process; the use of digital educational resources: the contribution of research in the supervised teaching practice in basic education; incorporating educational robots and visual programming environments in introductory programming courses; and perception for cooperation case study in web text editors from the perspective of blind users.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Zhang2016,
author={Zhang, Y. and Ren, Z. and Liu, L. and Wei, C. and Yin, C.},
title={Design for a fast high precision UAV power emergency relief system},
journal={2016 4th International Conference on Applied Robotics for the Power Industry, CARPI 2016},
year={2016},
doi={10.1109/CARPI.2016.7745626},
art_number={7745626},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003845001&doi=10.1109%2fCARPI.2016.7745626&partnerID=40&md5=c91233af43412155c4fa3e2c9f00cb7e},
affiliation={State Grid Shandong Electric Power Research Institute, Jinan, China; State Grid Shandong Electric Power Company, Jinan, China; Shandong Luneng Intelligence Technology Co. Ltd., Jinan, China},
abstract={Unmanned aerial vehicle (in this paper, it is referred to as UAV) is widely used in the field of electric power emergency relief. The route planning time of traditional UAV emergency relief system is too long to deliver the disaster delay, and its inaccurate image feedback lead to blind command. In this paper, a fast high precision UAV power emergency relief system has been successfully designed, mainly including route map fast planning system, automatic high-precision UAV flight platform and ground monitoring command system. The route map fast planning system has been designed based on the C language, GIS Data development technology and image recognition technology. Automatic high-precision UAV flight platform mainly include UAV flight platform, multiple picture Video segmentation processor and camera fixed device. UAV route planning can be finished fast, nearly 60% of the planning map time has been saved than traditional UAV system. © 2016 IEEE.},
author_keywords={Design;  Fast;  High Precision;  Power Emergency Relief System;  UAV},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Carlos201667,
author={Carlos, G.-S. and Carlos, G.-S. and Pablo, M.-R.},
title={Phogo: A low cost, engaging and modern proposal to learn how to program},
journal={ACM International Conference Proceeding Series},
year={2016},
volume={02-04-November-2016},
pages={67-71},
doi={10.1145/3012430.3012498},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008178853&doi=10.1145%2f3012430.3012498&partnerID=40&md5=c9fc77dc36f6a43741d7acba2330b2e8},
affiliation={Dpto. Ingeniería Informática, Escuela Politécnica Superior, Universidad Autónoma de Madrid, Campus de Cantoblanco, Madrid, 28049, Spain},
abstract={Basic computational thinking, so necessary in today's society, can be learned in an engaging way with the use of educational robots. In order to reach very diverse groups of people, educational robots need to be simple, scalable and low cost. Inspired by the success of the LOGO project, we have developed the Phogo pedagogical platform, built around a low cost robot (less than $80) capable of tracing its path with a marker pen. We also present a high-level Python-based control library that allows for transparent and easy wireless communication with the robots. The approach was tested in an informal workshop with a group of teenagers without any previous self-conscious computational knowledge. As the students were attracted by the robot and the simple approach, they were able to gain some insight about abstract programming concepts such as variables, functions, and flow control structures. The majority of the students were people with physical, cognitive or intellectual disabilities and they were able to follow, enjoy and learn as any other student making this an accessible activity to everyone. Finally, we summarize our efforts documenting and publishing the Phogo system as open-source in order to promote its use in future workshops. © 2016 ACM.},
author_keywords={3D-printing;  Computational thinking;  Educational robots;  LOGO;  Low cost;  Open-source;  Python;  Robotic platform},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Xu2016842,
author={Xu, B. and Wen, G. and Zhang, Z. and Chen, F.},
title={Genetic programming-based classification of ferrograph wear particles},
journal={2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2016},
year={2016},
pages={842-847},
doi={10.1109/URAI.2016.7733992},
art_number={7733992},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000386300&doi=10.1109%2fURAI.2016.7733992&partnerID=40&md5=16067fda8918039f8bec30d4d5937bee},
affiliation={Key Laboratory of Education Ministry for Modern Design and Rotor-Bearing Systems, Xi'An Jiaotong University, Xi'an, 710049, China; Research Institute of Diagnostics and Cybernetics, Xi'An Jiaotong University, Xi'an, 710049, China; School of Mechanical Engineering, Xinjiang University, Wulumuqi, 830047, China},
abstract={Ferrograph analysis is becoming one of the principal methods for condition monitoring and fault diagnosis of the machinery equipment due to its advantages of visualization and efficiency. One of the major challenges of ferrograph analysis is feature construction from the existing features of wear particles to improve classifier efficiency. The current feature construction method is trial and error based on previous experience and mass data, which is time-consuming, laborious and blindness. In this paper, genetic programming-based approach was proposed to construct new features from the five existing morphological features of ferrograph wear particles to improve the ability of classification process. The GP-based feature construction approach is used for fault classification of ferrograph wear particles for the first time and the results show that the method can be used in wear condition monitoring and fault prognosis of machinery equipment. © 2016 IEEE.},
author_keywords={Feature evolution;  Ferrograph;  Genetic programming;  Wear condition classification;  Wear particles},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Yang2016400,
author={Yang, W. and Zhang, X. and Ma, H.},
title={An inspection robot using infrared thermography for belt conveyor},
journal={2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2016},
year={2016},
pages={400-404},
doi={10.1109/URAI.2016.7734069},
art_number={7734069},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000673464&doi=10.1109%2fURAI.2016.7734069&partnerID=40&md5=135168f0b0686ea08614031dc18651df},
affiliation={School of Mechanical Engineering, Xi'An University of Science and Technology710054, China; Xi'An Coal Mining Machinery Co., Ltd., Xi'an, 710032, China},
abstract={The key mechanical components of belt conveyor is lack of effective monitoring at present. The traditional monitoring methods such as visual inspection, temperature measurement have shortcoming, the huge workload, blind spots and other issues are difficult to solve. This paper proposes an inspection robot program with infrared thermometer for belt conveyor. Along the inspection track, the motor drive the infrared thermometer moves which mounted on robot. Infrared thermal image of motor, pulleys, rollers and other key transmission components are captured. With image signal processing and pattern recognition technology, the infrared images are processed. After infrared image segmentation, feature extraction and classification, the automatic identification of the typical elements are realized. Finally, make use of the component type that has identified, the warning temperature values and contract the library rules of failure database, this paper achieves a Failure Prognostic System (FRS) on drive system of belt conveyor. Experimental results show that the method can achieve automatic identification and fault warning abnormal temperature rise of motor, pulley and roller and the other mechanical components. © 2016 IEEE.},
author_keywords={Belt conveyor;  Failure prognostic;  Infrared thermography;  Inspection robot;  Pattern recognition},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{NoAuthor2016,
title={HAI 2016 - Proceedings of the 4th International Conference on Human Agent Interaction},
journal={HAI 2016 - Proceedings of the 4th International Conference on Human Agent Interaction},
year={2016},
page_count={410},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994504386&partnerID=40&md5=492ca7be6ef380e32e03e8a53a15957d},
abstract={The proceedings contain 75 papers. The topics discussed include: perception of animacy by the linear motion of a group of robots; exploring social interaction with everyday object based on perceptual crossing; tracking human gestures under field-of-view constraints; whispering bubbles: exploring anthropomorphism through shape-changing interfaces; model-driven gaze simulation for the blind person in face-to-face communication; user generated agent: designable book recommendation robot programmed by children; cross-cultural study of perception and acceptance of Japanese self-adaptors; development of a simulated environment for recruitment examination and training of high school teachers; interaction in a natural environment: estimation of customer's preference based on nonverbal behaviors; ear ball for empathy: to realize the sensory experience of people with autism spectrum disorder; process of agency identification based on the desire to communicate in embodied interaction; building trust in PRVAs by user inner state transition through agent state transition; improving smartphone users affect and wellbeing with personalized positive psychology interventions; and sharing emotion described as text on the internet by changing self-physiological perception.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Lakshmanan20161229,
author={Lakshmanan, R. and Senthilnathan, R.},
title={Depth map based reactive planning to aid in navigation for visually challenged},
journal={Proceedings of 2nd IEEE International Conference on Engineering and Technology, ICETECH 2016},
year={2016},
pages={1229-1234},
doi={10.1109/ICETECH.2016.7569448},
art_number={7569448},
note={cited By 2},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991817676&doi=10.1109%2fICETECH.2016.7569448&partnerID=40&md5=d5d9325591abdba7172bc67b4c59f816},
affiliation={Department of Mechanical Engineering, SRM University, Kattankulathur, Chennai, India},
abstract={Visual information is essential for navigation oriented tasks, but visually challenged individuals face difficulties in performing these tasks since they lack sufficient information regarding their surrounding environment. In the literature, many vision and non-vision based aids have been proposed to help the blind for navigation and perception in general. The proposed system aims to a provide reactive planning method using a depth map acquired from a vision system, to assist visually challenged individuals in achieving collision-free navigation in an indoor environment. Understanding the environment in front involves two phases. Firstly, classifying the obstacles as static or dynamic will help us identify the obstacles that require a quick response. Secondly, the velocity of the obstacles is estimated from the depth map which gives information whether they are approaching or moving away. Once understanding the environment in front is carried out regarding its geometry, navigation planning is done to guide the user who holds the differential drive robot attached to the walking stick. © 2016 IEEE.},
author_keywords={Cane;  Depth map;  Kinect;  Navigation task;  Obstacle avoidance;  Visual aid;  Visually blind},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Nezamfar2016932,
author={Nezamfar, H. and Mohseni Salehi, S.S. and Moghadamfalahi, M. and Erdogmus, D.},
title={FlashTypeTM: A Context-Aware c-VEP-Based BCI Typing Interface Using EEG Signals},
journal={IEEE Journal on Selected Topics in Signal Processing},
year={2016},
volume={10},
number={5},
pages={932-941},
doi={10.1109/JSTSP.2016.2552140},
art_number={7448846},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982854021&doi=10.1109%2fJSTSP.2016.2552140&partnerID=40&md5=ea11d1bc1110a2c5e8b0cfa9fa1170be},
affiliation={Cognitive Systems Laboratory, Department of Electrical and Computer Engineering, Northeastern University, Boston, MA  02115, United States},
abstract={Brain computer interfaces (BCIs) offer individuals with disabilities an alternative channel of communication and control, hence they have been receiving increasing interest. BCIs can also be useful for healthy individuals in situations limiting their movement or where other computer interaction modalities need to be supplemented. Event-related and steady state visually evoked potentials (SSVEPs) are the top two brain signal types used in developing BCIs that allow the user to make a choice from a discrete set of options, including the selection of commands from a menu for a robot or computer to perform, as well as typing letters, symbols, or icons for communication. Popular BCI speller paradigms, such as the P300 Matrix Speller, RSVP KeyboardTM or SSVEP spellers in which the letters on the keyboard display flicker, are sensitive to the font, size and presentation speed. In addition, sensitivity to eye gaze control plays a significant role in usability of most of these keyboards. We present a code-VEP based BCI, utilized in a language model assisted keyboard application. Utilizing a cursor based selection method, stimuli and targets are separated. FlashTypeTM separates visual stimulation from alphabet presentation to achieve performance invariance under presentation variations. Therefore, FlashTypeTM can be used for all languages, including the ones containing symbols and icons. FlashTypeTM, contains a Static Keyboard, a row of Suggested Characters and a row of Predicted Words. FlashTypeTM, by default, uses only one EEG electrode and four stimuli. The system can operate using only one stimulus at a lower selection rate, useful for individuals with limited or no gaze control. This feature is to be explored in future. Replacing letters with text or icons representing commands would allow controlling a computer or robot. In this study, FlashTypeTM has been evaluated by three individuals performing 10 Mastery tasks. In depth experimentation, such as assessing the system with potential end users writing long passages of text, will be done in future. © 2016 IEEE.},
author_keywords={BCI;  c-VEP;  EEG;  Keyboard;  Language Model},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Burg2016142,
author={Burg, J. and Pauca, V.P. and Turkett, W. and Santago, P.},
title={A STEM incubator to engage students in hands-on, relevant learning: A report from the field},
journal={Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE},
year={2016},
volume={11-13-July-2016},
pages={142-147},
doi={10.1145/2899415.2899461},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979737390&doi=10.1145%2f2899415.2899461&partnerID=40&md5=173b83dbd6cb5bc4b8312b6d090bbf5a},
affiliation={Dept. of Comp. Sci., Wake Forest University, Winston-Salem, NC  27109, United States},
abstract={This paper describes the development of a STEM Incubator program to engage students in hand-on, relevant projects that draw student interest toward computer science and other STEM fields. The program is implemented via one-credit courses allowing students to collaborate on projects in various areas (such as digital sound and music, 3D design, robotics, digital image processing, bioinformatics, and mobile and pervasive computing) and around multiple application domains (e.g. internet of things and security, apps for college campus life, 3D printing and art, wearable sensors for disabilities, and sensors and unmanned vehicles for conservation). An apprentice/leader learning environment is created to sustain student involvement in ongoing projects. The evolution of the program is reviewed, including successes and challenges. We report on the demographics of students who have participated in the program so far, and on the success in attracting enthusiastic interest, notably among female students. The STEM Incubator program, like other similar programs described in this paper, attempts to put into practice the evidence-based teaching practices in active learning that have gained credence over the past decade. The paper is of interest to those considering a similar program or wishing to compare other programs to their own.},
author_keywords={Collaboration;  Hands-on learning;  Situated learning},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ferraro2016,
author={Ferraro, D. and Champ, J. and Teste, B. and Serra, M. and Malaquin, L. and Viovy, J.-L. and De Cremoux, P. and Descroix, S.},
title={Microfluidic platform combining droplets and magnetic tweezers: Application to HER2 expression in cancer diagnosis},
journal={Scientific Reports},
year={2016},
volume={6},
doi={10.1038/srep25540},
art_number={25540},
note={cited By 23},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971222818&doi=10.1038%2fsrep25540&partnerID=40&md5=fe7891d2ee67103da2a148a9dee50ee1},
affiliation={Institut Curie, PSL Research University, Laboratoire Physicochimie, CNRS/UMR 168, Institut Pierre-Gilles de Gennes, MMBM Group, Paris, France; APHP Hôpital Saint-Louis, Molecular Oncology Unit, University Paris-Diderot, INSERM/CNRS, UMR944/7212, Paris, France; LAAS-CNRS, Université de Toulouse, CNRS, Toulouse, France},
abstract={The development of precision medicine, together with the multiplication of targeted therapies and associated molecular biomarkers, call for major progress in genetic analysis methods, allowing increased multiplexing and the implementation of more complex decision trees, without cost increase or loss of robustness. We present a platform combining droplet microfluidics and magnetic tweezers, performing RNA purification, reverse transcription and amplification in a fully automated and programmable way, in droplets of 250nL directly sampled from a microtiter-plate. This platform decreases sample consumption about 100 fold as compared to current robotized platforms and it reduces human manipulations and contamination risk. The platform € s performance was first evaluated on cell lines, showing robust operation on RNA quantities corresponding to less than one cell, and then clinically validated with a cohort of 21 breast cancer samples, for the determination of their HER2 expression status, in a blind comparison with an established routine clinical analysis.},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhang20161168,
author={Zhang, T. and Jiang, L. and Fan, S. and Wu, X. and Feng, W.},
title={Development and experimental evaluation of multi-fingered robot hand with adaptive impedance control for unknown environment grasping},
journal={Robotica},
year={2016},
volume={34},
number={5},
pages={1168-1185},
doi={10.1017/S0263574714002161},
note={cited By 8},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028244362&doi=10.1017%2fS0263574714002161&partnerID=40&md5=dc64a7d4b7e58b6c56b8e018b9a0d284},
affiliation={Guangdong Provincial Key Laboratory of Robotics and Intelligent System, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China},
abstract={This paper presents adaptive impedance controllers with adaptive sliding mode friction compensation for anthropomorphic artificial hand. A five-fingered anthropomorphic artificial hand with multi-sensory and Field-Programmable Gate Arra (FPGA)-based control hardware and software architecture is designed to fulfill the requirements of the grasping force controller. In order to improve the force-tracking precision, the indirect adaptive algorithm was applied to estimate the parameters of the environment. The generalized momentum-based disturbance observer was applied to estimate the contact force from the torque sensor. Based on the sensors of the finger, an adaptive sliding mode friction compensation algorithm was utilized to improve the accuracy of the position control. The performances of the force-tracking impedance controller and position-based joint impedance control for the five-fingered anthropomorphic artificial hand are analyzed and compared in this paper. Furthermore, the performances of the force-tracking impedance controller with environmental parameters adaptive estimation and without environmental parameters estimation are analyzed and compared. Experimental results prove that accurate force-tracking and stable torque/force response under uncertain environments of unknown stiffness and position can be achieved with the proposed adaptive force-tracking impedance controller with friction compensation on five-finger artificial hand. © Copyright Cambridge University Press 2014.},
author_keywords={Adaptive impedance control;  Blind environment grasping;  Force control;  Multi-fingered robot hand},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Conchinha2016167,
author={Conchinha, C. and Osório, P. and De Freitas, J.C.},
title={Playful learning: Educational robotics applied to students with learning disabilities},
journal={2015 International Symposium on Computers in Education, SIIE 2015},
year={2016},
pages={167-171},
doi={10.1109/SIIE.2015.7451669},
art_number={7451669},
note={cited By 5},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969959749&doi=10.1109%2fSIIE.2015.7451669&partnerID=40&md5=04a7f7f7cf99b4fa5558536c62b94423},
affiliation={Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa, Faro, Portugal; Educational Psychology and Educational Technology at the City of Volta Redonda, Volta Redonda, Brazil; Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa, Almada, Portugal},
abstract={Since the ratification of the Salamanca agreement in 1994 that it is the concern of schools to seek inclusive approaches that may lead all students to academic success through differentiated strategies and adaptations or curricular and environmental interventions, whenever necessary [1] [2]. In this study we present a strategy for inclusion and knowledge consolidation based on playful learning using educational robotics (ER) projects. Participants were two boys aged 15 and a 14 years old girl. All students attended the third cycle in Brazil, and were diagnosed with special needs, with specific learning disabilities. Students were initially reluctant to participate in the activities but soon were captivated by the project and motivated to take part in all stages, particularly during assembly, programming and interacting with a Lego® Mindstorms® prototype, showing that ER may be significant on allowing students to learn while playing and also by promoting their inclusion on different and engaging activities. By favouring participant relationships, use of language and concepts ER may also prove helpful for students daily life. © 2015 IEEE.},
author_keywords={Educational Robotics;  Inclusion;  Learning Disabilities;  Lego® Mindstorms®;  Playful learning},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bougrain2016353,
author={Bougrain, L. and Le Golvan, B.},
title={Neuroprostheses [Les neuroprothèses]},
journal={Evolution Psychiatrique},
year={2016},
volume={81},
number={2},
pages={353-364},
doi={10.1016/j.evopsy.2016.01.010},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959564204&doi=10.1016%2fj.evopsy.2016.01.010&partnerID=40&md5=53240e4b4ae84aef1c28da7244975d81},
affiliation={Département de systèmes complexes, Intelligence artificielle et robotique, Université de Lorraine, LORIA, Vandœuvre-lès-Nancy, 54506, France; Équipe-projet Neurosys, Inria, Villers-lès-Nancy, 54500, France; Équipe Neurosys, CNRS, LORIA, UMR 7503, Vandœuvre-lès-Nancy, 54506, France},
abstract={Introduction: Neuroprostheses are electronic or electromechanical devices connected to the nervous system to replace a defective organ. This article aims to review the state of the art of these devices. Methods: This article successively presents various neuroprostheses. While cochlear implants have existed now for almost 60 years, in the last decade, technological solutions to restore other senses, such as sight with artificial retinas, and touch with artificial skins, have made significant progress. Similarly, myoprostheses, brain-machine interfaces and exoskeletons, which aim to restore the control of a limb, often make headlines in the news. Myoprostheses are intended to compensate for the lack of an amputated upper limb by registering nerve impulses transmitted to the muscles from the skin surface to control a prosthetic hand. Brain-computer interfaces register neural activity within the motor cortex, or more rarely from the surface of the scalp, to decode the motor order and transmit it to a motorized limb. Finally, exoskeletons are mechanical structures enveloping all or part of the body to animate it. Results: Cochlear implants and myoelectric prosthetics are now regularly offered for people with severe or profound hearing loss and for forearm amputees. Increasing the resolution of artificial retinas should help in the medium term to offer a basic visual perception of their environment, if not to people blind from birth, at least to macular degeneration sufferers. Finally, non-invasive motor neuroprostheses are now being included in rehabilitation programs for stroke. Invasive neuroprostheses actually able to decode the direction of movement will still require many years of research, in particular to integrate sensory feedback. Discussion: Thus, beyond the spectacular aspect of communications on the subject to get the attention of the public and funders, and the enthusiasm for novelty of journalists, the real issues are the expectations of potential users, the disappointments and satisfactions of patients, the actual number of people equipped, and cost and scope for use of such devices outside the laboratories. Conclusion: This article aims to position these new technologies in terms of reality and fiction, in terms of the expectations of people with a disability and fantasies of the augmented human, and in terms of the scientific difficulties encountered. © 2016 Elsevier Masson SAS.},
author_keywords={Artificial retina;  Brain-machine interfaces;  Disability;  Exoskeleton;  Functional electrical stimulation;  Myoelectric prosthetics;  Neuroprosthetics;  Nuclear implant;  Rehabilitation;  Robotic arm},
document_type={Article},
source={Scopus},
}

@ARTICLE{Rajanna20161,
author={Rajanna, V. and Vo, P. and Barth, J. and Mjelde, M. and Grey, T. and Oduola, C. and Hammond, T.},
title={KinoHaptics: An Automated, Wearable, Haptic Assisted, Physio-therapeutic System for Post-surgery Rehabilitation and Self-care},
journal={Journal of Medical Systems},
year={2016},
volume={40},
number={3},
pages={1-12},
doi={10.1007/s10916-015-0391-3},
art_number={60},
note={cited By 12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949557519&doi=10.1007%2fs10916-015-0391-3&partnerID=40&md5=da422d42e69db232794d50ddec3c9ae8},
affiliation={Sketch Recognition Lab, Department of Computer Science and Engineering, Texas A & M University, College Station, TX  77843, United States},
abstract={A carefully planned, structured, and supervised physiotherapy program, following a surgery, is crucial for the successful diagnosis of physical injuries. Nearly 50 % of the surgeries fail due to unsupervised, and erroneous physiotherapy. The demand for a physiotherapist for an extended period is expensive to afford, and sometimes inaccessible. Researchers have tried to leverage the advancements in wearable sensors and motion tracking by building affordable, automated, physio-therapeutic systems that direct a physiotherapy session by providing audio-visual feedback on patient’s performance. There are many aspects of automated physiotherapy program which are yet to be addressed by the existing systems: a wide classification of patients’ physiological conditions to be diagnosed, multiple demographics of the patients (blind, deaf, etc.), and the need to pursue patients to adopt the system for an extended period for self-care. In our research, we have tried to address these aspects by building a health behavior change support system called KinoHaptics, for post-surgery rehabilitation. KinoHaptics is an automated, wearable, haptic assisted, physio-therapeutic system that can be used by a wide variety of demographics and for various physiological conditions of the patients. The system provides rich and accurate vibro-haptic feedback that can be felt by the user, irrespective of the physiological limitations. KinoHaptics is built to ensure that no injuries are induced during the rehabilitation period. The persuasive nature of the system allows for personal goal-setting, progress tracking, and most importantly life-style compatibility. The system was evaluated under laboratory conditions, involving 14 users. Results show that KinoHaptics is highly convenient to use, and the vibro-haptic feedback is intuitive, accurate, and has shown to prevent accidental injuries. Also, results show that KinoHaptics is persuasive in nature as it supports behavior change and habit building. The successful acceptance of KinoHaptics, an automated, wearable, haptic assisted, physio-therapeutic system proves the need and future-scope of automated physio-therapeutic systems for self-care and behavior change. It also proves that such systems incorporated with vibro-haptic feedback encourage strong adherence to the physiotherapy program; can have profound impact on the physiotherapy experience resulting in higher acceptance rate. © 2015, Springer Science+Business Media New York.},
author_keywords={Haptics;  Health behavior change support system;  Kinect;  Medical informatics;  Persuasive system;  Persuasive technology;  Physiotherapy;  Self-care;  Ubiquitous systems;  Vibrotactile feedback;  Wearable computing},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Andruseac2016,
author={Andruseac, G.G. and Adochiei, R.I. and PǍsǍricǍ, A. and Adochiei, F.-C. and CorciovǍ, C. and Costin, H.},
title={Training program for dyslexic children using educational robotics},
journal={2015 E-Health and Bioengineering Conference, EHB 2015},
year={2016},
doi={10.1109/EHB.2015.7391547},
art_number={7391547},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978112091&doi=10.1109%2fEHB.2015.7391547&partnerID=40&md5=72b2fce784bd444deb26af47bf6ad696},
affiliation={Department of Biomedical Science, Faculty of Medical Bioengineering, Grigore T. Popa University of Medicine and Pharmacy, Iasi, Romania; Military Technical Academy, Bucharest, Romania; Gheorghe Asachi Technical University, Iaşi, Romania; University Politehnica of Bucharest, Romania; Institute of Computer Science, Romanian Academy Iaşi Branch, Iaşi, Romania},
abstract={This paper presents the implementation of a research project focused on the use of robotics as an effective tool in teaching technical disciplines to dyslexic children. Dyslexia is the most common learning disability and affects between 5 and 12 percent of all students. The goal of this project is to develop educational programs which will boost school performance of dyslexic children by using robotics in Science, Technology, Engineering and Mathematics Education (STEM). Studies have shown that robots can help students develop problem-solving abilities and learn computer programming, mathematics, and science. However, few studies discuss the use of robots in special education. We present the basic concept of using robotics as a mean to teach other subjects, and we describe the courses that are developed in the research project from the Department of Biomedical Science at the University of Medicine and Pharmacy Grigore T. Popa Iasi, project implemented to answer the needs of dyslexic children. © 2015 IEEE.},
author_keywords={constructivism;  dyslexia;  education;  robotics},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Al-Halhouli2016579,
author={Al-Halhouli, A. and Qitouqa, H. and Malkosh, N. and Shubbak, A. and Al-Gharabli, S. and Hamad, E.},
title={LEGO Mindstorms NXT for elderly and visually impaired people in need: A platform},
journal={Technology and Health Care},
year={2016},
volume={24},
number={4},
pages={579-585},
doi={10.3233/THC-161140},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981276184&doi=10.3233%2fTHC-161140&partnerID=40&md5=7f97d9918f234e53675d926e96936665},
affiliation={School of Applied Technical Sciences, German Jordanian University, P. O. Box: 35247, Amman, 11180, Jordan},
abstract={This paper presents the employment of LEGO Mindstorms NXT robotics as core component of low cost multidisciplinary platform for assisting elderly and visually impaired people. LEGO Mindstorms system offers a plug-And-play programmable robotics toolkit, incorporating construction guides, microcontrollers and sensors, all connected via a comprehensive programming language. It facilitates, without special training and at low cost, the use of such device for interpersonal communication and for handling multiple tasks required for elderly and visually impaired people in-need. The research project provides a model for larger-scale implementation, tackling the issues of creating additional functions in order to assist people in-need. The new functions were built and programmed using MATLAB through a user friendly Graphical User Interface (GUI). Power consumption problem, besides the integration of WiFi connection has been resolved, incorporating GPS application on smart phones enhanced the guiding and tracking functions. We believe that developing and expanding the system to encompass a range of applications beyond the initial design schematics to ease conducting a limited number of pre-described protocols. However, the beneficiaries for the proposed research would be limited to elderly people who require assistance within their household as assistive-robot to facilitate a low-cost solution for a highly demanding health circumstance. © 2016 - IOS Press and the authors. All rights reserved.},
author_keywords={Elderly;  Healthcare;  LEGO Mindstorms NXT;  MATLAB;  Visually impaired},
document_type={Article},
source={Scopus},
}

@ARTICLE{Motoyoshi201651,
author={Motoyoshi, T. and Tetsumura, N. and Masuta, H. and Koyanagi, K. and Oshima, T. and Kawakami, H.},
title={Tangible programming gimmick using RFID systems considering the use of visually impairments},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2016},
volume={9758},
pages={51-58},
doi={10.1007/978-3-319-41264-1_7},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978252753&doi=10.1007%2f978-3-319-41264-1_7&partnerID=40&md5=0b5e7cb9155065e8057c70780597dc11},
affiliation={Department of Intelligent Systems Design Engineering, Toyama Prefectural University, Toyama, 939-0398, Japan},
abstract={We developed P-CUBE as a tangible programming education tool for visually impairments or inexperienced persons in PC operation. Users are able to control a mobile robot simply by positioning blocks on a mat. The fundamental programming concepts taught by P-CUBE consist of three elements: sequences, branches and loops. These systems uses radio frequency identification (RFID) systems to identify the position of blocks or cards on the mat. Blocks utilize RFID tags alone. P-CUBE is designed to operate via tactile information for visually impaired. We report on the system configurations of P-CUBE and programming workshop held for visually impairments. Then, we discuss merits of tangible programming tools using RFID systems. © Springer International Publishing Switzerland 2016.},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Gacharna2016836,
author={Gacharna, T.A.N. and Rodriguez, A.D.A. and Barbosa, C.},
title={Learning strategies in mobile and industrial robotics for people with auditory impairment},
journal={GHTC 2016 - IEEE Global Humanitarian Technology Conference: Technology for the Benefit of Humanity, Conference Proceedings},
year={2016},
pages={836-841},
doi={10.1109/GHTC.2016.7857377},
art_number={7857377},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015159924&doi=10.1109%2fGHTC.2016.7857377&partnerID=40&md5=99423369085de47728f44d9a71ec1e78},
affiliation={Universidad ECCI, Coordinación de Ingeniería Electrónica y Mecatrónica, Bogotá, Colombia},
abstract={The difficulties of learning (comprehension and interpretation of the information), the lack of tools for virtual support and their own disability are the main reasons of students' dropout in Colombia specially in higher education programs for people with hearing impairment, which reduces significantly their opportunities in the professional field. This research aims to develop learning strategies for people with hearing disability in the fields of mobile and industrial robotics. To achieve this objective, pedagogical and didactical tools in virtual learning environments ICT (Information and Communications Technology) were designed, along with classroom training that facilitated learning and improved cognitive processes in students with hearing impairments. The most important results achieved in this work are: a greater degree of ownership and knowledge generation by deaf students, which impacted on their social inclusion level and labor skills level through the ICT Development of a mini sumo robot and a soccer robot by deaf students. This project also enhanced the competence in manufacturing programmable automaton systems, generation of new signs to denote different electronic devices such as Optical Sensors, H-Bridge, among others. The main conclusion is the evidence of the potential of ICT in generating greater social inclusion and employment opportunities for people with hearing disabilities. © 2016 IEEE.},
author_keywords={Hearing impairment;  inclusion;  information and communications technology;  learning},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Scott2016,
author={Scott, S.H.},
title={Use of robotic technology to assess brain function},
journal={International Conference of Control, Dynamic Systems, and Robotics},
year={2016},
page_count={2},
doi={10.11159/cdsr16.131},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053300855&doi=10.11159%2fcdsr16.131&partnerID=40&md5=f95e0412ef9581a8b9bcf8a2cbcc7fb3},
affiliation={Department of Biomedical and Molecular Sciences, Queen's University, Kingston, Canada},
abstract={Clinical assessment plays a crucial role in all facets of patient care, from diagnosing the specific disease or injury, to management and monitoring of rehabilitation strategies to ameliorate dysfunction. Most assessment scales for sensorimotor function are subjective in nature with relatively coarse rating systems, reflecting that it is difficult for even experienced observers to discriminate consistently small changes in performance using only the naked eye. Our general hypothesis is that robotic technologies can provide an objective approach to quantify sensory, motor and cognitive impairments. We developed a robotic device called KINARM, an exoskeleton robot that is attached to the arm and permits movements at the shoulder and elbow joints in the horizontal plane [1]. The system includes two KINARM robots to assess each arm, and an integrated virtual reality system that projects objects onto the horizontal workspace. We have developed a suite of behavioural tasks to quantify sensory, motor and cognitive impairments in subjects with neurological disorders. I will describe a number of tasks to assess various aspects of motor function, including a visual guided reaching task to quantify goal-directed motor actions [2], a bimanual task to assess the ability to coordinate movements of the two arms [3], a posture perturbation task to assess use of limb afferent feedback for motor action [4], an object hit task to assess rapid motor skills [5], and an object hit and avoid task to quantify rapid motor and cognitive processing [6]. Subject performance was characterized using a set of parameters related to the spatiotemporal features of each motor action. A large cohort of healthy control subjects (n > 100) completed each task in order to develop normative models on healthy performance considering factors such as age, sex and handedness. Impairments were defined as performance outside the 95% range observed for healthy controls. These studies highlight a broad range of impairments that can occur following stroke. First, the unaffected limb often displays impairments in motor function particularly for subjects with stroke in the right hemisphere. Second, the ability to make rapid motor decisions and motor actions are commonly impaired, but are not captured with existing clinical tools. Third, there is substantial heterogeneity in impairments across individuals with stroke, suggesting the need for patient-specific rehabilitation programs. We have also developed other robotic platforms for clinical assessment including end-point robots that can be grasped by the subjects, and systems that can be used while standing to assess coordination between voluntary control of the arms and whole-body balance control. Eye-tracking technologies can also be integrated into the systems to quantify oculomotor function and eye-hand coordination. These platforms are being used to quantify impairments in many disorders/injuries beyond stroke, including ALS, Parkinson's disease, spinal cord injury, transient ischemic attack, concussion, cardiac arrest, and pre- and post-operative assessments for a range of neurological and non-neurological interventions. © 2016 Avestia Publishing.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20161,
title={5th International Workshop on Learning Technology for Education in Cloud, LTEC 2016},
journal={Communications in Computer and Information Science},
year={2016},
volume={620},
pages={1-308},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978900518&partnerID=40&md5=564a9ba2bdc9fc48d01d69880cae43f7},
abstract={The proceedings contain 25 papers. The special focus in this conference is on Particular Approaches, Technologies, and Domains. The topics include: Revisiting mathematical textbooks problems in a technology enhanced learning environment; the knowledge management into technology based firms; informational technology skills and media literacy in students; emotions and connections are ubiquitous in second life; using games to improve learning skills in students with cognitive disabilities through kinect technology; web framework for developing real time applications for education; investigating the experience of moodle adoption through expert voices; learning strategies and interpersonal relationships of students learning cooperatively online; the impact of learner attitudes; emotion determination in elearning environments based on facial landmarks; ubiquitous networked learning; designing technology-based tasks for enhancing mathematical understanding through problem solving; digital technologies and a modeling approach to learn mathematics and develop problem solving competencies; knowledge management metamodel from social analysis of lessons learnt registered in the cloud; teaching information literacy in secondary education; course implementation; establishing meta-learning metrics when programming mindstorms EV3 robots; three curriculum maturing cycles in academic curriculum management systems and is a virtual learning environment a one-size-fits-all solution? a survey of cognitive styles within a university student population.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Purwar2016,
author={Purwar, A. and Desai, R.},
title={Using kinect to capture human motion for mechanism synthesis, motion generation and visualization},
journal={Proceedings of the ASME Design Engineering Technical Conference},
year={2016},
volume={5A-2016},
doi={10.1115/DETC2016-60499},
note={cited By 1},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007583362&doi=10.1115%2fDETC2016-60499&partnerID=40&md5=fb7adbd59310a38155681544bbbede08},
affiliation={Computer-Aided Design and Innovation Lab., Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY  11794-2300, United States},
abstract={In this paper, we are presenting a framework for capturing human motions using Microsoft Kinect sensor for the purpose of 1) generating task positions for mechanism and robot synthesis, and 2) generation and visualization of B-spline interpolated and approximated motion from the captured task positions. The theoretical foundation of this work lies in Kinematic Mapping, Dual and Bi-quaternions, and NURBS (Non-Uniform Rational B-spline) geometry. Lately, Kinect has opened doors for creation of natural and intuitive human-machine interactive (HMI) systems in medicine, robotic manipulation, CAD, and many other fields, where visual-sensing and -capture is a central theme. Kinect has made a huge impact in physical therapy area, achieving new benchmarks in tele-rehabilitation by improving physical exercise assessment, monitoring and supervision using the skeletal data. Moreover, Kinect's depth sensing capability has helped in retrieving depth information required for robotic vision in grasping, object recognition which was previously done using computationally demanding computer vision algorithms. Kinect's point cloud data with interactive gestures has proven to be useful in various CAD software for conceptual design of shapes. Mechanism synthesis is one of the areas in Kinematics, where Kinect-provided skeletal data can be leveraged to design and develop highly customized end-user collaborated mechanism solutions. We demonstrate that using Kinect, OpenGL, and Openframeworks, we can capture discrete (or, key) rigid body displacements, continuous motions, and generate and visualize rational B-spline motions from captured key positions. Capturing only a few key positions results in significant data savings and also provides a natural way to create tasks for mechanism synthesis problems. The output is a set of dual quaternions and 4 × 4 homogeneous transforms representing a task motion, which can be used as an input for mechanism synthesis applications. The tool produced also allows users to generate trajectories of various points on a moving rigid body interactively. A Kinect-based capture of such motions can help create highly-customized assistive devices for people who suffer from a range of motion-related difficulties due to old age or disabilities. Copyright © 2016 by ASME.},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{NoAuthor20161,
title={International Conference on Signal, Networks, Computing, and Systems, ICSNCS 2016},
journal={Lecture Notes in Electrical Engineering},
year={2016},
volume={396},
pages={1-347},
note={cited By 0},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993545920&partnerID=40&md5=8f788130690ad6bfc379bb09935399b1},
abstract={The proceedings contain 38 papers. The special focus in this conference is on Advanced Computing Paradigms and Methodologies for Systems Design. The topics include: A support vector machine approach for LTP using; load balancing challenges in cloud computing; a survey; physiological modeling of retinal layers for detecting the level of perception of people with night blindness; an improved encryption and signature verification ECC scheme for cloud computing; on Intuitionistic fuzzy soft sets and their application in decision-making; check what is inside before signing a PDF document; kinematic analysis of a two-wheeled self-balancing mobile robot; program code understandability and authenticating code predicting Systems; ANFIS-based controller for DFIG-based tidal current turbine to improve system stability; design of reversible floating point adder for DSP applications; a review of bio-inspired computing methods and potential applications; an effective task scheduling approach for cloud computing environment; construct-based sentiment analysis model; predictive control system design for lime kiln process; design of time-delay compensator for a FOPDT process model; a novel multipath mitigation technique for SPSGPS receivers in Indian urban canyons; controller capability comparison for a delayed first-order process model; on modeling and analysis of launch vehicle system; performance evaluation of tree-based classification techniques on intrusion dataset; modeling and simulation for conductivity of germanium and YBCO; cryptoviral extortion; evolution, scenarios, and analysis; simulation studies for delay effect on stability of a canonical tank process and kinematic control of a mobile manipulator.},
document_type={Conference Review},
source={Scopus},
}

@CONFERENCE{Moore20162636,
author={Moore, R.K.},
title={A real-time parametric general-purpose mammalian vocal synthesiser},
journal={Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
year={2016},
volume={08-12-September-2016},
pages={2636-2640},
doi={10.21437/Interspeech.2016-841},
note={cited By 3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994229409&doi=10.21437%2fInterspeech.2016-841&partnerID=40&md5=6bd2a3034fe3fc525f1e7c994b3a9ff9},
affiliation={Speech and Hearing Research Group, Dept. Computer Science, University of Sheffield, United Kingdom},
abstract={Although R&D into 'speech synthesis' has received a considerable amount of attention over many years, there has been remarkably little effort devoted to constructing vocal synthesisers for non-human animals. Of course, interest in synthesising human speech has been driven by the demand for practical applications such as reading machines for the blind or voiceoperated assistants. Nevertheless, there are potential uses for non-human vocal synthesis: e.g. in education, robotics or ecological fieldwork. The latter is of particular interest, since it is common practice to use 'playback' methods (based on recorded samples) that do not easily facilitate parametric control over key experimental variables. Therefore, this paper presents the design and implementation of a real-time parametric generalpurpose mammalian vocal synthesiser. The approach taken has been to decompose the overall sound production system into the relevant anatomical components (such as the lungs, vocal folds, tongue and mouth), and to implement a real-time simulation in 'Pure Data' - an open-source dataflow programming language. The software was successfully used to design an appropriate mammalian voice for the MiRo® biomimetic robot, but there are potential applications in a number of areas. The software is available for free download at http://www.dcs.shef. ac.uk/r~oger/downloads.html. Copyright © 2016 ISCA.},
author_keywords={Animal sound synthesis;  Mammalian vocalisation;  Robotic voices;  Vocal synthesis},
document_type={Conference Paper},
source={Scopus},
}
