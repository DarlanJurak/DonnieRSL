@ARTICLE{8302582, 
author={G. {Cappagli} and S. {Finocchietti} and G. {Baud-Bovy} and L. {Badino} and A. {D’Ausilio} and E. {Cocchi} and M. {Gori}}, 
journal={IEEE Transactions on Cognitive and Developmental Systems}, 
title={Assessing Social Competence in Visually Impaired People and Proposing an Interventional Program in Visually Impaired Children}, 
year={2018}, 
volume={10}, 
number={4}, 
pages={929-935}, 
abstract={Visually impaired children and adults have difficulties in engaging in positive social interactions. This paper assesses social competence in sighted and visually impaired people and to propose a novel interventional strategy in visually impaired children. We designed a task that assesses the ability to initiate and sustain an interaction with the experimenter while performing free hand movements using a sonorous feedback on the experimenter's wrist. Both participant and experimenter kinematic data were recorded with a motion capture system. The level of social interaction between participant and experimenter has been computed through objective measurements based on Granger causality analysis applied to the participant arm kinematics. The interventional program followed by the visually impaired children lasted 12 weeks and consisted in a series of spatial and social games performed with the use of a sonorous bracelet which provides an auditory feedback of body actions in space. Visually impaired individuals present a poorer communication flow with the experimenter than sighted people, which indicates a less efficient social interaction. The amount of communication between the two agents resulted in a significant improvement after the interventional program. Thus, a specific intervention, based on the substitution of visual with auditory feedback of body actions, can enhance social inclusion for the blind population.}, 
keywords={biomechanics;handicapped aids;interactive systems;experimenter;interventional program;visually impaired children;positive social interactions;visually impaired people;visually impaired individuals;social competence;time 12.0 week;Task analysis;Social factors;Retinopathy;Blindness;Visualization;Kinematics;Time series analysis;Blindness;Granger causality;social interaction}, 
doi={10.1109/TCDS.2018.2809487}, 
ISSN={2379-8920}, 
month={Dec},}
@INPROCEEDINGS{8215273, 
author={G. H. M. {Marques} and D. C. {Einloft} and A. C. P. {Bergamin} and J. A. {Marek} and R. G. {Maidana} and M. B. {Campos} and I. H. {Manssour} and A. M. {Amory}}, 
booktitle={2017 Latin American Robotics Symposium (LARS) and 2017 Brazilian Symposium on Robotics (SBR)}, 
title={Donnie robot: Towards an accessible and educational robot for visually impaired people}, 
year={2017}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Robotics has been used to draw the attention of young students to computing and engineering. Unfortunately, most hardware and software resources used to teach programming and robotics are not adequate for students with visual impairment (VI). For instance, most programming environments for young students are highly visual and the commercial robotics kits were not built for people with VI. This paper describes the main design requirements so that both the proposed robot hardware and the software can also be used by people with VI. The hardware part is the focus of this paper, a robot called Donnie. It consists of open hardware, a design with low-cost and easy to find parts, and a 3D printed structure. Our main contribution is the presentation of a low-cost Arduino-based robot, compatible with Player robotic framework and integrated with sound feedback and text-to-speech.}, 
keywords={control engineering computing;educational robots;handicapped aids;microcontrollers;robot programming;3D printed structure;Arduino-based robot;open hardware;robot hardware;VI;visual impairment;visually impaired people;educational robot;accessible robot;Donnie robot;Player robotic framework;Robot sensing systems;Hardware;Economic indicators;Programming profession;Software;Educational Robotics;Assistive Robotics;Blind Programmers;Audio-based navigation}, 
doi={10.1109/SBR-LARS-R.2017.8215273}, 
ISSN={}, 
month={Nov},}
@ARTICLE{7867603, 
author={R. {Pitta Barros} and A. {Medeiros Filgueira Burlamaqui} and S. {Oliveira de Azevedo} and S. {Thomaz de Lima Sa} and L. {Marcos Garcia Goncalves} and A. {Aglae R S. da Silva Burlamaqui}}, 
journal={IEEE Latin America Transactions}, 
title={CardBot - Assistive Technology for Visually Impaired in Educational Robotics: Experiments and Results}, 
year={2017}, 
volume={15}, 
number={3}, 
pages={517-527}, 
abstract={We proposes an educational assistive methodology aiming to provide the access to educational robotics activities to students with visual impairments or low vision. As an approach to soften the main issues related to this challenging problem, we introduce a low cost, assistive technology, called CardBot 2.0. Basically, this model for teaching-learning is composed by a programming environment, a mobile application, and several geometric cards, each of them representing a specific action that is recognized by the application with a tag. So, the student can program the robot by selecting and organizing geometric cards on the surface of a board or on a table. Also a contribution of this work being part of the solution, the professor can create new cards and register the respective actions and tags. This allows the professor to add new actions for the robot or even to create a new language. We validated our approach by performing experimental classes for students with different visual impairments and ages, and for students without impairment, with an analysis of the results, qualitative.}, 
keywords={assisted living;educational robots;handicapped aids;mobile computing;robot programming;teaching;visually impaired;educational robotics;educational assistive methodology;CardBot 2.0;teaching-learning model;programming environment;mobile application;robot programming;geometric cards;Visualization;Robots;Assistive technology;IEEE transactions;Instruments;Programming environments;Mobile applications;Assistive Technologies;Educational Robotics;Visual Impairments}, 
doi={10.1109/TLA.2017.7867603}, 
ISSN={1548-0992}, 
month={March},}
@INPROCEEDINGS{8487612, 
author={J. L. {Castellanos-Cruz} and M. F. {Gomez-Medina} and M. {Tavakoli} and P. M. {Pilarski} and K. {Adams}}, 
booktitle={2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob)}, 
title={Preliminary Testing of a Telerobotic Haptic System and Analysis of Visual Attention During a Playful Activity}, 
year={2018}, 
volume={}, 
number={}, 
pages={1280-1285}, 
abstract={Children with physical impairments face great challenges to play because of their limitations, for example, in reaching and grasping obj ects. Children with physical impairments can improve their independence, cognitive, and social skills by playing using robots. In this study, we developed a telerobotic haptic system with two haptic robots, one that is for a child and the other to interact with the environment. The goal of this study was to do preliminary tests of the haptic guidance method and the prediction of targets. Another goal was to explore and analyze the visual attention of the participants during the activity when eye-hand discoordination was induced. Five adults without disabilities played a whack-a-mole game using the robotic system, to assure that the robot works adequately before children with disabilities use it. The robots were programmed to induce eye-hand discoordination, so that haptic guidance would be required. A multi-layer perceptron neural network was implemented to predict the target moles that the participants had to reach, which in future versions, will control the activation of forbidden region virtual fixtures (FRVF) to guide the user towards the target moles. Analysis of participant's eye gaze led to the hypothesis that the less control a person has over the teleoperation system, the less they will look at the target. On average, the accuracy of the target prediction by the neural network was 70.7%. The predicting of targets will allow the robot to assist children during movement of the robot towards the target toy, without needing the children to explicitly point out with their gaze which toy they want to reach. This will potentially lead to a more intuitive and faster human-robot interaction.}, 
keywords={control engineering computing;gaze tracking;handicapped aids;haptic interfaces;human-robot interaction;medical computing;multilayer perceptrons;neural nets;telerobotics;telerobotic haptic system;visual attention;playful activity;physical impairments;haptic robots;preliminary tests;haptic guidance method;eye-hand discoordination;disabilities;whack-a-mole game;robotic system;multilayer perceptron neural network;teleoperation system;target prediction;target toy;human-robot interaction;forbidden region virtual fixtures;FRVF;participants eye gaze analysis;Haptic interfaces;Toy manufacturing industry;Games;Telerobotics;Visualization;Robot sensing systems}, 
doi={10.1109/BIOROB.2018.8487612}, 
ISSN={2155-1782}, 
month={Aug},}
@ARTICLE{7491211, 
author={A. {Khasnobish} and A. {Konar} and D. N. {Tibarewala} and A. K. {Nagar}}, 
journal={IEEE Transactions on Neural Systems and Rehabilitation Engineering}, 
title={Bypassing the Natural Visual-Motor Pathway to Execute Complex Movement Related Tasks Using Interval Type-2 Fuzzy Sets}, 
year={2017}, 
volume={25}, 
number={1}, 
pages={91-105}, 
abstract={In visual-motor coordination, the human brain processes visual stimuli representative of complex motion-related tasks at the occipital lobe to generate the necessary neuronal signals for the parietal and pre-frontal lobes, which in turn generates movement related plans to excite the motor cortex to execute the actual tasks. The paper introduces a novel approach to provide rehabilitative support to patients suffering from neurological damage in their pre-frontal, parietal and/or motor cortex regions. An attempt to bypass the natural visual-motor pathway is undertaken using interval type-2 fuzzy sets to generate the approximate EEG response of the damaged pre-frontal/parietal/motor cortex from the occipital EEG signals. The approximate EEG response is used to trigger a pre-trained joint coordinate generator to obtain the desired joint coordinates of the link end-points of a robot imitating the human subject. The robot arm is here employed as a rehabilitative aid in order to move each link end-points to the desired locations in the reference coordinate system by appropriately activating its links using the well-known inverse kinematics approach. The mean-square positional errors obtained for each link end-points is found within acceptable limits for all experimental subjects including subjects with partial parietal damage, indicating a possible impact of the proposed approach in rehabilitative robotics. Subjective variation in EEG features over different sessions of experimental trials is modeled here using interval type-2 fuzzy sets for its inherent power to handle uncertainty. Experiments undertaken confirm that interval type-2 fuzzy realization outperforms its classical type-1 counterpart and back-propagation neural approaches in all experimental cases, considering link positional error as a metric. The proposed research offers a new opening for the development of possible rehabilitative aids for people with partial impairment in visual-motor coordination.}, 
keywords={electroencephalography;fuzzy set theory;kinematics;medical robotics;medical signal processing;neurophysiology;patient rehabilitation;visual evoked potentials;natural visual-motor pathway;complex movement related tasks;interval type-2 fuzzy sets;visual-motor coordination;human brain process visual stimuli;occipital lobe;neuronal signals;parietal lobes;prefrontal lobes;motor cortex;rehabilitative support;neurological damage;EEG response;occipital EEG signals;joint coordinate generator;robot arm;rehabilitative aid;inverse kinematics approach;mean-square positional errors;partial parietal damage;rehabilitative robotics;EEG features;back-propagation neural approaches;link positional error;Electroencephalography;Fuzzy sets;Robot kinematics;Visualization;Uncertainty;Robot sensing systems;Bypassing natural visual–motor pathways;Fuzzy mapping;Interval type-2 fuzzy sets;Prediction of positional body joint coordinates and Inverse kinematics in Robotics;Rehabilitative aids for visual–motor impairment;Adult;Brain-Computer Interfaces;Cerebral Cortex;Electroencephalography;Fuzzy Logic;Humans;Man-Machine Systems;Middle Aged;Movement;Movement Disorders;Neural Pathways;Neurological Rehabilitation;Pattern Recognition, Automated;Psychomotor Performance;Reproducibility of Results;Robotics;Sensitivity and Specificity}, 
doi={10.1109/TNSRE.2016.2580580}, 
ISSN={1534-4320}, 
month={Jan},}
@INPROCEEDINGS{8460578, 
author={G. {Beraldo} and M. {Antonello} and A. {Cimolato} and E. {Menegatti} and L. {Tonin}}, 
booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
title={Brain-Computer Interface Meets ROS: A Robotic Approach to Mentally Drive Telepresence Robots}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={This paper shows and evaluates a novel approach to integrate a non-invasive Brain-Computer Interface (BCI) with the Robot Operating System (ROS) to mentally drive a telepresence robot. Controlling a mobile device by using human brain signals might improve the quality of life of people suffering from severe physical disabilities or elderly people who cannot move anymore. Thus, the BCI user can actively interact with relatives and friends located in different rooms thanks to a video streaming connection to the robot. To facilitate the control of the robot via BCI, we explore new ROS-based algorithms for navigation and obstacle avoidance in order to make the system safer and more reliable. In this regard, the robot exploits two maps of the environment, one for localization and one for navigation, and both are used as additional visual feedback for the BCI user to control the robot position. Experimental results show a decrease of the number of commands needed to complete the navigation task, suggesting a reduction user's cognitive workload. The novelty of this work is to provide a first evidence of an integration between BCI and ROS that can simplify and foster the development of software for BCI driven robotics devices.}, 
keywords={brain;brain-computer interfaces;collision avoidance;control engineering computing;geriatrics;handicapped aids;learning (artificial intelligence);medical robotics;medical signal processing;mobile robots;operating systems (computers);patient rehabilitation;position control;robot programming;telerobotics;video streaming;noninvasive Brain-Computer Interface;Robot Operating System;telepresence robot;mobile device;human brain signals;severe physical disabilities;elderly people;BCI user;robot position control;obstacle avoidance;video streaming;Navigation;Robot sensing systems;Task analysis;Telepresence;Brain-computer interfaces}, 
doi={10.1109/ICRA.2018.8460578}, 
ISSN={2577-087X}, 
month={May},}
@ARTICLE{8362728, 
author={H. {Yoon} and J. H. {Jeong} and B. {Yi}}, 
journal={IEEE Transactions on Robotics}, 
title={Image-Guided Dual Master–Slave Robotic System for Maxillary Sinus Surgery}, 
year={2018}, 
volume={34}, 
number={4}, 
pages={1098-1111}, 
abstract={The pathway to the maxillary sinus is anatomically curved and narrow. Thus, the conventional approach using a straight endoscope and surgical tools is difficult to diagnose and treat some blind regions of the maxillary sinus through the nostrils. Such cases are usually dealt with by an approach with an external incision that causes large invasive surgery. In order to approach the blind regions without any external incision, a new bendable device and an image-guided robotic approach for the maxillary sinus surgery are required. This work reports design, development, and validation of an image-guided dual master-slave robotic system for the maxillary sinus surgery. Initially, specifications of the robotic system for sinus surgery are decided by analysis of the anatomical structure of the sinus. A method for determining the design parameters of continuum type salve robot is also presented. Based on the specifications and the design parameter determining method, a compact design of bendable dual slave robotic system for inspection and biopsy operation of the maxillary sinus area is devised and workspace analysis for verifying the robot design is conducted. The performance of the dual master-slave system equipped with flexible devices is validated through several phantom tests. The results suggest that bendable end-effectors and navigation software are useful to navigate and treat blind regions inside general sinus areas as well as the maxillary sinus.}, 
keywords={end effectors;endoscopes;inspection;medical image processing;medical robotics;motion control;phantoms;surgery;maxillary sinus surgery;conventional approach;blind regions;invasive surgery;image-guided robotic approach;robot design;master-slave robotic system;slave robotic system;biopsy operation;Surgery;Robots;Endoscopes;Navigation;Biopsy;Tools;Lesions;Bendable device;dual arm;master–slave system;maxillary sinus;navigation;sinus surgery}, 
doi={10.1109/TRO.2018.2830334}, 
ISSN={1552-3098}, 
month={Aug},}
@INPROCEEDINGS{8460588, 
author={G. {Gras} and C. A. {Seneci} and P. {Giataganas} and G. {Yang}}, 
booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, 
title={Gaze-Assisted Adaptive Motion Scaling Optimization Using Graded and Preference Based Bayesian Approaches}, 
year={2018}, 
volume={}, 
number={}, 
pages={6425-6430}, 
abstract={A key component to the success of master-slave surgical systems is the quality of the master interface used to relay the surgeon's instructions to the slave robot. In previous work the authors developed a gaze-assisted intention recognition scheme, allowing the system to dynamically adapt the motion scaling based on where the user is trying to reach. This allowed users to perform tasks significantly more quickly and with less need for clutching. However, the system possessed a number of core parameters that were manually optimized, potentially providing a non-optimal solution depending on the user. This paper presents a Bayesian approach to the problem of optimizing a human-robot interface in a user-specific manner. Two Bayesian optimization methods are studied: one in which users are asked to grade robot behavior for a given set of parameters, and one where only preference relative to other parameter sets is expressed. The performance of these optimizations is evaluated in a blind comparison user study, demonstrating that the optimized parameters are preferred to the manually optimized ones in over 90 % of cases after only 12 test samples. These parameters are further shown to perform at least as well as the manually optimized ones in all cases, and showing statistically significant improvement in the case of the graded optimization.}, 
keywords={adaptive control;Bayes methods;human-robot interaction;medical robotics;optimisation;surgery;telerobotics;gaze-assisted adaptive motion scaling optimization;Bayesian approaches;master-slave surgical systems;slave robot;gaze-assisted intention recognition scheme;Bayesian approach;human-robot interface;Bayesian optimization methods;Robots;Bayes methods;Instruments;Linear programming;Optimization methods;Master-slave}, 
doi={10.1109/ICRA.2018.8460588}, 
ISSN={2577-087X}, 
month={May},}
@INPROCEEDINGS{8561000, 
author={D. Z. V. {G.} and E. B. G. {V.} and N. E. C. {R.}}, 
booktitle={2017 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
title={ROSmotic: A Scalable Smart Home for Blind People Controlled with an App}, 
year={2017}, 
volume={}, 
number={}, 
pages={1365-1370}, 
abstract={In this paper we present ROSmotic, a system for building smart homes operated by a smartphone app. The app is accessible for people with visual disabilities, and controlled by touch or voice commands. We provide a scalable and open source hardware and software solution by incorporating microcontrollers, cameras, laptops, and lights. We show an easy way to connect an iOS app with Robotics Operating System (ROS). We incorporate other open source libraries, cloud services, and image processing frameworks. The whole system is made in Swift and Python. Finally, we deliver the diagrams (logical and electronic), software code, and materials for its easy replication.}, 
keywords={cameras;cloud computing;handicapped aids;home automation;iOS (operating system);microcontrollers;mobile computing;public domain software;robot programming;smart phones;open source libraries;image processing frameworks;software code;ROSmotic;blind people;smart homes;smartphone app;visual disabilities;open source hardware;software solution;iOS app;cloud services;voice commands;touch commands;robotics operating system;microcontrollers;component;smart home;ROS;mobile app;visually impaired users;scalability}, 
doi={10.1109/CSCI.2017.238}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{7857377, 
author={T. A. N. {Gacharná} and A. D. Á. {Rodríguez} and C. {Barbosa}}, 
booktitle={2016 IEEE Global Humanitarian Technology Conference (GHTC)}, 
title={Learning strategies in mobile and industrial robotics for people with auditory impairment}, 
year={2016}, 
volume={}, 
number={}, 
pages={836-841}, 
abstract={The difficulties of learning (comprehension and interpretation of the information), the lack of tools for virtual support and their own disability are the main reasons of students' dropout in Colombia specially in higher education programs for people with hearing impairment, which reduces significantly their opportunities in the professional field. This research aims to develop learning strategies for people with hearing disability in the fields of mobile and industrial robotics. To achieve this objective, pedagogical and didactical tools in virtual learning environments ICT (Information and Communications Technology) were designed, along with classroom training that facilitated learning and improved cognitive processes in students with hearing impairments. The most important results achieved in this work are: a greater degree of ownership and knowledge generation by deaf students, which impacted on their social inclusion level and labor skills level through the ICT Development of a mini sumo robot and a soccer robot by deaf students. This project also enhanced the competence in manufacturing programmable automaton systems, generation of new signs to denote different electronic devices such as Optical Sensors, H-Bridge, among others. The main conclusion is the evidence of the potential of ICT in generating greater social inclusion and employment opportunities for people with hearing disabilities.}, 
keywords={computer based training;control engineering education;employment;factory automation;handicapped aids;industrial robots;manufacturing systems;mobile robots;multi-robot systems;employment opportunities;electronic devices;manufacturing programmable automaton systems;soccer robot;mini sumo robot;labor skill level;social inclusion level;deaf students;knowledge generation;cognitive processes;classroom training;information and communications technology;ICT;virtual learning environments;mobile robotics;hearing disability;learning strategies;auditory impairment;industrial robotics;Conferences;Education;Sociology;Statistics;Hearing impairment;information and communications technology;inclusion;learning}, 
doi={10.1109/GHTC.2016.7857377}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{8512754, 
author={M. {Bernardinis} and S. F. {Atashzar} and M. {Jog} and R. V. {Patel}}, 
booktitle={2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
title={Visual Displacement Perception in Parkinson's Disease Analyzed Using a Computer-Generated Graphical Tool}, 
year={2018}, 
volume={}, 
number={}, 
pages={2748-2751}, 
abstract={Parkinson's Disease (PD) is typically classified by the onset of motor impairments, however, non-motor symptoms are also present in all disease stages. Vision abnormalities contribute to the non-motor PD deficits, yet little research has studied how PD affects visual perceptions with no produced motor responses. This provides motivation for the current study which focuses on examining allocentric visual displacement perception - information used for object identification - in PD patients. To study this PD participants OFF and ON Levodopa therapy, and age-matched healthy control participants were tested. A modular graphics toolbox was implemented to carry out the perceptual testing. Individuals with PD were shown to have impairments in displacement perception of the larger tested magnitudes when both OFF and ON Levodopa compared to control participants, suggesting impairments in visual displacement processing pathways. These abnormalities could contribute to difficulties some PD patients have with visual recognition and visuospatial navigation. Furthermore, the study validated the graphical tool as a means of quantifying perceptual abilities that can be expanded to many perceptual modalities and paired with robotic devices.}, 
keywords={brain;cognition;diseases;medical computing;medical disorders;neurophysiology;patient diagnosis;patient treatment;visual perception;Parkinson's disease;computer-generated graphical tool;motor impairments;nonmotor symptoms;disease stages;vision abnormalities;nonmotor PD deficits;visual perceptions;produced motor responses;allocentric visual displacement perception - information;PD patients;PD participants OFF;Levodopa therapy;age-matched healthy control participants;modular graphics toolbox;perceptual testing;larger tested magnitudes;visual displacement processing pathways;visual recognition;Visualization;Standards;PD control;Green products;Tools;Diseases;Visual perception}, 
doi={10.1109/EMBC.2018.8512754}, 
ISSN={1558-4615}, 
month={July},}
@ARTICLE{8118304, 
author={Q. {Wu} and X. {Wang} and B. {Chen} and H. {Wu}}, 
journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
title={Development of a Minimal-Intervention-Based Admittance Control Strategy for Upper Extremity Rehabilitation Exoskeleton}, 
year={2018}, 
volume={48}, 
number={6}, 
pages={1005-1016}, 
abstract={The applications of robotics to the rehabilitation training of neuromuscular impairments have received increasing attention due to their promising prospects. The effectiveness of robot-assisted training directly depends on the control strategy applied in the therapy program. This paper presents an upper extremity exoskeleton for the functional recovery training of disabled patients. A minimal-intervention-based admittance control strategy is developed to induce the active participation of patients and maximize the use of recovered motor functions during training. The proposed control strategy can transit among three control modes, including human-conduct mode, robot-assist mode, and motion-restricted mode, based on the real-time position tracking errors of the end-effector. The human-robot interaction in different working areas can be modulated according to the motion intention of patient. Graphical guidance developed in Unity-3-D environment is introduced to provide visual training instructions. Furthermore, to improve training performance, the controller parameters should be adjusted in accordance with the hemiplegia degree of patients. For the patients with severe paralysis, robotic assistance should be increased to guarantee the accomplishment of training. For the patients recovering parts of motor functions, robotic assistance should be reduced to enhance the training intensity of effected limb and improve therapeutic effectiveness. The feasibility and effectiveness of the proposed control scheme are validated via training experiments with two healthy subjects and six stroke patients with different degrees of hemiplegia.}, 
keywords={end effectors;human-robot interaction;medical robotics;motion control;neurophysiology;patient rehabilitation;patient treatment;wearable robots;visual training instructions;training performance;controller parameters;robotic assistance;training intensity;control scheme;training experiments;stroke patients;upper extremity rehabilitation exoskeleton;rehabilitation training;neuromuscular impairments;upper extremity exoskeleton;functional recovery training;disabled patients;recovered motor functions;control modes;human-conduct mode;motion-restricted mode;human-robot interaction;Minimal-intervention-based Admittance Control Strategy;therapy program;end-effector;Training;Robots;Exoskeletons;Extremities;Trajectory;Medical treatment;Real-time systems;Admittance control strategy;human–robot interaction;minimal-intervention-based;rehabilitation;upper extremity exoskeleton}, 
doi={10.1109/TSMC.2017.2771227}, 
ISSN={2168-2216}, 
month={June},}
@ARTICLE{8263400, 
author={S. {Haddadin} and K. {Krieger} and A. {Albu-Schäffer} and T. {Lilge}}, 
journal={IEEE Transactions on Robotics}, 
title={Exploiting Elastic Energy Storage for “Blind” Cyclic Manipulation: Modeling, Stability Analysis, Control, and Experiments for Dribbling}, 
year={2018}, 
volume={34}, 
number={1}, 
pages={91-112}, 
abstract={For creating robots that are capable of human-like performance in terms of speed, energetic properties, and robustness, intrinsic compliance is a promising design element. In this paper, we investigate the principle effects of elastic energy storage and release for basketball dribbling in terms of open-loop cycle stability. We base the analysis, which is performed for the 1-degree-of-freedom (DoF) case, on error propagation, peak power performance during hand contact, and robustness with respect to varying hand stiffness. As the ball can only be controlled during contact, an intrinsically elastic hand extends the contact time and improves the energetic characteristics of the process. To back up our basic insights, we extend the 1-DoF controller to 6-DoFs and show how passive compliance can be exploited for a 6-DoF cyclic ball dribbling task with a 7-DoF articulated Cartesian impedance controlled robot. As a human is able to dribble blindly, we decided to focus on the case of contact force sensing only, i.e., no visual information is necessary in our approach. We show via simulation and experiment that it is possible to achieve a stable dynamic cycle based on the 1-DoF analysis for the primary vertical axis together with control strategies for the secondary translations and rotations of the task. The scheme allows also the continuous tracking of a desired dribbling height and horizontal position. The approach is also used to hypothesize about human dribbling and is validated with captured data.}, 
keywords={control system synthesis;elasticity;force control;humanoid robots;manipulator dynamics;manipulators;mobile robots;motion control;position control;sport;stability;elastic energy storage;blind;cyclic manipulation;stability analysis;robots;energetic properties;intrinsic compliance;principle effects;basketball dribbling;open-loop cycle stability;error propagation;peak power performance;hand contact;hand stiffness;contact time;energetic characteristics;1-DoF controller;6-DoFs;passive compliance;6-DoF cyclic ball dribbling;7-DoF articulated Cartesian impedance;contact force;stable dynamic cycle;1-DoF analysis;control strategies;human dribbling;design element;elastic hand;dribbling height;Robots;Stability analysis;Analytical models;Elasticity;Trajectory;Springs;Cycle stability analysis;disturbance observer;elastic energy storage;flexible joint manipulators;limit cycles;variable stiffness actuation}, 
doi={10.1109/TRO.2017.2765684}, 
ISSN={1552-3098}, 
month={Feb},}
@ARTICLE{8464299, 
author={T. {Liu} and H. {Liu} and Y. {Li} and Z. {Zhang} and S. {Liu}}, 
journal={IEEE/ASME Transactions on Mechatronics}, 
title={Efficient Blind Signal Reconstruction With Wavelet Transforms Regularization for Educational Robot Infrared Vision Sensing}, 
year={2019}, 
volume={24}, 
number={1}, 
pages={384-394}, 
abstract={Fourier transform infrared (FTIR) imaging spectrometers are often corrupted by the problems of band overlap and random noise during the infrared spectrum acquisition process. Such noise would degrade the quality of the acquired infrared spectrum, limiting the precision of the subsequent processing. In this paper, we present a novel blind reconstruction method with wavelet transform regularizations for infrared spectrum obtained from the aging instrument. Inspired by the finding that the wavelet coefficient distribution of the clean spectrum is sparser than that of the degraded spectrum, a blind reconstruction model for infrared spectrum is proposed in this paper to regularize the distribution of the degraded spectrum by total variation regularization. This method outperforms when suppressing random noise and preserving the spectral structure details. In addition, an effective optimization scheme is introduced in overcoming the issue of formulated optimization. The instrument response function and latent spectrum can be simultaneously estimated through the proposed method that can efficiently mitigate the effects caused by instrument degradation. Finally, extensive experiments on simulated and real noisy infrared spectra are carried out to demonstrate the superiority of the proposed method over the existing state-of-the-art ones. Thus, the reconstructed spectrum will better serve the feature extraction and educational robot infrared vision sensing in industrial applications.}, 
keywords={deconvolution;educational robots;feature extraction;Fourier transform infrared spectra;image denoising;image reconstruction;infrared imaging;infrared spectra;optimisation;random noise;robot vision;spectral analysis;wavelet transforms;educational robot infrared vision sensing;infrared spectrum acquisition process;wavelet coefficient distribution;clean spectrum;degraded spectrum;total variation regularization;latent spectrum;instrument degradation;simulated spectra;real noisy infrared spectra;reconstructed spectrum;random noise suppression;blind signal reconstruction model;FTIR imaging spectrometers;wavelet transform regularization;Fourier transform infrared imaging spectrometer;aging instrument;spectral structure detail preservation;effective optimization scheme;instrument response function;feature extraction;industrial applications;Wavelet transforms;Image reconstruction;Instruments;Mechatronics;Imaging;IEEE transactions;FTIR imaging spectrometers;instrumentation;mechatronics industry;optical data processing;robot vision;wavelet transforms}, 
doi={10.1109/TMECH.2018.2870056}, 
ISSN={1083-4435}, 
month={Feb},}
@ARTICLE{7467533, 
author={X. {Zhao} and Y. {Chu} and J. {Han} and Z. {Zhang}}, 
journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
title={SSVEP-Based Brain–Computer Interface Controlled Functional Electrical Stimulation System for Upper Extremity Rehabilitation}, 
year={2016}, 
volume={46}, 
number={7}, 
pages={947-956}, 
abstract={Traditional rehabilitation techniques have limited effects on the recovery of patients with tetraplegia. A brain-computer interface (BCI) provides an interactive channel that does not depend on the normal output of peripheral nerves and muscles. In this paper, an integrated framework of a noninvasive electroencephalogram (EEG)-based BCI with a noninvasive functional electrical stimulation (FES) is established, which can potentially enable the upper limbs to achieve more effective motor rehabilitation. The EEG signals based on steady-state visual evoked potential are used in the BCI. Their frequency domain characteristics identified by the pattern recognition method are utilized to recognize intentions of five subjects with average accuracy of 73.9%. Furthermore the movement intentions are transformed into instructions to trigger FES, which is controlled with iterative learning control method, to stimulate the relevant muscles of upper limbs tracking desired velocity and position. It is a useful technology with potential to restore, reinforce or replace lost motor function of patients with neurological injuries. Experiments with five healthy subjects demonstrate the feasibility of BCI integrated with upper extremity FES toward improved function restoration for an individual with upper limb disabilities, especially for patients with tetraplegia.}, 
keywords={brain-computer interfaces;electroencephalography;frequency-domain analysis;iterative learning control;medical control systems;SSVEP;brain-computer interface controlled functional electrical stimulation system;upper extremity rehabilitation;BCI;interactive channel;noninvasive electroencephalogram;EEG signals;noninvasive functional electrical stimulation;FES;steady-state visual;frequency domain characteristics;pattern recognition method;iterative learning control method;function restoration;Visualization;Muscles;Electroencephalography;Extremities;Robots;Performance evaluation;Time-frequency analysis;Brain-computer interfaces;functional electrical stimulation;human-robot interaction;intelligent control;rehabilitation robotics;Brain–computer interfaces;functional electrical stimulation;human–robot interaction;intelligent control;rehabilitation robotics}, 
doi={10.1109/TSMC.2016.2523762}, 
ISSN={2168-2216}, 
month={July},}
@INPROCEEDINGS{7910248, 
author={Z. {Zhu} and J. {Xiao}}, 
booktitle={2017 IEEE Integrated STEM Education Conference (ISEC)}, 
title={CCNY joint senior design program in assistive technology across department boundaries}, 
year={2017}, 
volume={}, 
number={}, 
pages={52-60}, 
abstract={We have built a cross-department joint senior design program at The City College of New York (CCNY) for undergraduate seniors majoring in Computer Science (CS), Computer Engineering (CpE) and Electrical Engineering (EE), to develop assistive technologies for people in need. These include: multimodal, passive and unobtrusive techniques for helping visually impaired people achieve independent travel in unfamiliar environments; smart house systems and mobile apps for improving the quality of life of elderly people and people with disabilities (e.g. with Autism Spectrum Disorder); and sensing technologies for health monitoring and rehabilitation. For evaluating the designs by students, we also have faculty and students from the Psychology Department involved in our team projects. The joint senior design course builds on our existing capstone design course structure in the CS and EE Departments, which also jointly manage the CpE program. We have obtained multiple grants/awards from the National Science Foundation, the NYS Industries for Disabilities and VentureWell to run this course with cross-disciplinary collaboration, learning-by-doing learning experience, student-led class schedules, team building practices, user-in-the-loop development and entrepreneurship training, and oral/writing presentation practices.}, 
keywords={assisted living;computer science education;educational courses;electrical engineering education;geriatrics;medical computing;mobile computing;patient monitoring;patient rehabilitation;CCNY joint senior design program;assistive technology;department boundaries;The City College of New York;CCNY;Computer Science;Computer Engineering;Electrical Engineering;CpE;CS;EE;smart house systems;mobile apps;health monitoring;health rehabilitation;psychology department;national science foundation;NYS industries;learning-by-doing learning experience;student-led class schedules;team building practices;user-in-the-loop development;entrepreneurship training;oral-writing presentation practices;Assistive technology;Entrepreneurship;Computers;Autism;Robot sensing systems;assistive technology;cross-disciplinary projects;student entrepreneurship;team-based senior design;total design methodology}, 
doi={10.1109/ISECon.2017.7910248}, 
ISSN={}, 
month={March},}
@INPROCEEDINGS{8557324, 
author={Q. {Chen} and B. {Tan} and K. {Woodbridge} and K. {Chetty}}, 
booktitle={2018 International Conference on Radar (RADAR)}, 
title={Doppler Based Detection of Multiple Targets in Passive Wi-Fi Radar Using Underdetermined Blind Source Separation}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-6}, 
abstract={Passive approaches for detecting and localizing people in wireless environments have attracted significant attention because of its diverse application in healthcare, security and robotics in recent years. However, within indoor environments multiple people moving in close proximity to each other often impedes the utility of such approaches. In this paper we present a new method for identifying multiple human targets in Wi-Fi passive radar systems using only a single receive channel to detect Doppler returns. The technique is based on tree-structure sparse underdetermined blind source separation and utilizes proximal alternating methods in a convex optimization field. Firstly, we show proof-of-principle simulation results for two targets moving within a typical indoor scenario and compare the results with those from the well-known independent component analysis (ICA). Secondly, we validate the simulation outputs using real-world experimental data. The results demonstrate the effectiveness of the proposed technique for device-free detection of multiple targets in the indoor wireless landscape.}, 
keywords={blind source separation;convex programming;Doppler radar;independent component analysis;object detection;passive radar;radar detection;radar signal processing;target tracking;trees (mathematics);wireless LAN;typical indoor scenario;device-free detection;indoor wireless landscape;Doppler based detection;passive approaches;wireless environments;robotics;Wi-Fi passive radar systems;tree-structure sparse underdetermined blind source separation;convex optimization field;multiple target detection;indoor environments;proof-of-principle simulation;proximal alternating methods;people localization;people detection;multiple human target identification;single receive channel;Doppler return detection;independent component analysis;ICA;real-world experimental data;Passive Wi-Fi radar;Multiple target detection;Underdetermined Blind Source Separation;proximal alternating Linearized minimization}, 
doi={10.1109/RADAR.2018.8557324}, 
ISSN={}, 
month={Aug},}
@ARTICLE{8103886, 
author={Y. {Bando} and K. {Itoyama} and M. {Konyo} and S. {Tadokoro} and K. {Nakadai} and K. {Yoshii} and T. {Kawahara} and H. G. {Okuno}}, 
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
title={Speech Enhancement Based on Bayesian Low-Rank and Sparse Decomposition of Multichannel Magnitude Spectrograms}, 
year={2018}, 
volume={26}, 
number={2}, 
pages={215-230}, 
abstract={This paper presents a blind multichannel speech enhancement method that can deal with the time-varying layout of microphones and sound sources. Since nonnegative tensor factorization (NTF) separates a multichannel magnitude (or power) spectrogram into source spectrograms without phase information, it is robust against the time-varying mixing system. This method, however, requires prior information such as the spectral bases (templates) of each source spectrogram in advance. To solve this problem, we develop a Bayesian model called robust NTF (Bayesian RNTF) that decomposes a multichannel magnitude spectrogram into target speech and noise spectrograms based on their sparseness and low rankness. Bayesian RNTF is applied to the challenging task of speech enhancement for a microphone array distributed on a hose-shaped rescue robot. When the robot searches for victims under collapsed buildings, the layout of the microphones changes over time and some of them often fail to capture target speech. Our method robustly works under such situations, thanks to its characteristic of time-varying mixing system. Experiments using a 3-m hose-shaped rescue robot with eight microphones show that the proposed method outperforms conventional blind methods in enhancement performance by the signal-to-noise ratio of 1.03 dB.}, 
keywords={Bayes methods;matrix decomposition;microphone arrays;microphones;pose estimation;rescue robots;speech enhancement;tensors;time-of-arrival estimation;signal-to-noise ratio;microphones;hose-shaped rescue robot;enhancement performance;conventional blind methods;microphones changes;rescue robot;microphone array;low rankness;sparseness;noise spectrograms;target speech;Bayesian RNTF;robust NTF;Bayesian model;time-varying mixing system;phase information;source spectrogram;nonnegative tensor factorization;sound sources;time-varying layout;blind multichannel speech enhancement method;multichannel magnitude spectrogram;sparse decomposition;Bayesian low-rank;noise figure 1.03 dB;Spectrogram;Bayes methods;Speech enhancement;Speech;Microphones;Robustness;Robots;Multichannel speech enhancement;low-rank and sparse decomposition;Bayesian signal processing}, 
doi={10.1109/TASLP.2017.2772340}, 
ISSN={2329-9290}, 
month={Feb},}
@INPROCEEDINGS{7733992, 
author={B. {Xu} and G. {Wen} and Z. {Zhang} and F. {Chen}}, 
booktitle={2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)}, 
title={Genetic programming-based classification of ferrograph wear particles}, 
year={2016}, 
volume={}, 
number={}, 
pages={842-847}, 
abstract={Ferrograph analysis is becoming one of the principal methods for condition monitoring and fault diagnosis of the machinery equipment due to its advantages of visualization and efficiency. One of the major challenges of ferrograph analysis is feature construction from the existing features of wear particles to improve classifier efficiency. The current feature construction method is trial and error based on previous experience and mass data, which is time-consuming, laborious and blindness. In this paper, genetic programming-based approach was proposed to construct new features from the five existing morphological features of ferrograph wear particles to improve the ability of classification process. The GP-based feature construction approach is used for fault classification of ferrograph wear particles for the first time and the results show that the method can be used in wear condition monitoring and fault prognosis of machinery equipment.}, 
keywords={condition monitoring;fault diagnosis;feature extraction;genetic algorithms;image classification;machinery;mechanical engineering computing;wear;feature construction;machinery equipment;fault diagnosis;condition monitoring;ferrograph analysis;ferrograph wear particle;fault classification;GP;genetic programming;Genetic programming;Ferrograph;Wear particles;Feature evolution;Wear condition classification}, 
doi={10.1109/URAI.2016.7733992}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7734069, 
author={W. {Yang} and X. {Zhang} and H. {Ma}}, 
booktitle={2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)}, 
title={An inspection robot using infrared thermography for belt conveyor}, 
year={2016}, 
volume={}, 
number={}, 
pages={400-404}, 
abstract={The key mechanical components of belt conveyor is lack of effective monitoring at present. The traditional monitoring methods such as visual inspection, temperature measurement have shortcoming, the huge workload, blind spots and other issues are difficult to solve. This paper proposes an inspection robot program with infrared thermometer for belt conveyor. Along the inspection track, the motor drive the infrared thermometer moves which mounted on robot. Infrared thermal image of motor, pulleys, rollers and other key transmission components are captured. With image signal processing and pattern recognition technology, the infrared images are processed. After infrared image segmentation, feature extraction and classification, the automatic identification of the typical elements are realized. Finally, make use of the component type that has identified, the warning temperature values and contract the library rules of failure database, this paper achieves a Failure Prognostic System (FRS) on drive system of belt conveyor. Experimental results show that the method can achieve automatic identification and fault warning abnormal temperature rise of motor, pulley and roller and the other mechanical components.}, 
keywords={conveyors;feature extraction;image classification;image segmentation;industrial robots;infrared imaging;inspection;robot vision;temperature;drive system;warning temperature value;FRS;failure prognostic system;feature classification;feature extraction;infrared image segmentation;infrared image processing;pattern recognition technology;image signal processing;transmission components;inspection track;belt conveyor;infrared thermography;inspection robot;Image segmentation;Belts;Entropy;MATLAB;Drives;Monitoring;Inspection robot;Belt Conveyor;Infrared thermography;Pattern recognition;Failure Prognostic}, 
doi={10.1109/URAI.2016.7734069}, 
ISSN={}, 
month={Aug},}
@INPROCEEDINGS{7754473, 
author={R. {Devi} and N. {Prabakaran}}, 
booktitle={2016 International Conference on Communication and Signal Processing (ICCSP)}, 
title={Design and implementation of application using voice control oversmart watch}, 
year={2016}, 
volume={}, 
number={}, 
pages={1781-1785}, 
abstract={The extent of this anticipate - Smart Watch application using Remote Innovation is to assemble an android application for WIRELESS SENSOR NETWORK. This anticipates is being created using android wear application by technique for OPTICAL HEART RATE Screen sensor. This shrewd watches outfit customers with access to various applications particularly from their wrists, without the need to touch their propelled cellular telephones. In this paper expect an essential part when the customer is in Perilous or in Limited Ranges. Various once in a while client disregard to take note of various basic call alerts and sends, however I have procured the thought of savvy to handle these kind of unavoidable circumstances, savvy gives us a vibrate when we get any alarms. In our proposed technique for android savvy has taken us absolutely to a next level; it in like manner enables the clients to get the installment check subtle elements taking into account the voice summons, It is of great noteworthiness for visually impaired or halfway located individuals who can't access visual information, as we have progressed another arrangement of getting recorded voice as yield. The choosing thing which has been made for wear contraption will offer important cost venture subsidizes and enable new handiness. It will have a whip hand in the straightforwardness of execution, ability to work in ruthless circumstances and large amounts of exhibitions.}, 
keywords={Android (operating system);mobile computing;notebook computers;wireless sensor networks;voice control oversmart watch;smart watch application;remote innovation;wireless sensor network;Android wear application;optical heart rate screen sensor;cellular telephones;basic call alerts;visually impaired individuals;halfway located individuals;visual information;Smart phones;Bluetooth;Androids;Humanoid robots;Programming;Libraries;Linux;Smart watch;Android phone;optical heart-rate monitor;Bluetooth}, 
doi={10.1109/ICCSP.2016.7754473}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{7877733, 
author={N. {Patil} and D. {Bhole} and P. {Shete}}, 
booktitle={2016 International Conference on Automatic Control and Dynamic Optimization Techniques (ICACDOT)}, 
title={Enhanced UI Automator Viewer with improved Android accessibility evaluation features}, 
year={2016}, 
volume={}, 
number={}, 
pages={977-983}, 
abstract={Inaccessible user interfaces of the applications in Android systems such as unlabeled interactive controls, lack of form element hint, lack of focus on the important interactive controls, improper directional navigation etc. are hurdles of users with all kinds of disabilities. Manual accessibility testing is tedious job for Applications developers. Also efficient semi automated Android accessibility evaluation tool which can evaluate all the accessibility developer's checklist are not available. These could be important reasons of non consideration of accessibility while developing Android applications. This paper presents enhancement of UI Automator Viewer a tool for evaluation of applications accessibility in Android environment. Limitation of UI Automator Viewer are eliminated by adding new features “Target device selection”, which allows the developer to select target device among multiple connected devices for automation testing, “Capture and play”, include Touch Event and key Event which help to send UI event to and retrieve information from connected device and “Color contrast” which shows color contrast of captured screenshot which helps the mobile application developer to represent their application for color blind and low vision persons and to make sure that all visual designs meet the minimum color-contrast ratio for normal and large text on a background. Testing accessibility of user interfaces of Android mobile applications become more efficient by the enhanced tool which can identify accessibility issues of user interfaces of Android applications and assist developers to create accessible user interfaces.}, 
keywords={Android (operating system);automation;program testing;software engineering;user interfaces;UI automator viewer;Android accessibility evaluation features;application user interfaces;Android systems;manual accessibility testing;application developers;semiautomated Android accessibility evaluation tool;accessibility developer checklist evaluation;application evaluation;target device selection;automation testing;capture and play;touch event;key event;color contrast;captured screenshot contrast;mobile application developer;visual designs;color-contrast ratio;accessible user interfaces;Testing;Mobile communication;Androids;Humanoid robots;Smart phones;Graphical user interfaces;Mobile applications;Android Mobile accessibility;Accessibility testing tool UI Automation;UI Automator Viewer}, 
doi={10.1109/ICACDOT.2016.7877733}, 
ISSN={}, 
month={Sep.},}
@ARTICLE{7831485, 
author={H. {Yang} and W. {Shin} and J. {Lee}}, 
journal={IEEE Transactions on Wireless Communications}, 
title={Linear Degrees of Freedom for $K$ -user MISO Interference Channels With Blind Interference Alignment}, 
year={2017}, 
volume={16}, 
number={3}, 
pages={1921-1934}, 
abstract={In this paper, we characterize the degrees of freedom (DoF) for K-user M × 1 multiple-input single-output interference channels with reconfigurable antennas, which have N-preset modes at the receivers, assuming linear coding strategies in the absence of channel state information at the transmitters, i.e., blind interference alignment. Our linear DoF converse builds on the lemma that if a set of transmit symbols is aligned at their common unintended receivers, those symbols must have independent signal subspace at their corresponding receivers. This lemma arises from the inherent feature that channel state's changing patterns of the links towards the same receiver are always identical, assuming that the coherence time of the channel is long enough. We derive an upper bound for the linear sum DoF, and propose an achievable scheme that exactly achieves the linear sum DoF upper bound when both of the n*/M = R1and MK/n* = R2are integers, where n* denotes the optimal number of preset modes out of N preset modes. For the other cases, where either R1or R2is not an integer, we only give some guidelines how the interfering signals are aligned at the receivers to achieve the upper bound. As an extension, we also show the linear sum DoF upper bound for downlink/uplink cellular networks.}, 
keywords={interference (signal);linear codes;MIMO communication;radio receivers;radio transmitters;telecommunication channels;linear degrees of freedom;K -user MISO interference channels;blind interference alignment;multiple-input single-output interference channels;reconfigurable antennas;linear coding strategies;receivers;channel state information;transmitters;downlink-uplink cellular networks;Integrated circuits;Transmitting antennas;MISO;Receiving antennas;Blind interference alignment;reconfigurable antenna;interference channel;degrees of freedom}, 
doi={10.1109/TWC.2017.2657503}, 
ISSN={1536-1276}, 
month={March},}
@INPROCEEDINGS{8367041, 
author={M. M. {Eler} and J. M. {Rojas} and Y. {Ge} and G. {Fraser}}, 
booktitle={2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)}, 
title={Automated Accessibility Testing of Mobile Apps}, 
year={2018}, 
volume={}, 
number={}, 
pages={116-126}, 
abstract={It is important to make mobile apps accessible, so as not to exclude users with common disabilities such as blindness, low vision, or color blindness. Even when developers are aware of these accessibility needs, the lack of tool support makes the development and assessment of accessible apps challenging. Some accessibility properties can be checked statically, but user interface widgets are often created dynamically and are not amenable to static checking. Some accessibility checking frameworks analyze accessibility properties at runtime, but have to rely on existing thorough test suites. In this paper, we introduce the idea of using automated test generation to explore the accessibility of mobile apps. We present the MATE tool (Mobile Accessibility Testing), which automatically explores apps while applying different checks for accessibility issues related to visual impairment. For each issue, MATE generates a detailed report that supports the developer in fixing the issue. Experiments on a sample of 73 apps demonstrate that MATE detects more basic accessibility problems than static analysis, and many additional types of accessibility problems that cannot be detected statically at all. Comparison with existing accessibility testing frameworks demonstrates that the independence of an existing test suite leads to the identification of many more accessibility problems. Even when enabling Android's assistive features like contrast enhancement, MATE can still find many accessibility issues.}, 
keywords={mobile computing;program diagnostics;program testing;smart phones;user interfaces;test suite;mobile apps;Mobile Accessibility Testing;accessibility testing frameworks;static analysis;MATE tool;automated test generation;accessibility checking frameworks;static checking;user interface widgets;accessibility properties;Testing;Tools;Androids;Humanoid robots;Google;Guidelines;Smart phones;accessibility;test generation;automated testing;software testing;mobile apps}, 
doi={10.1109/ICST.2018.00021}, 
ISSN={}, 
month={April},}
@INPROCEEDINGS{8572398, 
author={W. {Song} and Y. {Zhou} and X. {Hu} and S. {Duan} and H. {Lai}}, 
booktitle={2018 5th International Conference on Information, Cybernetics, and Computational Social Systems (ICCSS)}, 
title={Memristive Neural Network Based Reinforcement Learning with Reward Shaping for Path Finding}, 
year={2018}, 
volume={}, 
number={}, 
pages={200-205}, 
abstract={Robot is becoming an important role in people's daily life and work. Especially, in some extreme circumstances, robots can be used for searching and rescuing to improve the rescue efficiency and decrease additional casualties. Reinforcement learning, especially q-learning, is always employed in robot path finding for the unknown environment. However, the basic reinforcement learning always faces the problem of inefficiency and blindness. In this paper, a novel path finding method called MRNS q-learning is proposed. By leveraging the advantages of the reward shaping q-learning and memristive RBF neural network, this method may provide higher processing efficiency and convergence speed. In addition, a hardware architecture for the MRNS q-learning is also given. Finally, simulation results demonstrate the effectiveness and ascendancy of the proposed scheme.}, 
keywords={control engineering computing;learning (artificial intelligence);mobile robots;path planning;radial basis function networks;robot programming;MRNS q-learning;reward shaping;memristive RBF neural network;convergence speed;memristive neural network;robot path;reinforcement learning;path finding;Memristors;Radial basis function networks;Robots;Heuristic algorithms;Computational modeling;reinforcement learning;memristor;q-learning;reward shaping;RBF neural network;path-finding}, 
doi={10.1109/ICCSS.2018.8572398}, 
ISSN={2639-4235}, 
month={Aug},}
@ARTICLE{7313016, 
author={H. {Yang} and W. {Shin} and J. {Lee}}, 
journal={IEEE Transactions on Signal Processing}, 
title={Hierarchical Blind Interference Alignment Over Interference Networks With Finite Coherence Time}, 
year={2016}, 
volume={64}, 
number={5}, 
pages={1289-1304}, 
abstract={We investigate a blind interference alignment (BIA) scheme through staggered antenna switching over various interference networks (e.g., broadcast channel, interference channel, and cellular networks) with realistic channel assumptions. In existing BIA, the coherence time of channel is assumed to be long enough, but that may not always be true in realistic scenarios. Therefore, we propose a dynamic supersymbol design method which can construct a supersymbol with limited symbol extension that is determined by the coherence time of channel. It is demonstrated that the supersymbol block length can be reduced significantly by aligning interferences in a hierarchical manner, referred to as hierarchical BIA. The key idea of hierarchical BIA is to align interferences in groups and to use the same supersymbol structure between groups, producing aligned inter-group interferences without inner-group interference. Consequently, it is observed that with a given coherence time the proposed dynamic supersymbol design that exploits hierarchical BIA achieves higher degrees of freedom than the conventional method.}, 
keywords={antennas;interference (signal);hierarchical blind interference alignment;interference networks;finite coherence time;staggered antenna switching;broadcast channel;interference channel;cellular networks;dynamic supersymbol design method;limited symbol extension;supersymbol block length;hierarchical BIA;supersymbol structure;inter-group interferences;degrees of freedom;Receivers;Interference;Transmitters;Coherence;Antennas;Switches;Heuristic algorithms;Blind interference alignment (BIA);coherence time;degrees of freedom (Dof);reconfigurable antenna;supersymbol}, 
doi={10.1109/TSP.2015.2496282}, 
ISSN={1053-587X}, 
month={March},}
@ARTICLE{8520887, 
author={H. {Yoon} and J. {Li}}, 
journal={IEEE Transactions on Automation Science and Engineering}, 
title={A Novel Positive Transfer Learning Approach for Telemonitoring of Parkinson’s Disease}, 
year={2019}, 
volume={16}, 
number={1}, 
pages={180-191}, 
abstract={Telemonitoring is the use of electronic devices to remotely monitor patients. Taking the Parkinson's disease (PD) as an example, the use of at-home testing device (AHTD) enables remote, internet-based measurement of PD vocal symptoms. Translating AHTD measurement into a unified PD rating scale (UPDRS) through predictive analytics enables cost-effective, convenient, and close tracking of PD progression. Building a predictive model between AHTD measurement and UPDRS is not straightforward because PD patients are highly heterogeneous, which requires patient-specific models. Learning a patient-specific model faces the challenge of limited data. Transfer learning (TL) tackles this challenge by leveraging other patients' information to make up the data shortage when modeling a target patient. Among different TL methods, the category of parameter transfer methods is more appropriate for the telemonitoring application because it transfers patient-specific model parameters but not patients' data. However, existing parameter transfer methods fall short because not every other patient's information is helpful and blind transfer causes the problem of negative transfer. To tackle this limitation, we propose a positive TL (PTL) method. We provide an in-depth theoretical study on the risk and condition for negative transfer to happen, which further drive the development of novel PTL algorithms that are robust to negative transfer. We apply PTL to predict UPDRS of 42 PD patients using their AHTD vocal measurement. PTL achieves significantly better accuracy compared with single learning and one-model-fits-all approaches.}, 
keywords={biomedical measurement;diseases;learning (artificial intelligence);medical signal processing;patient monitoring;telemedicine;Parkinson's disease;electronic devices;at-home testing device;internet-based measurement;PD vocal symptoms;unified PD rating scale;UPDRS;data shortage;telemonitoring application;patient-specific model parameters;blind transfer;negative transfer;positive TL method;AHTD vocal measurement;parameter transfer method;positive transfer learning approach;Data models;Predictive models;Diseases;Machine learning;Monitoring;Prediction algorithms;Machine learning;negative transfer;telemonitoring;transfer learning (TL)}, 
doi={10.1109/TASE.2018.2874233}, 
ISSN={1545-5955}, 
month={Jan},}
@INPROCEEDINGS{8278090, 
author={M. {Bertacchi} and I. {Silveira} and N. {Omar}}, 
booktitle={2017 Workshop of Computer Vision (WVC)}, 
title={A Comparative Analysis of the Evolution of the IBM Watson's Visual Recognition API on Android}, 
year={2017}, 
volume={}, 
number={}, 
pages={120-125}, 
abstract={This work presents a comparative analysis of the evolution of IBM Watson, done with a Computer Vision application, which describes pictures for visually impaired using Watson, a computer developed by IBM primarily for text recognition and analysis. Watson also has an API of Visual Recognition with Cognition techniques, and it is through it that picture description is developed. Android was chosen to deal with the application interface, because of its popularity and portability with the IBM platform presented in this article. The comparison results were satisfactory, allowing the cognitive field to become more frequently explored, in particular to help people with special needs.}, 
keywords={application program interfaces;cognition;computer vision;handicapped aids;object recognition;comparative analysis;Android;text recognition;picture description;application interface;IBM platform;computer vision application;IBM Watson visual recognition API;visually impaired;cognition techniques;special needs;Smart phones;Cameras;Computer vision;Androids;Humanoid robots;Operating systems;Visualization;Computer Vision;IBM Watson;Cognition;Android}, 
doi={10.1109/WVC.2017.00028}, 
ISSN={}, 
month={Oct},}
@INPROCEEDINGS{7760402, 
author={Y. {Bando} and K. {Itoyama} and M. {Konyo} and S. {Tadokoro} and K. {Nakadai} and K. {Yoshii} and H. G. {Okuno}}, 
booktitle={2016 24th European Signal Processing Conference (EUSIPCO)}, 
title={Variational Bayesian multi-channel robust NMF for human-voice enhancement with a deformable and partially-occluded microphone array}, 
year={2016}, 
volume={}, 
number={}, 
pages={1018-1022}, 
abstract={This paper presents a human-voice enhancement method for a deformable and partially-occluded microphone array. Although microphone arrays distributed on the long bodies of hose-shaped rescue robots are crucial for finding victims under collapsed buildings, human voices captured by a microphone array are contaminated by non-stationary actuator and friction noise. Standard blind source separation methods cannot be used because the relative microphone positions change over time and some of them are occasionally shaded by rubble. To solve these problems, we develop a Bayesian model that separates multichannel amplitude spectrograms into sparse and low-rank components (human voice and noise) without using phase information, which depends on the array layout. The voice level at each microphone is estimated in a time-varying manner for reducing the influence of the shaded microphones. Experiments using a 3-m hose-shaped robot with eight microphones show that our method outperforms conventional methods by the signal-to-noise ratio of 2.7 dB.}, 
keywords={Bayes methods;matrix decomposition;microphone arrays;rescue robots;speech enhancement;variational techniques;variational Bayesian multichannel robust NMF;human-voice enhancement;partially-occluded microphone array;deformable microphone array;hose-shaped rescue robot;nonstationary actuator;friction noise;signal-to-noise ratio;multichannel amplitude spectrogram;Spectrogram;Robots;Bayes methods;Human voice;Radio frequency;Microphone arrays}, 
doi={10.1109/EUSIPCO.2016.7760402}, 
ISSN={2076-1465}, 
month={Aug},}
@ARTICLE{8007258, 
author={T. {Lisini Baldi} and S. {Scheggi} and M. {Aggravi} and D. {Prattichizzo}}, 
journal={IEEE Robotics and Automation Letters}, 
title={Haptic Guidance in Dynamic Environments Using Optimal Reciprocal Collision Avoidance}, 
year={2018}, 
volume={3}, 
number={1}, 
pages={265-272}, 
abstract={Human guidance in situations where the users cannot rely on their main sensory modalities, such as assistive or search-and-rescue scenarios, is a challenging task. In this letter, we address the problem of guiding users along collision-free paths in dynamic environments, assuming that they cannot rely on their main sensory modalities. In order to safely guide the subjects, we adapt the optimal reciprocal collision avoidance to our specific problem. The proposed algorithm takes into account the stimuli which can be displayed to the users and the motion uncertainty of the users when reacting to the provided stimuli. The proposed algorithm was evaluated in three different dynamic scenarios. A total of 18 blindfolded human subjects were asked to follow haptic cues in order to reach a target area while avoiding real static obstacles and moving users. Three metrics such as time to reach the goal, length of the trajectories, and minimal distance from the obstacles are considered to compare results obtained using this approach and experiments performed without visual impairments. Experimental results reveal that blindfolded subjects are successfully able to avoid collisions and safely reach the targets in all the performed trials. Although in this letter we display directional cues via haptic stimuli, we believe that the proposed approach can be general and tuned to work with different haptic interfaces and/or feedback modalities.}, 
keywords={collision avoidance;haptic interfaces;haptic guidance;dynamic environments;optimal reciprocal collision avoidance;sensory modalities;haptic interfaces;feedback modalities;Haptic interfaces;Collision avoidance;Heuristic algorithms;Navigation;Robot sensing systems;Dynamics;Collision avoidance;haptics and haptic interfaces;human guidance}, 
doi={10.1109/LRA.2017.2738328}, 
ISSN={2377-3766}, 
month={Jan},}
@INPROCEEDINGS{7472132, 
author={L. {Sun} and B. {Chen} and K. {Ton} and Z. {Lin}}, 
booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
title={A parameter-free Cauchy-Schwartz information measure for independent component analysis}, 
year={2016}, 
volume={}, 
number={}, 
pages={2524-2528}, 
abstract={Independent component analysis (ICA) by an information measure has seen wide applications in engineering. Different from traditional probability density function based information measures, a probability survival distribution based Cauchy-Schwartz information measure for multiple variables is proposed in this paper. Empirical estimation of survival distribution is parameter-free which is inherited by the estimation of the new information measure. This measure is proved to be a valid statistical independence measure and is adopted as an objective function to develop an ICA algorithm which is validated by an experiment. This work shows promising potential regarding the use of survival distribution based information measure for ICA.}, 
keywords={independent component analysis;probability;parameter-free Cauchy-Schwartz information measure;independent component analysis;probability survival distribution;Estimation;Random variables;Density measurement;Independent component analysis;Electronic mail;Linear programming;Entropy;Probability Survival Distribution;Information Measure;Independent Component Analysis;Blind Signal Separation}, 
doi={10.1109/ICASSP.2016.7472132}, 
ISSN={2379-190X}, 
month={March},}
@INPROCEEDINGS{8351104, 
author={S. {Peng} and W. {Ser} and Z. {Lin} and B. {Chen}}, 
booktitle={2018 IEEE International Symposium on Circuits and Systems (ISCAS)}, 
title={Robust sparse nonnegative matrix factorization based on maximum correntropy criterion}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-5}, 
abstract={Nonnegative matrix factorization (NMF) is a significant matrix decomposition technique for learning parts-based, linear representation of nonnegative data, which has been widely used in a broad range of practical applications such as document clustering, image clustering, face recognition and blind spectral unmixing. Traditional NMF methods, which mainly minimize the square of the Euclidean distance or the Kullback-Leibler (KL) divergence, seriously suffer the outliers and non-Gaussian noises. In this paper, we propose a robust sparse nonnegative matrix factorization algorithm, called l1-norm nonnegative matrix factorization based on maximum correntropy criterion (11-CNMF). Specifically, l1-CNMF is derived from the traditional NMF algorithm by incorporating the l1 sparsity constraint and maximum correntropy criterion. Numerical experiments on the Yale database and the ORL database with and without apparent outliers show the effectiveness of the proposed algorithm for image clustering compared with other existing related methods.}, 
keywords={face recognition;Gaussian noise;matrix decomposition;pattern clustering;sparse matrices;matrix decomposition technique;NMF algorithm;l1sparsity constraint;l1-CNMF;l1-norm nonnegative matrix factorization;robust sparse nonnegative matrix factorization algorithm;nonGaussian noises;Kullback-Leibler divergence;blind spectral unmixing;face recognition;document clustering;broad range;nonnegative data;linear representation;image clustering;maximum correntropy criterion;Matrix decomposition;Clustering algorithms;Sparse matrices;Manganese;Robustness;Linear programming;Databases}, 
doi={10.1109/ISCAS.2018.8351104}, 
ISSN={2379-447X}, 
month={May},}
@ARTICLE{8304591, 
author={J. {Fang} and J. {Xue}}, 
journal={IEEE Transactions on Industrial Electronics}, 
title={Tunnel Brightness Compensation With Spatial–Temporal Visual-Content Preservation}, 
year={2018}, 
volume={65}, 
number={11}, 
pages={9005-9015}, 
abstract={Tunnels cause many traffic accidents in China every year, which is related to the inappropriate driving behaviors combined with less visual comfortability when driving across tunnels. The most common phenomenon when driving across the inlet and outlet sections of a tunnel is the abruptly varying visual brightness, causing a short-term blindness for a driver, known as the “black hole” and “white hole” effects, respectively. In this paper, we propose a tunnel brightness compensation model with spatial-temporal visual-content preservation. The highlights of this paper are twofold. 1) We analyze the visual brightness variation by introducing spatio-temporal orientation energy for a stable characterization of the visual comfortability of drivers in view of the distinguishable visual content caused by a sequential brightness variation. 2) We construct a tunnel brightness compensation model that preserves the spatial-temporal visual content by visual-content matching with multiple frames. Our method can manifestly improve the brightness quality and maintain the scene content simultaneously. Extensive visual brightness compensation experiments on 60 visual clips of inlet and outlet sections of tunnels demonstrate that the proposed method generates a state-of-the-art performance.}, 
keywords={brightness;feature extraction;image representation;image sequences;road safety;spatiotemporal phenomena;traffic engineering computing;tunnels;tunnel brightness compensation;spatial-temporal visual-content preservation;visual comfortability;visual brightness variation;spatio-temporal orientation energy;distinguishable visual content;spatial-temporal visual content;visual-content matching;brightness quality;driving behaviors;brightness variation;visual brightness compensation experiments;Brightness;Accidents;Visualization;Vehicles;Cameras;Dynamic range;Brightness compensation;spatio–temporal content-preserving;tunnel safety}, 
doi={10.1109/TIE.2018.2808934}, 
ISSN={0278-0046}, 
month={Nov},}
@INPROCEEDINGS{8699234, 
author={S. {Ikeda} and I. {Takemura} and A. {Kimura} and F. {Shibata}}, 
booktitle={2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)}, 
title={Diminished Reality System Based on Open-Source Software for Self-Driving Mobility}, 
year={2018}, 
volume={}, 
number={}, 
pages={354-357}, 
abstract={The diminished reality (DR) techniques that visualize blind areas in road environments are expected to prevent accidents and to reduce passengers' stress or anxiety. However, the feasibility of such techniques is still unclear because most researches on DR for road environments are based on the assumption of the availability of specific sensor arrangements and infrastructures, which are not guaranteed to spread in the future. In this research, we propose a novel design to implement a DR system for rendering ghosted hidden background areas using various sensor data for self-driving. Our major assumption is that a number of automotive vehicles run around the world in the near future and their sensors and program modules are available for other purposes. In our experiments, we confirmed that hidden area can be visualized by using such data and modules.}, 
keywords={automobiles;data visualisation;driver information systems;public domain software;road accidents;road safety;road vehicles;traffic engineering computing;virtual reality;DR system;diminished reality system;open-source software;self-driving mobility;diminished reality techniques;road environments;accident prevention;ghosted hidden background areas rendering;automotive vehicles;blind areas visualization;data visualization;Cameras;Three-dimensional displays;Laser radar;Vehicle dynamics;Roads;Rendering (computer graphics);Robot sensing systems;Human-centered computing—Human computer interaction—Interaction paradigms-Mixed/augmented reality;Modeling and simulation—Computer graphics—Graphics systems and interfaces—Mixed/augmented reality}, 
doi={10.1109/ISMAR-Adjunct.2018.00103}, 
ISSN={}, 
month={Oct},}
@ARTICLE{7407359, 
author={K. {Adhikari} and S. {Tatinati} and W. T. {Ang} and K. C. {Veluvolu} and K. {Nazarpour}}, 
journal={IEEE Transactions on Biomedical Engineering}, 
title={A Quaternion Weighted Fourier Linear Combiner for Modeling Physiological Tremor}, 
year={2016}, 
volume={63}, 
number={11}, 
pages={2336-2346}, 
abstract={Goal: This paper offers a new approach to model physiological tremor aiming at attenuating undesired vibrations of the tip of microsurgical instruments. Method: Several tremor modeling algorithms, such as the weighted Fourier linear combiner (wFLC), have proved effective. They, however, treat the three-dimensional (3-D) tremor signal as three independent 1-D signals in the x-, y-, and z-axes. In addition, the force f by which a surgeon holds the instrument has never been taken into account in modeling. Hence, conventional algorithms are inherently blind to any potential multidimensional couplings. Results: We first show that there exists statistically significant subject-and task-dependent coherence between data in the x-, y-, z-, and f-axes. We hypothesize that a filter that models the tremor in 4-D (x, y, z, and f) yields a more accurate model of tremor. We, therefore, developed a quaternion version of the wFLC algorithm and termed it QwFLC. We tested the proposed QwFLC algorithm with real physiological tremor data that were recorded from five novice subjects and four experienced microsurgeons. Although compared to wFLC, QwFLC requires six times larger computational resources, we showed that QwFLC can improve the modeling by up to 67% and that the improvement is proportional to the total coherence between the tremor in xyz and the force signal. Conclusion: By taking into account interactions of the 3-D tremor and the force data, the tremor modeling performance enhances significantly.}, 
keywords={Fourier analysis;gait analysis;medical disorders;physiological models;quaternion weighted Fourier linear combiner;physiological tremor;microsurgical instruments;tremor modeling algorithms;three-dimensional tremor signal;1D signals;potential multidimensional couplings;subject-task-dependent coherence;task-dependent coherence;wFLC algorithm;QwFLC algorithm;microsurgeons;computational resources;force data;Physiology;Coherence;Microsurgery;Instruments;Force;Adaptation models;Physiological tremor;quaternion algebra;weighted Fourier linear combiner;Algorithms;Computer Simulation;Essential Tremor;Fourier Analysis;Humans;Microsurgery;Models, Biological;Robotic Surgical Procedures}, 
doi={10.1109/TBME.2016.2530564}, 
ISSN={0018-9294}, 
month={Nov},}
@ARTICLE{8423727, 
author={J. {Li} and Y. {Zhang} and M. {Mao}}, 
journal={IEEE Transactions on Neural Networks and Learning Systems}, 
title={General Square-Pattern Discretization Formulas via Second-Order Derivative Elimination for Zeroing Neural Network Illustrated by Future Optimization}, 
year={2019}, 
volume={30}, 
number={3}, 
pages={891-901}, 
abstract={Previous works provide a few effective discretization formulas for zeroing neural network (ZNN), of which the precision is a square pattern. However, those formulas are separately developed via many relatively blind attempts. In this paper, general square-pattern discretization (SPD) formulas are proposed for ZNN via the idea of the second-order derivative elimination. All existing SPD formulas in previous works are included in the framework of the general SPD formulas. The connections and differences of various general formulas are also discussed. Furthermore, the general SPD formulas are used to solve future optimization under linear equality constraints, and the corresponding general discrete ZNN models are proposed. General discrete ZNN models have at least one parameter to adjust, thereby determining their zero stability. Thus, the parameter domains are obtained by restricting zero stability. Finally, numerous comparative numerical experiments, including the motion control of a PUMA560 robot manipulator, are provided to substantiate theoretical results and their superiority to conventional Euler formula.}, 
keywords={gradient methods;manipulators;matrix algebra;motion control;neural nets;optimisation;quadratic programming;stability;general square-pattern discretization formulas;second-order derivative elimination;zeroing neural network illustrated;future optimization;effective discretization formulas;square pattern;general SPD formulas;general formulas;corresponding general discrete ZNN models;zero stability;conventional Euler formula;Optimization;Numerical stability;Neural networks;Numerical models;Time-varying systems;Stability criteria;Future optimization;general square-pattern discretization (SPD) formulas;second-order derivative elimination (SODE);zero stability;zeroing neural network (ZNN)}, 
doi={10.1109/TNNLS.2018.2853732}, 
ISSN={2162-237X}, 
month={March},}